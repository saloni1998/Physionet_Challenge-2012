{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('/home/saloni/Documents/ML/Mortality/train.csv')\n",
    "labels=pd.read_csv('/home/saloni/Documents/ML/Mortality/labels_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dailydata=df.copy()\n",
    "result=pd.concat([dailydata,labels],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>...</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Temp</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Weight</th>\n",
       "      <th>pH</th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>54</td>\n",
       "      <td>2.973333</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>97.25</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>37.357143</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>171.052632</td>\n",
       "      <td>10.3</td>\n",
       "      <td>80.060976</td>\n",
       "      <td>7.387273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ALP   ALT   AST  Age   Albumin   BUN  Bilirubin  Cholesterol  Creatinine  \\\n",
       "0  77.0  31.0  46.0   54  2.973333  10.5        0.7        154.0        0.75   \n",
       "\n",
       "     DiasABP        ...           SaO2      SysABP       Temp  TroponinI  \\\n",
       "0  58.795833        ...          97.25  116.891892  37.357143        2.1   \n",
       "\n",
       "   TroponinT       Urine   WBC     Weight        pH  In-hospital_death  \n",
       "0       0.14  171.052632  10.3  80.060976  7.387273                  0  \n",
       "\n",
       "[1 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_variables = ['Age', 'Albumin', 'ALP', 'ALT', 'AST', 'Bilirubin', 'BUN', 'Cholesterol', 'Creatinine',\n",
    "                             'DiasABP', 'FiO2', 'GCS', 'Gender', 'Glucose', 'HCO3', 'HCT', 'Height', 'HR', 'ICUType', 'K',\n",
    "                             'Lactate', 'Mg', 'MAP', 'MechVent', 'Na', 'NIDiasABP', 'NIMAP', 'NISysABP', 'PaCO2', 'PaO2',\n",
    "                             'pH', 'Platelets', 'RecordID', 'RespRate', 'SaO2', 'SysABP', 'Temp', 'TroponinI','TroponinT','Urine',\n",
    "                             'WBC', 'Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datawithoutoutliers=result.copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3169, 43)\n"
     ]
    }
   ],
   "source": [
    "for i in list_of_variables:\n",
    "    datawithoutoutliers=datawithoutoutliers[np.abs(datawithoutoutliers[i]-datawithoutoutliers[i].mean())<=(4*datawithoutoutliers[i].std())]\n",
    "    outliers=datawithoutoutliers[np.abs(datawithoutoutliers[i]-datawithoutoutliers[i].mean())>=(4*datawithoutoutliers[i].std())]\n",
    "    \n",
    "print(datawithoutoutliers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels=datawithoutoutliers.pop(\"In-hospital_death\")\n",
    "df=datawithoutoutliers.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3169,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3169, 42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#normalization\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df = scaler.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "df_res,labels_res=SMOTE(random_state=9).fit_sample(df,labels) #balancing the data\n",
    "df_res=pd.DataFrame(df_res)\n",
    "labels_res=pd.DataFrame(labels_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc=OneHotEncoder(sparse=False)\n",
    "onehot_encoded = enc.fit_transform(labels_res)\n",
    "\n",
    "labels_res=onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(df_res,labels_res,test_size=0.33,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden_1=120\n",
    "n_hidden_2=120\n",
    "n_hidden_3=120\n",
    "n_hidden_4=120\n",
    "n_hidden_5=120\n",
    "\n",
    "\n",
    "x=tf.placeholder(tf.float32,shape=[None,42])\n",
    "y_=tf.placeholder(tf.float32,shape=[None,2])\n",
    "w =tf.Variable(tf.zeros([42,2]))\n",
    "b=tf.Variable(tf.zeros([2]))\n",
    "\n",
    "def multilayer_perceptron(x,weights,biases):\n",
    "    layer_1=tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    layer_1=tf.nn.sigmoid(layer_1)\n",
    "    \n",
    "    layer_2=tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
    "    layer_2=tf.nn.sigmoid(layer_2)\n",
    "    \n",
    "    layer_3=tf.add(tf.matmul(layer_2,weights['h3']),biases['b3'])\n",
    "    layer_3=tf.nn.sigmoid(layer_3)\n",
    "    \n",
    "    layer_4=tf.add(tf.matmul(layer_3,weights['h4']),biases['b4'])\n",
    "    layer_4=tf.nn.sigmoid(layer_4)\n",
    "    \n",
    "    layer_5=tf.add(tf.matmul(layer_4,weights['h5']),biases['b5'])\n",
    "    layer_5=tf.nn.relu(layer_5)\n",
    "    \n",
    "    \n",
    "    out_layer=tf.add(tf.matmul(layer_5,weights['out']),biases['out'])\n",
    "    return out_layer\n",
    "\n",
    "weights={\n",
    "       \n",
    "    'h1':tf.Variable(tf.truncated_normal([42,n_hidden_1])),\n",
    "    'h2':tf.Variable(tf.truncated_normal([n_hidden_1,n_hidden_2])),\n",
    "    'h3':tf.Variable(tf.truncated_normal([n_hidden_2,n_hidden_3])),\n",
    "    'h4':tf.Variable(tf.truncated_normal([n_hidden_3,n_hidden_4])),\n",
    "    'h5':tf.Variable(tf.truncated_normal([n_hidden_4,n_hidden_5])),\n",
    "    'out':tf.Variable(tf.truncated_normal([n_hidden_5,2]))\n",
    "}\n",
    "\n",
    "biases={\n",
    "    'b1':tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3':tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'b4':tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    'b5':tf.Variable(tf.truncated_normal([n_hidden_5])),\n",
    "    'out':tf.Variable(tf.truncated_normal([2]))\n",
    "}\n",
    "    \n",
    "y=multilayer_perceptron(x,weights,biases)\n",
    "cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_,logits=y))  \n",
    "train_step=tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "sess.run(tf.global_variables_initializer())                     \n",
    "                     \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_history=[]\n",
    "cost_history=[]\n",
    "accuracy_history=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_epochs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - cost: 9.24004 mse:  136.942631748 - -train accuracy: 0.507852\n",
      "epoch: 1 - cost: 17.0569 mse:  347.58140078 - -train accuracy: 0.492148\n",
      "epoch: 2 - cost: 8.58024 mse:  127.062143022 - -train accuracy: 0.507852\n",
      "epoch: 3 - cost: 14.5427 mse:  278.52839411 - -train accuracy: 0.492148\n",
      "epoch: 4 - cost: 8.82081 mse:  131.060037545 - -train accuracy: 0.507852\n",
      "epoch: 5 - cost: 12.6862 mse:  232.004399542 - -train accuracy: 0.492148\n",
      "epoch: 6 - cost: 9.26931 mse:  138.657144932 - -train accuracy: 0.507852\n",
      "epoch: 7 - cost: 11.1412 mse:  195.310900791 - -train accuracy: 0.492148\n",
      "epoch: 8 - cost: 9.78716 mse:  147.933179215 - -train accuracy: 0.507852\n",
      "epoch: 9 - cost: 9.75498 mse:  164.514362978 - -train accuracy: 0.492148\n",
      "epoch: 10 - cost: 10.3139 mse:  158.001868568 - -train accuracy: 0.507852\n",
      "epoch: 11 - cost: 8.50033 mse:  138.919446629 - -train accuracy: 0.492148\n",
      "epoch: 12 - cost: 10.8092 mse:  168.540468024 - -train accuracy: 0.507852\n",
      "epoch: 13 - cost: 7.41344 mse:  119.536690462 - -train accuracy: 0.492148\n",
      "epoch: 14 - cost: 11.2734 mse:  179.368729209 - -train accuracy: 0.507852\n",
      "epoch: 15 - cost: 6.44914 mse:  104.656707444 - -train accuracy: 0.492148\n",
      "epoch: 16 - cost: 11.7133 mse:  190.666160265 - -train accuracy: 0.507852\n",
      "epoch: 17 - cost: 5.57533 mse:  92.9701859442 - -train accuracy: 0.492148\n",
      "epoch: 18 - cost: 12.1243 mse:  202.271244678 - -train accuracy: 0.507852\n",
      "epoch: 19 - cost: 4.79491 mse:  84.1569934122 - -train accuracy: 0.49268\n",
      "epoch: 20 - cost: 12.4458 mse:  212.305643736 - -train accuracy: 0.507852\n",
      "epoch: 21 - cost: 4.16305 mse:  78.4326057527 - -train accuracy: 0.493213\n",
      "epoch: 22 - cost: 12.6063 mse:  218.546200118 - -train accuracy: 0.507852\n",
      "epoch: 23 - cost: 3.7352 mse:  75.4541937836 - -train accuracy: 0.494544\n",
      "epoch: 24 - cost: 12.5551 mse:  219.188064101 - -train accuracy: 0.507852\n",
      "epoch: 25 - cost: 3.55339 mse:  75.0866892912 - -train accuracy: 0.494544\n",
      "epoch: 26 - cost: 12.3829 mse:  216.608669221 - -train accuracy: 0.507852\n",
      "epoch: 27 - cost: 3.51489 mse:  76.1225131513 - -train accuracy: 0.494544\n",
      "epoch: 28 - cost: 12.1981 mse:  213.571351448 - -train accuracy: 0.507852\n",
      "epoch: 29 - cost: 3.50867 mse:  77.3700051999 - -train accuracy: 0.494544\n",
      "epoch: 30 - cost: 12.0149 mse:  210.575544053 - -train accuracy: 0.507852\n",
      "epoch: 31 - cost: 3.5164 mse:  78.7150325702 - -train accuracy: 0.49481\n",
      "epoch: 32 - cost: 11.8362 mse:  207.659524312 - -train accuracy: 0.507852\n",
      "epoch: 33 - cost: 3.53253 mse:  80.1383689104 - -train accuracy: 0.49481\n",
      "epoch: 34 - cost: 11.6601 mse:  204.775963814 - -train accuracy: 0.507852\n",
      "epoch: 35 - cost: 3.55021 mse:  81.5830866802 - -train accuracy: 0.494544\n",
      "epoch: 36 - cost: 11.485 mse:  201.95461792 - -train accuracy: 0.507852\n",
      "epoch: 37 - cost: 3.57421 mse:  83.0684788694 - -train accuracy: 0.49481\n",
      "epoch: 38 - cost: 11.3128 mse:  199.204850162 - -train accuracy: 0.507852\n",
      "epoch: 39 - cost: 3.60166 mse:  84.4968155112 - -train accuracy: 0.49481\n",
      "epoch: 40 - cost: 11.1389 mse:  196.45301295 - -train accuracy: 0.507852\n",
      "epoch: 41 - cost: 3.63659 mse:  86.0329758723 - -train accuracy: 0.494544\n",
      "epoch: 42 - cost: 10.9652 mse:  193.756864801 - -train accuracy: 0.507852\n",
      "epoch: 43 - cost: 3.6752 mse:  87.5660789618 - -train accuracy: 0.494544\n",
      "epoch: 44 - cost: 10.7949 mse:  191.052979227 - -train accuracy: 0.507852\n",
      "epoch: 45 - cost: 3.71521 mse:  89.0784869399 - -train accuracy: 0.494277\n",
      "epoch: 46 - cost: 10.6251 mse:  188.296027469 - -train accuracy: 0.507852\n",
      "epoch: 47 - cost: 3.75894 mse:  90.5585550586 - -train accuracy: 0.494277\n",
      "epoch: 48 - cost: 10.4544 mse:  185.561086147 - -train accuracy: 0.507852\n",
      "epoch: 49 - cost: 3.80406 mse:  92.1387209212 - -train accuracy: 0.494011\n",
      "epoch: 50 - cost: 10.2871 mse:  182.925389555 - -train accuracy: 0.507852\n",
      "epoch: 51 - cost: 3.84754 mse:  93.7090495307 - -train accuracy: 0.493213\n",
      "epoch: 52 - cost: 10.1164 mse:  180.270896116 - -train accuracy: 0.507852\n",
      "epoch: 53 - cost: 3.89876 mse:  95.4257195361 - -train accuracy: 0.493213\n",
      "epoch: 54 - cost: 9.94997 mse:  177.710174086 - -train accuracy: 0.507852\n",
      "epoch: 55 - cost: 3.94148 mse:  96.975758223 - -train accuracy: 0.493479\n",
      "epoch: 56 - cost: 9.78359 mse:  175.197758924 - -train accuracy: 0.507852\n",
      "epoch: 57 - cost: 3.98854 mse:  98.6612294878 - -train accuracy: 0.493479\n",
      "epoch: 58 - cost: 9.61757 mse:  172.762661645 - -train accuracy: 0.507852\n",
      "epoch: 59 - cost: 4.03298 mse:  100.375971997 - -train accuracy: 0.493745\n",
      "epoch: 60 - cost: 9.44773 mse:  170.38870236 - -train accuracy: 0.507852\n",
      "epoch: 61 - cost: 4.08142 mse:  102.20829473 - -train accuracy: 0.493745\n",
      "epoch: 62 - cost: 9.27917 mse:  168.019826107 - -train accuracy: 0.507852\n",
      "epoch: 63 - cost: 4.13168 mse:  103.932981332 - -train accuracy: 0.493479\n",
      "epoch: 64 - cost: 9.11446 mse:  165.660971009 - -train accuracy: 0.507852\n",
      "epoch: 65 - cost: 4.1745 mse:  105.608485213 - -train accuracy: 0.493213\n",
      "epoch: 66 - cost: 8.95106 mse:  163.421300999 - -train accuracy: 0.507852\n",
      "epoch: 67 - cost: 4.22154 mse:  107.392588875 - -train accuracy: 0.492947\n",
      "epoch: 68 - cost: 8.78768 mse:  161.203909955 - -train accuracy: 0.507852\n",
      "epoch: 69 - cost: 4.26448 mse:  109.02518018 - -train accuracy: 0.492947\n",
      "epoch: 70 - cost: 8.62945 mse:  159.020523708 - -train accuracy: 0.507852\n",
      "epoch: 71 - cost: 4.29955 mse:  110.465939769 - -train accuracy: 0.493213\n",
      "epoch: 72 - cost: 8.4724 mse:  156.849713333 - -train accuracy: 0.507852\n",
      "epoch: 73 - cost: 4.33532 mse:  111.833812649 - -train accuracy: 0.492947\n",
      "epoch: 74 - cost: 8.31639 mse:  154.633536541 - -train accuracy: 0.507852\n",
      "epoch: 75 - cost: 4.36441 mse:  113.051088529 - -train accuracy: 0.493213\n",
      "epoch: 76 - cost: 8.16009 mse:  152.45058656 - -train accuracy: 0.507852\n",
      "epoch: 77 - cost: 4.39563 mse:  114.25629226 - -train accuracy: 0.493479\n",
      "epoch: 78 - cost: 8.0077 mse:  150.290189526 - -train accuracy: 0.508917\n",
      "epoch: 79 - cost: 4.41615 mse:  115.274221937 - -train accuracy: 0.493479\n",
      "epoch: 80 - cost: 7.85991 mse:  148.177345493 - -train accuracy: 0.509449\n",
      "epoch: 81 - cost: 4.42974 mse:  116.137782155 - -train accuracy: 0.493745\n",
      "epoch: 82 - cost: 7.71387 mse:  146.139482505 - -train accuracy: 0.509715\n",
      "epoch: 83 - cost: 4.43668 mse:  116.919948063 - -train accuracy: 0.494277\n",
      "epoch: 84 - cost: 7.57538 mse:  144.141435623 - -train accuracy: 0.51078\n",
      "epoch: 85 - cost: 4.4309 mse:  117.380682052 - -train accuracy: 0.495874\n",
      "epoch: 86 - cost: 7.43492 mse:  142.151621708 - -train accuracy: 0.512111\n",
      "epoch: 87 - cost: 4.42015 mse:  117.769264105 - -train accuracy: 0.497205\n",
      "epoch: 88 - cost: 7.30057 mse:  140.261852347 - -train accuracy: 0.513708\n",
      "epoch: 89 - cost: 4.3984 mse:  117.9479049 - -train accuracy: 0.499068\n",
      "epoch: 90 - cost: 7.16368 mse:  138.327082071 - -train accuracy: 0.515039\n",
      "epoch: 91 - cost: 4.37584 mse:  118.157174803 - -train accuracy: 0.500665\n",
      "epoch: 92 - cost: 7.03464 mse:  136.481052922 - -train accuracy: 0.516636\n",
      "epoch: 93 - cost: 4.34299 mse:  118.198558451 - -train accuracy: 0.502262\n",
      "epoch: 94 - cost: 6.90209 mse:  134.632604903 - -train accuracy: 0.5177\n",
      "epoch: 95 - cost: 4.30707 mse:  118.17180923 - -train accuracy: 0.504126\n",
      "epoch: 96 - cost: 6.77723 mse:  132.933467379 - -train accuracy: 0.520628\n",
      "epoch: 97 - cost: 4.2587 mse:  117.93776159 - -train accuracy: 0.506255\n",
      "epoch: 98 - cost: 6.64789 mse:  131.196942702 - -train accuracy: 0.522491\n",
      "epoch: 99 - cost: 4.21313 mse:  117.814927188 - -train accuracy: 0.508384\n",
      "epoch: 100 - cost: 6.52513 mse:  129.57200758 - -train accuracy: 0.525153\n",
      "epoch: 101 - cost: 4.1603 mse:  117.562508813 - -train accuracy: 0.512111\n",
      "epoch: 102 - cost: 6.40659 mse:  128.060338107 - -train accuracy: 0.528081\n",
      "epoch: 103 - cost: 4.1018 mse:  117.148023251 - -train accuracy: 0.51424\n",
      "epoch: 104 - cost: 6.28761 mse:  126.518719644 - -train accuracy: 0.531275\n",
      "epoch: 105 - cost: 4.04457 mse:  116.73402562 - -train accuracy: 0.514506\n",
      "epoch: 106 - cost: 6.17434 mse:  125.08618282 - -train accuracy: 0.535534\n",
      "epoch: 107 - cost: 3.98133 mse:  116.172882561 - -train accuracy: 0.516902\n",
      "epoch: 108 - cost: 6.06085 mse:  123.666640135 - -train accuracy: 0.538994\n",
      "epoch: 109 - cost: 3.91938 mse:  115.66648268 - -train accuracy: 0.517434\n",
      "epoch: 110 - cost: 5.94982 mse:  122.277190348 - -train accuracy: 0.541656\n",
      "epoch: 111 - cost: 3.85679 mse:  115.089869656 - -train accuracy: 0.518499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 112 - cost: 5.8407 mse:  120.896395714 - -train accuracy: 0.546713\n",
      "epoch: 113 - cost: 3.79512 mse:  114.461293191 - -train accuracy: 0.52116\n",
      "epoch: 114 - cost: 5.73659 mse:  119.54000648 - -train accuracy: 0.549108\n",
      "epoch: 115 - cost: 3.73392 mse:  113.717422722 - -train accuracy: 0.524355\n",
      "epoch: 116 - cost: 5.63398 mse:  118.207849354 - -train accuracy: 0.552569\n",
      "epoch: 117 - cost: 3.67733 mse:  113.097783514 - -train accuracy: 0.527282\n",
      "epoch: 118 - cost: 5.53691 mse:  116.971316209 - -train accuracy: 0.554964\n",
      "epoch: 119 - cost: 3.62324 mse:  112.477349497 - -train accuracy: 0.53021\n",
      "epoch: 120 - cost: 5.44551 mse:  115.822983913 - -train accuracy: 0.556561\n",
      "epoch: 121 - cost: 3.56914 mse:  111.878677075 - -train accuracy: 0.531275\n",
      "epoch: 122 - cost: 5.35534 mse:  114.665091546 - -train accuracy: 0.560021\n",
      "epoch: 123 - cost: 3.5164 mse:  111.190286622 - -train accuracy: 0.532606\n",
      "epoch: 124 - cost: 5.27119 mse:  113.552971891 - -train accuracy: 0.561884\n",
      "epoch: 125 - cost: 3.46576 mse:  110.462276222 - -train accuracy: 0.534203\n",
      "epoch: 126 - cost: 5.18832 mse:  112.457930308 - -train accuracy: 0.564812\n",
      "epoch: 127 - cost: 3.41512 mse:  109.770649189 - -train accuracy: 0.535534\n",
      "epoch: 128 - cost: 5.10604 mse:  111.415687325 - -train accuracy: 0.566676\n",
      "epoch: 129 - cost: 3.3651 mse:  109.120923064 - -train accuracy: 0.537929\n",
      "epoch: 130 - cost: 5.03178 mse:  110.437309036 - -train accuracy: 0.568273\n",
      "epoch: 131 - cost: 3.31853 mse:  108.421989987 - -train accuracy: 0.53926\n",
      "epoch: 132 - cost: 4.96452 mse:  109.531771746 - -train accuracy: 0.569603\n",
      "epoch: 133 - cost: 3.27327 mse:  107.787517404 - -train accuracy: 0.541389\n",
      "epoch: 134 - cost: 4.8919 mse:  108.629341502 - -train accuracy: 0.57333\n",
      "epoch: 135 - cost: 3.23076 mse:  107.286167751 - -train accuracy: 0.542454\n",
      "epoch: 136 - cost: 4.82036 mse:  107.736076326 - -train accuracy: 0.574927\n",
      "epoch: 137 - cost: 3.18738 mse:  106.692949009 - -train accuracy: 0.543253\n",
      "epoch: 138 - cost: 4.74901 mse:  106.841731691 - -train accuracy: 0.577056\n",
      "epoch: 139 - cost: 3.14529 mse:  106.119752608 - -train accuracy: 0.543253\n",
      "epoch: 140 - cost: 4.6786 mse:  105.973947041 - -train accuracy: 0.579452\n",
      "epoch: 141 - cost: 3.10452 mse:  105.621841584 - -train accuracy: 0.544051\n",
      "epoch: 142 - cost: 4.6111 mse:  105.154130188 - -train accuracy: 0.58238\n",
      "epoch: 143 - cost: 3.0644 mse:  105.07923351 - -train accuracy: 0.545116\n",
      "epoch: 144 - cost: 4.54733 mse:  104.369671886 - -train accuracy: 0.583977\n",
      "epoch: 145 - cost: 3.02594 mse:  104.535466249 - -train accuracy: 0.545914\n",
      "epoch: 146 - cost: 4.4849 mse:  103.553043378 - -train accuracy: 0.585574\n",
      "epoch: 147 - cost: 2.9908 mse:  104.023543372 - -train accuracy: 0.546713\n",
      "epoch: 148 - cost: 4.42752 mse:  102.79598234 - -train accuracy: 0.586372\n",
      "epoch: 149 - cost: 2.95799 mse:  103.522636719 - -train accuracy: 0.547245\n",
      "epoch: 150 - cost: 4.37523 mse:  102.083463668 - -train accuracy: 0.587969\n",
      "epoch: 151 - cost: 2.92509 mse:  103.045571067 - -train accuracy: 0.548044\n",
      "epoch: 152 - cost: 4.32326 mse:  101.40449563 - -train accuracy: 0.589034\n",
      "epoch: 153 - cost: 2.89325 mse:  102.616486789 - -train accuracy: 0.550173\n",
      "epoch: 154 - cost: 4.27325 mse:  100.749512216 - -train accuracy: 0.589034\n",
      "epoch: 155 - cost: 2.86334 mse:  102.178051956 - -train accuracy: 0.552036\n",
      "epoch: 156 - cost: 4.22593 mse:  100.098447372 - -train accuracy: 0.590099\n",
      "epoch: 157 - cost: 2.83284 mse:  101.676760278 - -train accuracy: 0.553101\n",
      "epoch: 158 - cost: 4.17895 mse:  99.4330223308 - -train accuracy: 0.590099\n",
      "epoch: 159 - cost: 2.8008 mse:  101.120460468 - -train accuracy: 0.554432\n",
      "epoch: 160 - cost: 4.13276 mse:  98.7190997671 - -train accuracy: 0.591695\n",
      "epoch: 161 - cost: 2.77203 mse:  100.577984382 - -train accuracy: 0.554964\n",
      "epoch: 162 - cost: 4.09124 mse:  98.0375737876 - -train accuracy: 0.59276\n",
      "epoch: 163 - cost: 2.74246 mse:  99.9758293734 - -train accuracy: 0.555496\n",
      "epoch: 164 - cost: 4.04773 mse:  97.3007442367 - -train accuracy: 0.594357\n",
      "epoch: 165 - cost: 2.71447 mse:  99.3707132536 - -train accuracy: 0.556295\n",
      "epoch: 166 - cost: 4.00628 mse:  96.5994249498 - -train accuracy: 0.59489\n",
      "epoch: 167 - cost: 2.68698 mse:  98.7599228333 - -train accuracy: 0.556827\n",
      "epoch: 168 - cost: 3.96124 mse:  95.8873804618 - -train accuracy: 0.595156\n",
      "epoch: 169 - cost: 2.6572 mse:  98.2135768308 - -train accuracy: 0.557892\n",
      "epoch: 170 - cost: 3.91182 mse:  95.1333590755 - -train accuracy: 0.596487\n",
      "epoch: 171 - cost: 2.6298 mse:  97.6834337526 - -train accuracy: 0.55869\n",
      "epoch: 172 - cost: 3.86899 mse:  94.4595104269 - -train accuracy: 0.598084\n",
      "epoch: 173 - cost: 2.60406 mse:  97.2176479072 - -train accuracy: 0.56082\n",
      "epoch: 174 - cost: 3.82772 mse:  93.8266617751 - -train accuracy: 0.599148\n",
      "epoch: 175 - cost: 2.57888 mse:  96.7462037271 - -train accuracy: 0.561352\n",
      "epoch: 176 - cost: 3.78981 mse:  93.2304799188 - -train accuracy: 0.599681\n",
      "epoch: 177 - cost: 2.55367 mse:  96.2515897705 - -train accuracy: 0.562151\n",
      "epoch: 178 - cost: 3.75198 mse:  92.6238645723 - -train accuracy: 0.600745\n",
      "epoch: 179 - cost: 2.53024 mse:  95.783681763 - -train accuracy: 0.562683\n",
      "epoch: 180 - cost: 3.71705 mse:  92.0415934503 - -train accuracy: 0.602608\n",
      "epoch: 181 - cost: 2.50762 mse:  95.2904408903 - -train accuracy: 0.564014\n",
      "epoch: 182 - cost: 3.68483 mse:  91.5235537442 - -train accuracy: 0.603141\n",
      "epoch: 183 - cost: 2.48511 mse:  94.8373644571 - -train accuracy: 0.564812\n",
      "epoch: 184 - cost: 3.64652 mse:  90.9655939864 - -train accuracy: 0.604472\n",
      "epoch: 185 - cost: 2.46016 mse:  94.3790170827 - -train accuracy: 0.565611\n",
      "epoch: 186 - cost: 3.60544 mse:  90.3885893355 - -train accuracy: 0.606335\n",
      "epoch: 187 - cost: 2.43613 mse:  93.9105280249 - -train accuracy: 0.566143\n",
      "epoch: 188 - cost: 3.56758 mse:  89.8000332721 - -train accuracy: 0.607932\n",
      "epoch: 189 - cost: 2.41482 mse:  93.4369847325 - -train accuracy: 0.566942\n",
      "epoch: 190 - cost: 3.53533 mse:  89.2993725915 - -train accuracy: 0.608464\n",
      "epoch: 191 - cost: 2.39294 mse:  92.9908684598 - -train accuracy: 0.568539\n",
      "epoch: 192 - cost: 3.50291 mse:  88.8109239441 - -train accuracy: 0.609795\n",
      "epoch: 193 - cost: 2.3722 mse:  92.5575386704 - -train accuracy: 0.568273\n",
      "epoch: 194 - cost: 3.47119 mse:  88.2997697704 - -train accuracy: 0.61086\n",
      "epoch: 195 - cost: 2.3526 mse:  92.1397182173 - -train accuracy: 0.568273\n",
      "epoch: 196 - cost: 3.4428 mse:  87.845540101 - -train accuracy: 0.612457\n",
      "epoch: 197 - cost: 2.33319 mse:  91.7397269648 - -train accuracy: 0.568539\n",
      "epoch: 198 - cost: 3.41501 mse:  87.4070681803 - -train accuracy: 0.61432\n",
      "epoch: 199 - cost: 2.31351 mse:  91.350150395 - -train accuracy: 0.568805\n",
      "epoch: 200 - cost: 3.38725 mse:  86.9691371048 - -train accuracy: 0.614852\n",
      "epoch: 201 - cost: 2.29445 mse:  90.9610400108 - -train accuracy: 0.56987\n",
      "epoch: 202 - cost: 3.36031 mse:  86.5804876097 - -train accuracy: 0.616183\n",
      "epoch: 203 - cost: 2.27314 mse:  90.5832138339 - -train accuracy: 0.56987\n",
      "epoch: 204 - cost: 3.32831 mse:  86.1297531042 - -train accuracy: 0.617248\n",
      "epoch: 205 - cost: 2.25254 mse:  90.2354310501 - -train accuracy: 0.570402\n",
      "epoch: 206 - cost: 3.29856 mse:  85.7255656181 - -train accuracy: 0.617514\n",
      "epoch: 207 - cost: 2.23221 mse:  89.8592305507 - -train accuracy: 0.5712\n",
      "epoch: 208 - cost: 3.26924 mse:  85.2862025097 - -train accuracy: 0.618579\n",
      "epoch: 209 - cost: 2.21179 mse:  89.4923232443 - -train accuracy: 0.571467\n",
      "epoch: 210 - cost: 3.23759 mse:  84.8377877337 - -train accuracy: 0.61991\n",
      "epoch: 211 - cost: 2.1923 mse:  89.1194551469 - -train accuracy: 0.57333\n",
      "epoch: 212 - cost: 3.20525 mse:  84.3712452826 - -train accuracy: 0.620176\n",
      "epoch: 213 - cost: 2.17162 mse:  88.7381226396 - -train accuracy: 0.573596\n",
      "epoch: 214 - cost: 3.17061 mse:  83.8750669115 - -train accuracy: 0.62124\n",
      "epoch: 215 - cost: 2.15244 mse:  88.3512417935 - -train accuracy: 0.574128\n",
      "epoch: 216 - cost: 3.14145 mse:  83.4476511588 - -train accuracy: 0.621507\n",
      "epoch: 217 - cost: 2.13412 mse:  87.9761656744 - -train accuracy: 0.574661\n",
      "epoch: 218 - cost: 3.1133 mse:  83.0117314766 - -train accuracy: 0.622305\n",
      "epoch: 219 - cost: 2.11613 mse:  87.6092950795 - -train accuracy: 0.575459\n",
      "epoch: 220 - cost: 3.08684 mse:  82.6125080198 - -train accuracy: 0.622305\n",
      "epoch: 221 - cost: 2.09944 mse:  87.272859492 - -train accuracy: 0.575459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 222 - cost: 3.06093 mse:  82.2360579073 - -train accuracy: 0.623902\n",
      "epoch: 223 - cost: 2.08105 mse:  86.9668169501 - -train accuracy: 0.576258\n",
      "epoch: 224 - cost: 3.03086 mse:  81.8172007175 - -train accuracy: 0.625233\n",
      "epoch: 225 - cost: 2.06026 mse:  86.6490014086 - -train accuracy: 0.576524\n",
      "epoch: 226 - cost: 2.99771 mse:  81.3873816022 - -train accuracy: 0.625765\n",
      "epoch: 227 - cost: 2.04145 mse:  86.3803243668 - -train accuracy: 0.577588\n",
      "epoch: 228 - cost: 2.96827 mse:  80.9896901854 - -train accuracy: 0.627096\n",
      "epoch: 229 - cost: 2.02185 mse:  86.1110167143 - -train accuracy: 0.576524\n",
      "epoch: 230 - cost: 2.93909 mse:  80.5932448209 - -train accuracy: 0.628959\n",
      "epoch: 231 - cost: 2.00137 mse:  85.8430539107 - -train accuracy: 0.577056\n",
      "epoch: 232 - cost: 2.90905 mse:  80.185223144 - -train accuracy: 0.629758\n",
      "epoch: 233 - cost: 1.98097 mse:  85.5860875675 - -train accuracy: 0.578387\n",
      "epoch: 234 - cost: 2.87952 mse:  79.7816013316 - -train accuracy: 0.630024\n",
      "epoch: 235 - cost: 1.96136 mse:  85.3777595171 - -train accuracy: 0.578653\n",
      "epoch: 236 - cost: 2.85457 mse:  79.4520457891 - -train accuracy: 0.630822\n",
      "epoch: 237 - cost: 1.94103 mse:  85.1909775803 - -train accuracy: 0.578653\n",
      "epoch: 238 - cost: 2.82819 mse:  79.1509090527 - -train accuracy: 0.631355\n",
      "epoch: 239 - cost: 1.92366 mse:  85.1144496186 - -train accuracy: 0.578387\n",
      "epoch: 240 - cost: 2.80337 mse:  78.8703546313 - -train accuracy: 0.631887\n",
      "epoch: 241 - cost: 1.90665 mse:  85.0089507897 - -train accuracy: 0.578121\n",
      "epoch: 242 - cost: 2.77719 mse:  78.6063600308 - -train accuracy: 0.632952\n",
      "epoch: 243 - cost: 1.88983 mse:  84.8779149659 - -train accuracy: 0.577056\n",
      "epoch: 244 - cost: 2.74954 mse:  78.3082177681 - -train accuracy: 0.633484\n",
      "epoch: 245 - cost: 1.87411 mse:  84.7235991491 - -train accuracy: 0.577056\n",
      "epoch: 246 - cost: 2.72609 mse:  78.081886435 - -train accuracy: 0.634549\n",
      "epoch: 247 - cost: 1.859 mse:  84.5832115186 - -train accuracy: 0.57679\n",
      "epoch: 248 - cost: 2.70654 mse:  77.8780604913 - -train accuracy: 0.635081\n",
      "epoch: 249 - cost: 1.84589 mse:  84.4456460771 - -train accuracy: 0.576524\n",
      "epoch: 250 - cost: 2.68827 mse:  77.6520863189 - -train accuracy: 0.635081\n",
      "epoch: 251 - cost: 1.83357 mse:  84.2501950466 - -train accuracy: 0.575193\n",
      "epoch: 252 - cost: 2.67428 mse:  77.4375606443 - -train accuracy: 0.635347\n",
      "epoch: 253 - cost: 1.82122 mse:  84.0518006716 - -train accuracy: 0.574661\n",
      "epoch: 254 - cost: 2.66053 mse:  77.2296689394 - -train accuracy: 0.635614\n",
      "epoch: 255 - cost: 1.80936 mse:  83.8548900059 - -train accuracy: 0.574661\n",
      "epoch: 256 - cost: 2.64252 mse:  76.9905520748 - -train accuracy: 0.636678\n",
      "epoch: 257 - cost: 1.79581 mse:  83.6230543218 - -train accuracy: 0.575725\n",
      "epoch: 258 - cost: 2.62107 mse:  76.7294227114 - -train accuracy: 0.637477\n",
      "epoch: 259 - cost: 1.78145 mse:  83.4155846222 - -train accuracy: 0.577056\n",
      "epoch: 260 - cost: 2.59662 mse:  76.4520950479 - -train accuracy: 0.638808\n",
      "epoch: 261 - cost: 1.76843 mse:  83.1972527346 - -train accuracy: 0.577588\n",
      "epoch: 262 - cost: 2.57807 mse:  76.2563392 - -train accuracy: 0.639074\n",
      "epoch: 263 - cost: 1.75663 mse:  83.0365432408 - -train accuracy: 0.578121\n",
      "epoch: 264 - cost: 2.55595 mse:  76.0142594168 - -train accuracy: 0.639606\n",
      "epoch: 265 - cost: 1.74494 mse:  82.863259109 - -train accuracy: 0.578919\n",
      "epoch: 266 - cost: 2.53493 mse:  75.7914150222 - -train accuracy: 0.639872\n",
      "epoch: 267 - cost: 1.73214 mse:  82.6815981934 - -train accuracy: 0.579452\n",
      "epoch: 268 - cost: 2.51599 mse:  75.5824083025 - -train accuracy: 0.639606\n",
      "epoch: 269 - cost: 1.72197 mse:  82.4927180254 - -train accuracy: 0.579718\n",
      "epoch: 270 - cost: 2.50106 mse:  75.4167441974 - -train accuracy: 0.640138\n",
      "epoch: 271 - cost: 1.71267 mse:  82.347200118 - -train accuracy: 0.579984\n",
      "epoch: 272 - cost: 2.4855 mse:  75.2514521379 - -train accuracy: 0.640937\n",
      "epoch: 273 - cost: 1.70215 mse:  82.1721015017 - -train accuracy: 0.580516\n",
      "epoch: 274 - cost: 2.46684 mse:  75.0666184183 - -train accuracy: 0.641203\n",
      "epoch: 275 - cost: 1.69134 mse:  82.0089334276 - -train accuracy: 0.582113\n",
      "epoch: 276 - cost: 2.44843 mse:  74.8552814889 - -train accuracy: 0.642002\n",
      "epoch: 277 - cost: 1.68124 mse:  81.8140423887 - -train accuracy: 0.582113\n",
      "epoch: 278 - cost: 2.43535 mse:  74.687919297 - -train accuracy: 0.6428\n",
      "epoch: 279 - cost: 1.67197 mse:  81.6418618556 - -train accuracy: 0.581581\n",
      "epoch: 280 - cost: 2.42045 mse:  74.5335893084 - -train accuracy: 0.643066\n",
      "epoch: 281 - cost: 1.66229 mse:  81.5023753613 - -train accuracy: 0.582912\n",
      "epoch: 282 - cost: 2.40468 mse:  74.4007615645 - -train accuracy: 0.643599\n",
      "epoch: 283 - cost: 1.65275 mse:  81.3659411008 - -train accuracy: 0.583977\n",
      "epoch: 284 - cost: 2.38944 mse:  74.2723449656 - -train accuracy: 0.643599\n",
      "epoch: 285 - cost: 1.64254 mse:  81.2285517842 - -train accuracy: 0.584243\n",
      "epoch: 286 - cost: 2.37423 mse:  74.1394131854 - -train accuracy: 0.643599\n",
      "epoch: 287 - cost: 1.63419 mse:  81.0973773257 - -train accuracy: 0.584775\n",
      "epoch: 288 - cost: 2.36003 mse:  74.0070645692 - -train accuracy: 0.643599\n",
      "epoch: 289 - cost: 1.62395 mse:  80.9358348617 - -train accuracy: 0.585307\n",
      "epoch: 290 - cost: 2.3452 mse:  73.8678747024 - -train accuracy: 0.644131\n",
      "epoch: 291 - cost: 1.61407 mse:  80.7923046268 - -train accuracy: 0.58584\n",
      "epoch: 292 - cost: 2.32901 mse:  73.7071657916 - -train accuracy: 0.644929\n",
      "epoch: 293 - cost: 1.60458 mse:  80.6065647743 - -train accuracy: 0.585574\n",
      "epoch: 294 - cost: 2.31301 mse:  73.5527845319 - -train accuracy: 0.644929\n",
      "epoch: 295 - cost: 1.59568 mse:  80.4611645366 - -train accuracy: 0.586106\n",
      "epoch: 296 - cost: 2.29776 mse:  73.3935271903 - -train accuracy: 0.645462\n",
      "epoch: 297 - cost: 1.58714 mse:  80.3048505136 - -train accuracy: 0.586638\n",
      "epoch: 298 - cost: 2.28257 mse:  73.2350953972 - -train accuracy: 0.645728\n",
      "epoch: 299 - cost: 1.57837 mse:  80.13835994 - -train accuracy: 0.586372\n",
      "epoch: 300 - cost: 2.26669 mse:  73.0444450706 - -train accuracy: 0.645994\n",
      "epoch: 301 - cost: 1.56884 mse:  79.9308901933 - -train accuracy: 0.587437\n",
      "epoch: 302 - cost: 2.2513 mse:  72.8782260845 - -train accuracy: 0.64626\n",
      "epoch: 303 - cost: 1.56027 mse:  79.7404048879 - -train accuracy: 0.588235\n",
      "epoch: 304 - cost: 2.2366 mse:  72.6737228115 - -train accuracy: 0.646526\n",
      "epoch: 305 - cost: 1.55263 mse:  79.5452750869 - -train accuracy: 0.588501\n",
      "epoch: 306 - cost: 2.22508 mse:  72.4989272893 - -train accuracy: 0.646793\n",
      "epoch: 307 - cost: 1.54527 mse:  79.3342919832 - -train accuracy: 0.588768\n",
      "epoch: 308 - cost: 2.21639 mse:  72.369856803 - -train accuracy: 0.646793\n",
      "epoch: 309 - cost: 1.53744 mse:  79.1791588712 - -train accuracy: 0.589566\n",
      "epoch: 310 - cost: 2.2018 mse:  72.1777385266 - -train accuracy: 0.647059\n",
      "epoch: 311 - cost: 1.53003 mse:  78.9775695287 - -train accuracy: 0.589832\n",
      "epoch: 312 - cost: 2.19065 mse:  72.0360497993 - -train accuracy: 0.647857\n",
      "epoch: 313 - cost: 1.52148 mse:  78.8123876283 - -train accuracy: 0.590897\n",
      "epoch: 314 - cost: 2.17252 mse:  71.8157941982 - -train accuracy: 0.64839\n",
      "epoch: 315 - cost: 1.51155 mse:  78.5594006037 - -train accuracy: 0.591429\n",
      "epoch: 316 - cost: 2.1577 mse:  71.5737570564 - -train accuracy: 0.648656\n",
      "epoch: 317 - cost: 1.50472 mse:  78.2985412059 - -train accuracy: 0.591163\n",
      "epoch: 318 - cost: 2.14904 mse:  71.4290408473 - -train accuracy: 0.648656\n",
      "epoch: 319 - cost: 1.49657 mse:  78.0910140538 - -train accuracy: 0.591429\n",
      "epoch: 320 - cost: 2.13345 mse:  71.1950029928 - -train accuracy: 0.649188\n",
      "epoch: 321 - cost: 1.48961 mse:  77.8685402692 - -train accuracy: 0.591163\n",
      "epoch: 322 - cost: 2.12171 mse:  71.0087778569 - -train accuracy: 0.650253\n",
      "epoch: 323 - cost: 1.48208 mse:  77.6522905323 - -train accuracy: 0.591962\n",
      "epoch: 324 - cost: 2.10741 mse:  70.7985709792 - -train accuracy: 0.650253\n",
      "epoch: 325 - cost: 1.47536 mse:  77.444485728 - -train accuracy: 0.591695\n",
      "epoch: 326 - cost: 2.09583 mse:  70.6091578538 - -train accuracy: 0.650785\n",
      "epoch: 327 - cost: 1.46834 mse:  77.2473088537 - -train accuracy: 0.591695\n",
      "epoch: 328 - cost: 2.08463 mse:  70.4433421889 - -train accuracy: 0.651051\n",
      "epoch: 329 - cost: 1.46104 mse:  77.0487798489 - -train accuracy: 0.592494\n",
      "epoch: 330 - cost: 2.07245 mse:  70.2818228828 - -train accuracy: 0.651584\n",
      "epoch: 331 - cost: 1.45289 mse:  76.8683988831 - -train accuracy: 0.593293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 332 - cost: 2.05729 mse:  70.1043406065 - -train accuracy: 0.652382\n",
      "epoch: 333 - cost: 1.44453 mse:  76.6705708486 - -train accuracy: 0.593825\n",
      "epoch: 334 - cost: 2.04552 mse:  69.9302391202 - -train accuracy: 0.652382\n",
      "epoch: 335 - cost: 1.43922 mse:  76.4959987307 - -train accuracy: 0.594091\n",
      "epoch: 336 - cost: 2.03765 mse:  69.8067686438 - -train accuracy: 0.652382\n",
      "epoch: 337 - cost: 1.43152 mse:  76.3220584984 - -train accuracy: 0.59489\n",
      "epoch: 338 - cost: 2.02081 mse:  69.6217068469 - -train accuracy: 0.653181\n",
      "epoch: 339 - cost: 1.42421 mse:  76.1460286193 - -train accuracy: 0.595156\n",
      "epoch: 340 - cost: 2.00771 mse:  69.4815049744 - -train accuracy: 0.653447\n",
      "epoch: 341 - cost: 1.41758 mse:  76.0065011495 - -train accuracy: 0.59489\n",
      "epoch: 342 - cost: 1.99712 mse:  69.3655147196 - -train accuracy: 0.653713\n",
      "epoch: 343 - cost: 1.41093 mse:  75.8665546522 - -train accuracy: 0.59489\n",
      "epoch: 344 - cost: 1.98601 mse:  69.2545003066 - -train accuracy: 0.653979\n",
      "epoch: 345 - cost: 1.4037 mse:  75.7194940424 - -train accuracy: 0.594623\n",
      "epoch: 346 - cost: 1.974 mse:  69.1324671022 - -train accuracy: 0.655044\n",
      "epoch: 347 - cost: 1.39721 mse:  75.5851423657 - -train accuracy: 0.594623\n",
      "epoch: 348 - cost: 1.96492 mse:  69.0554596952 - -train accuracy: 0.655842\n",
      "epoch: 349 - cost: 1.39046 mse:  75.5018270791 - -train accuracy: 0.595422\n",
      "epoch: 350 - cost: 1.95182 mse:  68.9788828111 - -train accuracy: 0.656641\n",
      "epoch: 351 - cost: 1.3833 mse:  75.4296284238 - -train accuracy: 0.595156\n",
      "epoch: 352 - cost: 1.93979 mse:  68.9176604407 - -train accuracy: 0.656907\n",
      "epoch: 353 - cost: 1.37676 mse:  75.3690526589 - -train accuracy: 0.595422\n",
      "epoch: 354 - cost: 1.93001 mse:  68.8755710812 - -train accuracy: 0.657439\n",
      "epoch: 355 - cost: 1.37076 mse:  75.3279273272 - -train accuracy: 0.595954\n",
      "epoch: 356 - cost: 1.91979 mse:  68.843438737 - -train accuracy: 0.657439\n",
      "epoch: 357 - cost: 1.36492 mse:  75.2966142185 - -train accuracy: 0.595954\n",
      "epoch: 358 - cost: 1.91074 mse:  68.8329667489 - -train accuracy: 0.657972\n",
      "epoch: 359 - cost: 1.35947 mse:  75.2515002672 - -train accuracy: 0.597285\n",
      "epoch: 360 - cost: 1.90239 mse:  68.8154650286 - -train accuracy: 0.658504\n",
      "epoch: 361 - cost: 1.35291 mse:  75.198105482 - -train accuracy: 0.598882\n",
      "epoch: 362 - cost: 1.89065 mse:  68.7694153611 - -train accuracy: 0.65877\n",
      "epoch: 363 - cost: 1.34635 mse:  75.1646382151 - -train accuracy: 0.599947\n",
      "epoch: 364 - cost: 1.88042 mse:  68.7638425422 - -train accuracy: 0.659303\n",
      "epoch: 365 - cost: 1.33994 mse:  75.1394025497 - -train accuracy: 0.600745\n",
      "epoch: 366 - cost: 1.87127 mse:  68.7628769115 - -train accuracy: 0.659835\n",
      "epoch: 367 - cost: 1.33448 mse:  75.1145727677 - -train accuracy: 0.600745\n",
      "epoch: 368 - cost: 1.86248 mse:  68.7415091158 - -train accuracy: 0.660634\n",
      "epoch: 369 - cost: 1.32915 mse:  75.0986562198 - -train accuracy: 0.601278\n",
      "epoch: 370 - cost: 1.85446 mse:  68.741721682 - -train accuracy: 0.660634\n",
      "epoch: 371 - cost: 1.32421 mse:  75.0801723803 - -train accuracy: 0.601011\n",
      "epoch: 372 - cost: 1.84683 mse:  68.7618699923 - -train accuracy: 0.6609\n",
      "epoch: 373 - cost: 1.31789 mse:  75.0627779579 - -train accuracy: 0.602342\n",
      "epoch: 374 - cost: 1.83597 mse:  68.7499748377 - -train accuracy: 0.661698\n",
      "epoch: 375 - cost: 1.31219 mse:  75.0475822582 - -train accuracy: 0.602076\n",
      "epoch: 376 - cost: 1.82791 mse:  68.7659179152 - -train accuracy: 0.661698\n",
      "epoch: 377 - cost: 1.30658 mse:  75.07393205 - -train accuracy: 0.602875\n",
      "epoch: 378 - cost: 1.81905 mse:  68.8084556555 - -train accuracy: 0.662497\n",
      "epoch: 379 - cost: 1.30092 mse:  75.1089785425 - -train accuracy: 0.603939\n",
      "epoch: 380 - cost: 1.81008 mse:  68.8588785763 - -train accuracy: 0.663029\n",
      "epoch: 381 - cost: 1.29434 mse:  75.129697749 - -train accuracy: 0.604472\n",
      "epoch: 382 - cost: 1.80099 mse:  68.9266150634 - -train accuracy: 0.663561\n",
      "epoch: 383 - cost: 1.28835 mse:  75.2088027992 - -train accuracy: 0.606069\n",
      "epoch: 384 - cost: 1.7906 mse:  69.0218706893 - -train accuracy: 0.664626\n",
      "epoch: 385 - cost: 1.28166 mse:  75.2808718033 - -train accuracy: 0.606335\n",
      "epoch: 386 - cost: 1.78016 mse:  69.0707615667 - -train accuracy: 0.66436\n",
      "epoch: 387 - cost: 1.27753 mse:  75.3590843345 - -train accuracy: 0.605536\n",
      "epoch: 388 - cost: 1.77538 mse:  69.1983727889 - -train accuracy: 0.664626\n",
      "epoch: 389 - cost: 1.27213 mse:  75.4485448667 - -train accuracy: 0.606069\n",
      "epoch: 390 - cost: 1.76694 mse:  69.2849210858 - -train accuracy: 0.664626\n",
      "epoch: 391 - cost: 1.26702 mse:  75.5412176473 - -train accuracy: 0.606069\n",
      "epoch: 392 - cost: 1.75874 mse:  69.3598002429 - -train accuracy: 0.664626\n",
      "epoch: 393 - cost: 1.26137 mse:  75.5961197038 - -train accuracy: 0.605802\n",
      "epoch: 394 - cost: 1.74925 mse:  69.4332732484 - -train accuracy: 0.664626\n",
      "epoch: 395 - cost: 1.25546 mse:  75.6465925195 - -train accuracy: 0.607133\n",
      "epoch: 396 - cost: 1.73939 mse:  69.4738366026 - -train accuracy: 0.665158\n",
      "epoch: 397 - cost: 1.25046 mse:  75.6745863884 - -train accuracy: 0.607666\n",
      "epoch: 398 - cost: 1.73116 mse:  69.5233990937 - -train accuracy: 0.664892\n",
      "epoch: 399 - cost: 1.24533 mse:  75.7397759229 - -train accuracy: 0.608198\n",
      "epoch: 400 - cost: 1.72248 mse:  69.5707774877 - -train accuracy: 0.665158\n",
      "epoch: 401 - cost: 1.23968 mse:  75.7943399089 - -train accuracy: 0.610061\n",
      "epoch: 402 - cost: 1.71249 mse:  69.6210041579 - -train accuracy: 0.665158\n",
      "epoch: 403 - cost: 1.23476 mse:  75.839144902 - -train accuracy: 0.610061\n",
      "epoch: 404 - cost: 1.70609 mse:  69.678207299 - -train accuracy: 0.665957\n",
      "epoch: 405 - cost: 1.23122 mse:  75.8905288369 - -train accuracy: 0.610327\n",
      "epoch: 406 - cost: 1.70114 mse:  69.7367080235 - -train accuracy: 0.666223\n",
      "epoch: 407 - cost: 1.22738 mse:  75.9533031195 - -train accuracy: 0.610327\n",
      "epoch: 408 - cost: 1.69366 mse:  69.7717151217 - -train accuracy: 0.665957\n",
      "epoch: 409 - cost: 1.22285 mse:  75.9660610886 - -train accuracy: 0.610594\n",
      "epoch: 410 - cost: 1.68557 mse:  69.8069272004 - -train accuracy: 0.666755\n",
      "epoch: 411 - cost: 1.21733 mse:  75.9914869467 - -train accuracy: 0.610594\n",
      "epoch: 412 - cost: 1.67496 mse:  69.8276210671 - -train accuracy: 0.667554\n",
      "epoch: 413 - cost: 1.21204 mse:  76.0407200228 - -train accuracy: 0.611392\n",
      "epoch: 414 - cost: 1.66611 mse:  69.8653592979 - -train accuracy: 0.667554\n",
      "epoch: 415 - cost: 1.20683 mse:  76.0944122976 - -train accuracy: 0.611392\n",
      "epoch: 416 - cost: 1.65945 mse:  69.928908188 - -train accuracy: 0.668086\n",
      "epoch: 417 - cost: 1.20281 mse:  76.1442886952 - -train accuracy: 0.611392\n",
      "epoch: 418 - cost: 1.65301 mse:  69.9756987335 - -train accuracy: 0.66782\n",
      "epoch: 419 - cost: 1.19827 mse:  76.1912048872 - -train accuracy: 0.611658\n",
      "epoch: 420 - cost: 1.64588 mse:  70.0286256496 - -train accuracy: 0.66782\n",
      "epoch: 421 - cost: 1.19353 mse:  76.2557920527 - -train accuracy: 0.612989\n",
      "epoch: 422 - cost: 1.63764 mse:  70.0964889499 - -train accuracy: 0.668352\n",
      "epoch: 423 - cost: 1.18905 mse:  76.3253391463 - -train accuracy: 0.613788\n",
      "epoch: 424 - cost: 1.63096 mse:  70.1673818588 - -train accuracy: 0.668885\n",
      "epoch: 425 - cost: 1.18465 mse:  76.3855420333 - -train accuracy: 0.613255\n",
      "epoch: 426 - cost: 1.62618 mse:  70.2615977541 - -train accuracy: 0.669151\n",
      "epoch: 427 - cost: 1.18101 mse:  76.4768170661 - -train accuracy: 0.613788\n",
      "epoch: 428 - cost: 1.62028 mse:  70.356904822 - -train accuracy: 0.669151\n",
      "epoch: 429 - cost: 1.1757 mse:  76.5789713794 - -train accuracy: 0.614054\n",
      "epoch: 430 - cost: 1.60933 mse:  70.4407601193 - -train accuracy: 0.670216\n",
      "epoch: 431 - cost: 1.16982 mse:  76.6631675532 - -train accuracy: 0.615385\n",
      "epoch: 432 - cost: 1.59869 mse:  70.5277189445 - -train accuracy: 0.670482\n",
      "epoch: 433 - cost: 1.16545 mse:  76.7981205889 - -train accuracy: 0.616183\n",
      "epoch: 434 - cost: 1.59065 mse:  70.6507586193 - -train accuracy: 0.671014\n",
      "epoch: 435 - cost: 1.1611 mse:  76.9531674447 - -train accuracy: 0.616715\n",
      "epoch: 436 - cost: 1.58247 mse:  70.8177394942 - -train accuracy: 0.67128\n",
      "epoch: 437 - cost: 1.15627 mse:  77.1508232195 - -train accuracy: 0.616982\n",
      "epoch: 438 - cost: 1.57498 mse:  71.0215588493 - -train accuracy: 0.672079\n",
      "epoch: 439 - cost: 1.15134 mse:  77.3703336975 - -train accuracy: 0.61778\n",
      "epoch: 440 - cost: 1.56635 mse:  71.1936822706 - -train accuracy: 0.672345\n",
      "epoch: 441 - cost: 1.14679 mse:  77.5428761266 - -train accuracy: 0.617248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 442 - cost: 1.55934 mse:  71.3812191396 - -train accuracy: 0.672345\n",
      "epoch: 443 - cost: 1.14246 mse:  77.7508041681 - -train accuracy: 0.617514\n",
      "epoch: 444 - cost: 1.5524 mse:  71.571778852 - -train accuracy: 0.672611\n",
      "epoch: 445 - cost: 1.13864 mse:  77.9321418724 - -train accuracy: 0.61778\n",
      "epoch: 446 - cost: 1.54616 mse:  71.7391254862 - -train accuracy: 0.672877\n",
      "epoch: 447 - cost: 1.13446 mse:  78.0945285776 - -train accuracy: 0.61778\n",
      "epoch: 448 - cost: 1.5404 mse:  71.8992699115 - -train accuracy: 0.673143\n",
      "epoch: 449 - cost: 1.13116 mse:  78.2620298508 - -train accuracy: 0.617248\n",
      "epoch: 450 - cost: 1.53518 mse:  72.0852983208 - -train accuracy: 0.67341\n",
      "epoch: 451 - cost: 1.12651 mse:  78.4335827319 - -train accuracy: 0.617514\n",
      "epoch: 452 - cost: 1.52673 mse:  72.2427048296 - -train accuracy: 0.67341\n",
      "epoch: 453 - cost: 1.12234 mse:  78.6191530621 - -train accuracy: 0.617514\n",
      "epoch: 454 - cost: 1.51991 mse:  72.429258063 - -train accuracy: 0.67341\n",
      "epoch: 455 - cost: 1.11816 mse:  78.8146399484 - -train accuracy: 0.617248\n",
      "epoch: 456 - cost: 1.51444 mse:  72.6310828109 - -train accuracy: 0.67341\n",
      "epoch: 457 - cost: 1.11473 mse:  79.0106051573 - -train accuracy: 0.616449\n",
      "epoch: 458 - cost: 1.51024 mse:  72.8414438788 - -train accuracy: 0.67341\n",
      "epoch: 459 - cost: 1.1115 mse:  79.230511457 - -train accuracy: 0.616982\n",
      "epoch: 460 - cost: 1.50467 mse:  73.0504142022 - -train accuracy: 0.673676\n",
      "epoch: 461 - cost: 1.10821 mse:  79.4769912723 - -train accuracy: 0.617514\n",
      "epoch: 462 - cost: 1.49863 mse:  73.2847931496 - -train accuracy: 0.673676\n",
      "epoch: 463 - cost: 1.10416 mse:  79.73369737 - -train accuracy: 0.618579\n",
      "epoch: 464 - cost: 1.49082 mse:  73.5080650953 - -train accuracy: 0.673942\n",
      "epoch: 465 - cost: 1.09979 mse:  79.9780999479 - -train accuracy: 0.618579\n",
      "epoch: 466 - cost: 1.48387 mse:  73.7368156436 - -train accuracy: 0.674208\n",
      "epoch: 467 - cost: 1.09577 mse:  80.1749003871 - -train accuracy: 0.61778\n",
      "epoch: 468 - cost: 1.47778 mse:  73.9274777594 - -train accuracy: 0.674208\n",
      "epoch: 469 - cost: 1.09202 mse:  80.3503493438 - -train accuracy: 0.61778\n",
      "epoch: 470 - cost: 1.47243 mse:  74.076272757 - -train accuracy: 0.674474\n",
      "epoch: 471 - cost: 1.08941 mse:  80.5189406809 - -train accuracy: 0.61778\n",
      "epoch: 472 - cost: 1.46866 mse:  74.2351735523 - -train accuracy: 0.674208\n",
      "epoch: 473 - cost: 1.08577 mse:  80.6654175037 - -train accuracy: 0.618046\n",
      "epoch: 474 - cost: 1.46171 mse:  74.3789256653 - -train accuracy: 0.67474\n",
      "epoch: 475 - cost: 1.08277 mse:  80.7928637922 - -train accuracy: 0.618046\n",
      "epoch: 476 - cost: 1.45816 mse:  74.5130957326 - -train accuracy: 0.675007\n",
      "epoch: 477 - cost: 1.0793 mse:  80.9162926431 - -train accuracy: 0.618046\n",
      "epoch: 478 - cost: 1.45303 mse:  74.6446705973 - -train accuracy: 0.675273\n",
      "epoch: 479 - cost: 1.0761 mse:  81.0235889059 - -train accuracy: 0.618312\n",
      "epoch: 480 - cost: 1.4474 mse:  74.768261408 - -train accuracy: 0.675273\n",
      "epoch: 481 - cost: 1.07196 mse:  81.1066503734 - -train accuracy: 0.618579\n",
      "epoch: 482 - cost: 1.44045 mse:  74.8663246482 - -train accuracy: 0.676604\n",
      "epoch: 483 - cost: 1.06836 mse:  81.1924413064 - -train accuracy: 0.619111\n",
      "epoch: 484 - cost: 1.43459 mse:  74.9783226131 - -train accuracy: 0.676337\n",
      "epoch: 485 - cost: 1.06428 mse:  81.2885346985 - -train accuracy: 0.620442\n",
      "epoch: 486 - cost: 1.42632 mse:  75.0580779072 - -train accuracy: 0.676604\n",
      "epoch: 487 - cost: 1.06056 mse:  81.3632837426 - -train accuracy: 0.620442\n",
      "epoch: 488 - cost: 1.42031 mse:  75.1746601414 - -train accuracy: 0.677668\n",
      "epoch: 489 - cost: 1.05669 mse:  81.4824292071 - -train accuracy: 0.622039\n",
      "epoch: 490 - cost: 1.41407 mse:  75.2892093458 - -train accuracy: 0.678201\n",
      "epoch: 491 - cost: 1.05438 mse:  81.5923844609 - -train accuracy: 0.620974\n",
      "epoch: 492 - cost: 1.41064 mse:  75.4105749993 - -train accuracy: 0.678467\n",
      "epoch: 493 - cost: 1.05126 mse:  81.7192355061 - -train accuracy: 0.620708\n",
      "epoch: 494 - cost: 1.40559 mse:  75.5260341799 - -train accuracy: 0.678733\n",
      "epoch: 495 - cost: 1.04842 mse:  81.8518720145 - -train accuracy: 0.620442\n",
      "epoch: 496 - cost: 1.401 mse:  75.6838065111 - -train accuracy: 0.679265\n",
      "epoch: 497 - cost: 1.04432 mse:  81.9963867444 - -train accuracy: 0.62124\n",
      "epoch: 498 - cost: 1.39224 mse:  75.8164765876 - -train accuracy: 0.679532\n",
      "epoch: 499 - cost: 1.04052 mse:  82.1254522973 - -train accuracy: 0.621773\n",
      "epoch: 500 - cost: 1.38603 mse:  75.9635795605 - -train accuracy: 0.680596\n",
      "epoch: 501 - cost: 1.03755 mse:  82.2911988603 - -train accuracy: 0.621773\n",
      "epoch: 502 - cost: 1.38116 mse:  76.131523253 - -train accuracy: 0.680862\n",
      "epoch: 503 - cost: 1.03356 mse:  82.4429258442 - -train accuracy: 0.622305\n",
      "epoch: 504 - cost: 1.37289 mse:  76.2781679692 - -train accuracy: 0.680596\n",
      "epoch: 505 - cost: 1.02967 mse:  82.5946410644 - -train accuracy: 0.623636\n",
      "epoch: 506 - cost: 1.36605 mse:  76.4259819251 - -train accuracy: 0.681129\n",
      "epoch: 507 - cost: 1.02634 mse:  82.7516649018 - -train accuracy: 0.624434\n",
      "epoch: 508 - cost: 1.36027 mse:  76.5693782036 - -train accuracy: 0.681129\n",
      "epoch: 509 - cost: 1.02332 mse:  82.8754218141 - -train accuracy: 0.624967\n",
      "epoch: 510 - cost: 1.35482 mse:  76.6964900623 - -train accuracy: 0.681129\n",
      "epoch: 511 - cost: 1.02085 mse:  83.0363986754 - -train accuracy: 0.624701\n",
      "epoch: 512 - cost: 1.35035 mse:  76.8563007326 - -train accuracy: 0.681395\n",
      "epoch: 513 - cost: 1.01828 mse:  83.1879856823 - -train accuracy: 0.624434\n",
      "epoch: 514 - cost: 1.34683 mse:  76.9886396861 - -train accuracy: 0.681395\n",
      "epoch: 515 - cost: 1.01591 mse:  83.3123010887 - -train accuracy: 0.623636\n",
      "epoch: 516 - cost: 1.34467 mse:  77.1626108083 - -train accuracy: 0.680862\n",
      "epoch: 517 - cost: 1.01352 mse:  83.474927241 - -train accuracy: 0.623636\n",
      "epoch: 518 - cost: 1.3408 mse:  77.3168939137 - -train accuracy: 0.680862\n",
      "epoch: 519 - cost: 1.01106 mse:  83.6241804531 - -train accuracy: 0.624168\n",
      "epoch: 520 - cost: 1.33613 mse:  77.4527540144 - -train accuracy: 0.682193\n",
      "epoch: 521 - cost: 1.00777 mse:  83.7513950927 - -train accuracy: 0.623902\n",
      "epoch: 522 - cost: 1.33107 mse:  77.579599831 - -train accuracy: 0.682459\n",
      "epoch: 523 - cost: 1.00568 mse:  83.9080563703 - -train accuracy: 0.623902\n",
      "epoch: 524 - cost: 1.32779 mse:  77.7324366395 - -train accuracy: 0.682193\n",
      "epoch: 525 - cost: 1.0031 mse:  84.0842102363 - -train accuracy: 0.624168\n",
      "epoch: 526 - cost: 1.3245 mse:  77.9164069115 - -train accuracy: 0.682193\n",
      "epoch: 527 - cost: 1.00082 mse:  84.2825252797 - -train accuracy: 0.624434\n",
      "epoch: 528 - cost: 1.32095 mse:  78.0888420543 - -train accuracy: 0.682459\n",
      "epoch: 529 - cost: 0.998092 mse:  84.4893523081 - -train accuracy: 0.624434\n",
      "epoch: 530 - cost: 1.31499 mse:  78.261605169 - -train accuracy: 0.682459\n",
      "epoch: 531 - cost: 0.994676 mse:  84.663705209 - -train accuracy: 0.624701\n",
      "epoch: 532 - cost: 1.30976 mse:  78.4172892876 - -train accuracy: 0.682726\n",
      "epoch: 533 - cost: 0.991748 mse:  84.7967810846 - -train accuracy: 0.625499\n",
      "epoch: 534 - cost: 1.30571 mse:  78.5546331567 - -train accuracy: 0.683258\n",
      "epoch: 535 - cost: 0.989546 mse:  84.9416279972 - -train accuracy: 0.624967\n",
      "epoch: 536 - cost: 1.30287 mse:  78.6954058689 - -train accuracy: 0.68379\n",
      "epoch: 537 - cost: 0.988082 mse:  85.0782318718 - -train accuracy: 0.625233\n",
      "epoch: 538 - cost: 1.30066 mse:  78.824750189 - -train accuracy: 0.683524\n",
      "epoch: 539 - cost: 0.985354 mse:  85.1984871732 - -train accuracy: 0.625765\n",
      "epoch: 540 - cost: 1.29422 mse:  78.9215389578 - -train accuracy: 0.683524\n",
      "epoch: 541 - cost: 0.98187 mse:  85.2904630631 - -train accuracy: 0.625765\n",
      "epoch: 542 - cost: 1.28823 mse:  79.0082862028 - -train accuracy: 0.684056\n",
      "epoch: 543 - cost: 0.978678 mse:  85.3632729252 - -train accuracy: 0.626031\n",
      "epoch: 544 - cost: 1.28259 mse:  79.0729395316 - -train accuracy: 0.684589\n",
      "epoch: 545 - cost: 0.976199 mse:  85.4197152851 - -train accuracy: 0.625765\n",
      "epoch: 546 - cost: 1.27854 mse:  79.1193343127 - -train accuracy: 0.685121\n",
      "epoch: 547 - cost: 0.973567 mse:  85.4786505154 - -train accuracy: 0.626031\n",
      "epoch: 548 - cost: 1.27356 mse:  79.1950002558 - -train accuracy: 0.685653\n",
      "epoch: 549 - cost: 0.970247 mse:  85.5409057599 - -train accuracy: 0.627362\n",
      "epoch: 550 - cost: 1.2681 mse:  79.2597663361 - -train accuracy: 0.686186\n",
      "epoch: 551 - cost: 0.96788 mse:  85.5773462835 - -train accuracy: 0.626564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 552 - cost: 1.26575 mse:  79.3305642677 - -train accuracy: 0.686452\n",
      "epoch: 553 - cost: 0.965839 mse:  85.6510655101 - -train accuracy: 0.626031\n",
      "epoch: 554 - cost: 1.26203 mse:  79.4179724578 - -train accuracy: 0.686452\n",
      "epoch: 555 - cost: 0.963512 mse:  85.7295840322 - -train accuracy: 0.626298\n",
      "epoch: 556 - cost: 1.25764 mse:  79.4967486864 - -train accuracy: 0.686984\n",
      "epoch: 557 - cost: 0.960846 mse:  85.7940319951 - -train accuracy: 0.626564\n",
      "epoch: 558 - cost: 1.25274 mse:  79.5706629004 - -train accuracy: 0.687517\n",
      "epoch: 559 - cost: 0.958282 mse:  85.8531816453 - -train accuracy: 0.626298\n",
      "epoch: 560 - cost: 1.2492 mse:  79.6523759459 - -train accuracy: 0.68725\n",
      "epoch: 561 - cost: 0.95674 mse:  85.9139004149 - -train accuracy: 0.626564\n",
      "epoch: 562 - cost: 1.24731 mse:  79.7510986953 - -train accuracy: 0.68725\n",
      "epoch: 563 - cost: 0.954567 mse:  86.0129126665 - -train accuracy: 0.627096\n",
      "epoch: 564 - cost: 1.24252 mse:  79.8223411626 - -train accuracy: 0.68725\n",
      "epoch: 565 - cost: 0.951565 mse:  86.0671982927 - -train accuracy: 0.627895\n",
      "epoch: 566 - cost: 1.23739 mse:  79.8778471142 - -train accuracy: 0.687783\n",
      "epoch: 567 - cost: 0.94897 mse:  86.1184106991 - -train accuracy: 0.628161\n",
      "epoch: 568 - cost: 1.23263 mse:  79.9351458088 - -train accuracy: 0.688581\n",
      "epoch: 569 - cost: 0.945404 mse:  86.1421099961 - -train accuracy: 0.628693\n",
      "epoch: 570 - cost: 1.22606 mse:  79.9621540048 - -train accuracy: 0.688847\n",
      "epoch: 571 - cost: 0.942836 mse:  86.1607201326 - -train accuracy: 0.629225\n",
      "epoch: 572 - cost: 1.22174 mse:  79.9917236243 - -train accuracy: 0.689114\n",
      "epoch: 573 - cost: 0.94076 mse:  86.2009219911 - -train accuracy: 0.628959\n",
      "epoch: 574 - cost: 1.21757 mse:  80.0422885225 - -train accuracy: 0.68938\n",
      "epoch: 575 - cost: 0.937996 mse:  86.2466279555 - -train accuracy: 0.629225\n",
      "epoch: 576 - cost: 1.21232 mse:  80.0861541295 - -train accuracy: 0.68938\n",
      "epoch: 577 - cost: 0.9356 mse:  86.2739138834 - -train accuracy: 0.629492\n",
      "epoch: 578 - cost: 1.20791 mse:  80.1307413263 - -train accuracy: 0.689646\n",
      "epoch: 579 - cost: 0.933075 mse:  86.302185651 - -train accuracy: 0.629225\n",
      "epoch: 580 - cost: 1.20348 mse:  80.1807229066 - -train accuracy: 0.690178\n",
      "epoch: 581 - cost: 0.930447 mse:  86.3560219909 - -train accuracy: 0.63029\n",
      "epoch: 582 - cost: 1.19924 mse:  80.2391503483 - -train accuracy: 0.690178\n",
      "epoch: 583 - cost: 0.928548 mse:  86.4087364425 - -train accuracy: 0.63029\n",
      "epoch: 584 - cost: 1.19604 mse:  80.3051492894 - -train accuracy: 0.690445\n",
      "epoch: 585 - cost: 0.926118 mse:  86.4664798018 - -train accuracy: 0.63029\n",
      "epoch: 586 - cost: 1.19168 mse:  80.3818504594 - -train accuracy: 0.690445\n",
      "epoch: 587 - cost: 0.924272 mse:  86.5450080214 - -train accuracy: 0.630556\n",
      "epoch: 588 - cost: 1.18795 mse:  80.4541196716 - -train accuracy: 0.690711\n",
      "epoch: 589 - cost: 0.922371 mse:  86.611576894 - -train accuracy: 0.630822\n",
      "epoch: 590 - cost: 1.18378 mse:  80.5076501669 - -train accuracy: 0.690977\n",
      "epoch: 591 - cost: 0.919931 mse:  86.6458635604 - -train accuracy: 0.630822\n",
      "epoch: 592 - cost: 1.17968 mse:  80.5661062745 - -train accuracy: 0.690977\n",
      "epoch: 593 - cost: 0.917941 mse:  86.7051721399 - -train accuracy: 0.631355\n",
      "epoch: 594 - cost: 1.1758 mse:  80.6484849057 - -train accuracy: 0.690711\n",
      "epoch: 595 - cost: 0.915627 mse:  86.7767690738 - -train accuracy: 0.632153\n",
      "epoch: 596 - cost: 1.17145 mse:  80.7291890842 - -train accuracy: 0.690711\n",
      "epoch: 597 - cost: 0.913393 mse:  86.8432901989 - -train accuracy: 0.631887\n",
      "epoch: 598 - cost: 1.16756 mse:  80.8134640124 - -train accuracy: 0.690977\n",
      "epoch: 599 - cost: 0.91104 mse:  86.9239797315 - -train accuracy: 0.632952\n",
      "epoch: 600 - cost: 1.16368 mse:  80.9313165149 - -train accuracy: 0.690711\n",
      "epoch: 601 - cost: 0.908659 mse:  87.025931238 - -train accuracy: 0.633218\n",
      "epoch: 602 - cost: 1.16029 mse:  81.0505940012 - -train accuracy: 0.691243\n",
      "epoch: 603 - cost: 0.906571 mse:  87.1458174464 - -train accuracy: 0.633218\n",
      "epoch: 604 - cost: 1.15739 mse:  81.1631127414 - -train accuracy: 0.691243\n",
      "epoch: 605 - cost: 0.904726 mse:  87.2563161098 - -train accuracy: 0.633484\n",
      "epoch: 606 - cost: 1.15417 mse:  81.2597830418 - -train accuracy: 0.691775\n",
      "epoch: 607 - cost: 0.902541 mse:  87.3349531717 - -train accuracy: 0.633484\n",
      "epoch: 608 - cost: 1.15044 mse:  81.3768120096 - -train accuracy: 0.692042\n",
      "epoch: 609 - cost: 0.900462 mse:  87.4422174769 - -train accuracy: 0.63375\n",
      "epoch: 610 - cost: 1.14625 mse:  81.4991441394 - -train accuracy: 0.692308\n",
      "epoch: 611 - cost: 0.897561 mse:  87.5565077734 - -train accuracy: 0.635081\n",
      "epoch: 612 - cost: 1.14042 mse:  81.6130290962 - -train accuracy: 0.692574\n",
      "epoch: 613 - cost: 0.894694 mse:  87.6509084976 - -train accuracy: 0.635347\n",
      "epoch: 614 - cost: 1.135 mse:  81.7154350592 - -train accuracy: 0.693106\n",
      "epoch: 615 - cost: 0.892326 mse:  87.7500939427 - -train accuracy: 0.635347\n",
      "epoch: 616 - cost: 1.1304 mse:  81.8327498296 - -train accuracy: 0.693372\n",
      "epoch: 617 - cost: 0.889536 mse:  87.8872779974 - -train accuracy: 0.636412\n",
      "epoch: 618 - cost: 1.12507 mse:  81.964384595 - -train accuracy: 0.693905\n",
      "epoch: 619 - cost: 0.88744 mse:  88.0078389377 - -train accuracy: 0.636412\n",
      "epoch: 620 - cost: 1.12149 mse:  82.1032143918 - -train accuracy: 0.693905\n",
      "epoch: 621 - cost: 0.884946 mse:  88.1398950634 - -train accuracy: 0.637743\n",
      "epoch: 622 - cost: 1.11608 mse:  82.244924159 - -train accuracy: 0.694171\n",
      "epoch: 623 - cost: 0.881473 mse:  88.2695445476 - -train accuracy: 0.639872\n",
      "epoch: 624 - cost: 1.10967 mse:  82.3783451044 - -train accuracy: 0.694171\n",
      "epoch: 625 - cost: 0.878477 mse:  88.4075033858 - -train accuracy: 0.640937\n",
      "epoch: 626 - cost: 1.10441 mse:  82.5201454639 - -train accuracy: 0.694171\n",
      "epoch: 627 - cost: 0.875591 mse:  88.5359265589 - -train accuracy: 0.640937\n",
      "epoch: 628 - cost: 1.09979 mse:  82.630070271 - -train accuracy: 0.694703\n",
      "epoch: 629 - cost: 0.87362 mse:  88.6321603481 - -train accuracy: 0.641203\n",
      "epoch: 630 - cost: 1.09651 mse:  82.7443518235 - -train accuracy: 0.694969\n",
      "epoch: 631 - cost: 0.871257 mse:  88.7463203409 - -train accuracy: 0.642002\n",
      "epoch: 632 - cost: 1.09219 mse:  82.8724966996 - -train accuracy: 0.694969\n",
      "epoch: 633 - cost: 0.868824 mse:  88.8467452227 - -train accuracy: 0.642268\n",
      "epoch: 634 - cost: 1.088 mse:  82.9836631648 - -train accuracy: 0.695768\n",
      "epoch: 635 - cost: 0.866662 mse:  88.9511192985 - -train accuracy: 0.642534\n",
      "epoch: 636 - cost: 1.08436 mse:  83.0963904274 - -train accuracy: 0.696034\n",
      "epoch: 637 - cost: 0.864786 mse:  89.0477766838 - -train accuracy: 0.6428\n",
      "epoch: 638 - cost: 1.08105 mse:  83.2002029972 - -train accuracy: 0.6963\n",
      "epoch: 639 - cost: 0.863075 mse:  89.1622397525 - -train accuracy: 0.643066\n",
      "epoch: 640 - cost: 1.07757 mse:  83.2956967481 - -train accuracy: 0.696833\n",
      "epoch: 641 - cost: 0.861263 mse:  89.241428075 - -train accuracy: 0.6428\n",
      "epoch: 642 - cost: 1.07449 mse:  83.4132572745 - -train accuracy: 0.697099\n",
      "epoch: 643 - cost: 0.858629 mse:  89.3291672854 - -train accuracy: 0.643865\n",
      "epoch: 644 - cost: 1.06958 mse:  83.495864007 - -train accuracy: 0.697365\n",
      "epoch: 645 - cost: 0.856547 mse:  89.4002164115 - -train accuracy: 0.643599\n",
      "epoch: 646 - cost: 1.06605 mse:  83.603276142 - -train accuracy: 0.697631\n",
      "epoch: 647 - cost: 0.854226 mse:  89.5097002724 - -train accuracy: 0.645196\n",
      "epoch: 648 - cost: 1.06179 mse:  83.7090381295 - -train accuracy: 0.69843\n",
      "epoch: 649 - cost: 0.852197 mse:  89.5796646371 - -train accuracy: 0.644929\n",
      "epoch: 650 - cost: 1.05907 mse:  83.818210073 - -train accuracy: 0.69843\n",
      "epoch: 651 - cost: 0.850344 mse:  89.6868974914 - -train accuracy: 0.645196\n",
      "epoch: 652 - cost: 1.05588 mse:  83.9345715759 - -train accuracy: 0.69843\n",
      "epoch: 653 - cost: 0.848584 mse:  89.8043964181 - -train accuracy: 0.645462\n",
      "epoch: 654 - cost: 1.05218 mse:  84.0564773953 - -train accuracy: 0.698696\n",
      "epoch: 655 - cost: 0.846102 mse:  89.9112174795 - -train accuracy: 0.645994\n",
      "epoch: 656 - cost: 1.04741 mse:  84.1713805307 - -train accuracy: 0.698962\n",
      "epoch: 657 - cost: 0.843516 mse:  90.0121903786 - -train accuracy: 0.646526\n",
      "epoch: 658 - cost: 1.04299 mse:  84.3014144217 - -train accuracy: 0.700027\n",
      "epoch: 659 - cost: 0.841117 mse:  90.1223723867 - -train accuracy: 0.646526\n",
      "epoch: 660 - cost: 1.03923 mse:  84.4246828214 - -train accuracy: 0.700293\n",
      "epoch: 661 - cost: 0.839201 mse:  90.2213447049 - -train accuracy: 0.646526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 662 - cost: 1.03563 mse:  84.5493681829 - -train accuracy: 0.701091\n",
      "epoch: 663 - cost: 0.836733 mse:  90.3188583514 - -train accuracy: 0.647325\n",
      "epoch: 664 - cost: 1.0314 mse:  84.66195877 - -train accuracy: 0.700825\n",
      "epoch: 665 - cost: 0.834181 mse:  90.4103766555 - -train accuracy: 0.647591\n",
      "epoch: 666 - cost: 1.02728 mse:  84.7637179401 - -train accuracy: 0.701357\n",
      "epoch: 667 - cost: 0.832085 mse:  90.4870264874 - -train accuracy: 0.648124\n",
      "epoch: 668 - cost: 1.02378 mse:  84.8555252004 - -train accuracy: 0.702156\n",
      "epoch: 669 - cost: 0.829999 mse:  90.5592233308 - -train accuracy: 0.647591\n",
      "epoch: 670 - cost: 1.02037 mse:  84.9374377194 - -train accuracy: 0.702688\n",
      "epoch: 671 - cost: 0.828217 mse:  90.6261563011 - -train accuracy: 0.647857\n",
      "epoch: 672 - cost: 1.01721 mse:  85.0177242567 - -train accuracy: 0.703221\n",
      "epoch: 673 - cost: 0.826428 mse:  90.7177973836 - -train accuracy: 0.64839\n",
      "epoch: 674 - cost: 1.01408 mse:  85.1138119785 - -train accuracy: 0.703487\n",
      "epoch: 675 - cost: 0.824642 mse:  90.7906981551 - -train accuracy: 0.649188\n",
      "epoch: 676 - cost: 1.01104 mse:  85.2166307662 - -train accuracy: 0.703487\n",
      "epoch: 677 - cost: 0.822797 mse:  90.8728265919 - -train accuracy: 0.649188\n",
      "epoch: 678 - cost: 1.00802 mse:  85.2954487718 - -train accuracy: 0.703753\n",
      "epoch: 679 - cost: 0.821335 mse:  90.954402865 - -train accuracy: 0.649188\n",
      "epoch: 680 - cost: 1.00536 mse:  85.3906010429 - -train accuracy: 0.703753\n",
      "epoch: 681 - cost: 0.819687 mse:  91.030607432 - -train accuracy: 0.648656\n",
      "epoch: 682 - cost: 1.0023 mse:  85.4740532254 - -train accuracy: 0.703487\n",
      "epoch: 683 - cost: 0.817805 mse:  91.0992414173 - -train accuracy: 0.649454\n",
      "epoch: 684 - cost: 0.999092 mse:  85.5579236947 - -train accuracy: 0.703753\n",
      "epoch: 685 - cost: 0.816099 mse:  91.173849515 - -train accuracy: 0.649987\n",
      "epoch: 686 - cost: 0.9959 mse:  85.669715879 - -train accuracy: 0.704019\n",
      "epoch: 687 - cost: 0.814082 mse:  91.2712348031 - -train accuracy: 0.650253\n",
      "epoch: 688 - cost: 0.992479 mse:  85.769969696 - -train accuracy: 0.704019\n",
      "epoch: 689 - cost: 0.812362 mse:  91.3566804973 - -train accuracy: 0.650253\n",
      "epoch: 690 - cost: 0.989441 mse:  85.8755075274 - -train accuracy: 0.704019\n",
      "epoch: 691 - cost: 0.810255 mse:  91.4492148408 - -train accuracy: 0.650519\n",
      "epoch: 692 - cost: 0.986035 mse:  85.9895142787 - -train accuracy: 0.703753\n",
      "epoch: 693 - cost: 0.808523 mse:  91.5481252542 - -train accuracy: 0.651318\n",
      "epoch: 694 - cost: 0.983079 mse:  86.1211074904 - -train accuracy: 0.704285\n",
      "epoch: 695 - cost: 0.806681 mse:  91.6654007512 - -train accuracy: 0.651318\n",
      "epoch: 696 - cost: 0.979674 mse:  86.2434623766 - -train accuracy: 0.704552\n",
      "epoch: 697 - cost: 0.804719 mse:  91.7754247817 - -train accuracy: 0.650785\n",
      "epoch: 698 - cost: 0.976105 mse:  86.387285388 - -train accuracy: 0.704552\n",
      "epoch: 699 - cost: 0.802675 mse:  91.9113128152 - -train accuracy: 0.650785\n",
      "epoch: 700 - cost: 0.972528 mse:  86.5351114674 - -train accuracy: 0.705084\n",
      "epoch: 701 - cost: 0.800587 mse:  92.042511426 - -train accuracy: 0.651051\n",
      "epoch: 702 - cost: 0.968883 mse:  86.6526078177 - -train accuracy: 0.705084\n",
      "epoch: 703 - cost: 0.798692 mse:  92.1653060479 - -train accuracy: 0.651051\n",
      "epoch: 704 - cost: 0.965426 mse:  86.7894214795 - -train accuracy: 0.70535\n",
      "epoch: 705 - cost: 0.796619 mse:  92.2886358526 - -train accuracy: 0.651584\n",
      "epoch: 706 - cost: 0.961902 mse:  86.9275014536 - -train accuracy: 0.70535\n",
      "epoch: 707 - cost: 0.794845 mse:  92.427178082 - -train accuracy: 0.651584\n",
      "epoch: 708 - cost: 0.958361 mse:  87.0886470688 - -train accuracy: 0.705882\n",
      "epoch: 709 - cost: 0.792198 mse:  92.5687398735 - -train accuracy: 0.653447\n",
      "epoch: 710 - cost: 0.953988 mse:  87.2322202081 - -train accuracy: 0.705882\n",
      "epoch: 711 - cost: 0.790169 mse:  92.7053891083 - -train accuracy: 0.653979\n",
      "epoch: 712 - cost: 0.950993 mse:  87.3846418104 - -train accuracy: 0.705882\n",
      "epoch: 713 - cost: 0.788484 mse:  92.8371624273 - -train accuracy: 0.653713\n",
      "epoch: 714 - cost: 0.94861 mse:  87.5305938638 - -train accuracy: 0.706415\n",
      "epoch: 715 - cost: 0.786831 mse:  92.9810382065 - -train accuracy: 0.653713\n",
      "epoch: 716 - cost: 0.945532 mse:  87.6565395251 - -train accuracy: 0.707479\n",
      "epoch: 717 - cost: 0.785171 mse:  93.0978537318 - -train accuracy: 0.653979\n",
      "epoch: 718 - cost: 0.942754 mse:  87.7626017591 - -train accuracy: 0.708012\n",
      "epoch: 719 - cost: 0.783609 mse:  93.1783762964 - -train accuracy: 0.654512\n",
      "epoch: 720 - cost: 0.940385 mse:  87.8723112904 - -train accuracy: 0.708012\n",
      "epoch: 721 - cost: 0.782075 mse:  93.2808469513 - -train accuracy: 0.654512\n",
      "epoch: 722 - cost: 0.937952 mse:  88.0101833639 - -train accuracy: 0.708544\n",
      "epoch: 723 - cost: 0.780577 mse:  93.423249165 - -train accuracy: 0.655044\n",
      "epoch: 724 - cost: 0.935208 mse:  88.1612787482 - -train accuracy: 0.70881\n",
      "epoch: 725 - cost: 0.778767 mse:  93.5900272722 - -train accuracy: 0.654778\n",
      "epoch: 726 - cost: 0.931673 mse:  88.3362973042 - -train accuracy: 0.709343\n",
      "epoch: 727 - cost: 0.776636 mse:  93.7458131057 - -train accuracy: 0.654245\n",
      "epoch: 728 - cost: 0.928184 mse:  88.4888930991 - -train accuracy: 0.709609\n",
      "epoch: 729 - cost: 0.774894 mse:  93.8841118626 - -train accuracy: 0.653979\n",
      "epoch: 730 - cost: 0.925569 mse:  88.641665649 - -train accuracy: 0.709875\n",
      "epoch: 731 - cost: 0.773162 mse:  94.0362992874 - -train accuracy: 0.654778\n",
      "epoch: 732 - cost: 0.922501 mse:  88.8010997755 - -train accuracy: 0.709875\n",
      "epoch: 733 - cost: 0.770975 mse:  94.1793654729 - -train accuracy: 0.655842\n",
      "epoch: 734 - cost: 0.918782 mse:  88.9480151759 - -train accuracy: 0.710141\n",
      "epoch: 735 - cost: 0.769059 mse:  94.3018833586 - -train accuracy: 0.656907\n",
      "epoch: 736 - cost: 0.915783 mse:  89.074520996 - -train accuracy: 0.710407\n",
      "epoch: 737 - cost: 0.767455 mse:  94.4268719414 - -train accuracy: 0.656641\n",
      "epoch: 738 - cost: 0.913085 mse:  89.2129045227 - -train accuracy: 0.710407\n",
      "epoch: 739 - cost: 0.765679 mse:  94.5724291372 - -train accuracy: 0.657972\n",
      "epoch: 740 - cost: 0.90978 mse:  89.3418920534 - -train accuracy: 0.71094\n",
      "epoch: 741 - cost: 0.763919 mse:  94.6795307653 - -train accuracy: 0.65877\n",
      "epoch: 742 - cost: 0.906944 mse:  89.4559929009 - -train accuracy: 0.711206\n",
      "epoch: 743 - cost: 0.762441 mse:  94.8103620907 - -train accuracy: 0.659303\n",
      "epoch: 744 - cost: 0.904276 mse:  89.612967349 - -train accuracy: 0.711472\n",
      "epoch: 745 - cost: 0.760587 mse:  94.9541631605 - -train accuracy: 0.659835\n",
      "epoch: 746 - cost: 0.901231 mse:  89.7715032762 - -train accuracy: 0.712004\n",
      "epoch: 747 - cost: 0.759055 mse:  95.1110736597 - -train accuracy: 0.659569\n",
      "epoch: 748 - cost: 0.898648 mse:  89.9211873856 - -train accuracy: 0.712004\n",
      "epoch: 749 - cost: 0.757573 mse:  95.2511626287 - -train accuracy: 0.659303\n",
      "epoch: 750 - cost: 0.896245 mse:  90.0747977303 - -train accuracy: 0.712537\n",
      "epoch: 751 - cost: 0.756056 mse:  95.3999423116 - -train accuracy: 0.659303\n",
      "epoch: 752 - cost: 0.893493 mse:  90.2172177505 - -train accuracy: 0.712537\n",
      "epoch: 753 - cost: 0.754241 mse:  95.5270407031 - -train accuracy: 0.659835\n",
      "epoch: 754 - cost: 0.890273 mse:  90.3472268522 - -train accuracy: 0.713335\n",
      "epoch: 755 - cost: 0.752302 mse:  95.6521024025 - -train accuracy: 0.660634\n",
      "epoch: 756 - cost: 0.88697 mse:  90.4674397346 - -train accuracy: 0.713335\n",
      "epoch: 757 - cost: 0.750477 mse:  95.7548972602 - -train accuracy: 0.6609\n",
      "epoch: 758 - cost: 0.884096 mse:  90.5939467483 - -train accuracy: 0.713069\n",
      "epoch: 759 - cost: 0.748903 mse:  95.8610953172 - -train accuracy: 0.6609\n",
      "epoch: 760 - cost: 0.881508 mse:  90.7225007977 - -train accuracy: 0.713069\n",
      "epoch: 761 - cost: 0.74741 mse:  95.9731083143 - -train accuracy: 0.661166\n",
      "epoch: 762 - cost: 0.878571 mse:  90.8520086748 - -train accuracy: 0.713069\n",
      "epoch: 763 - cost: 0.7453 mse:  96.0981826398 - -train accuracy: 0.661964\n",
      "epoch: 764 - cost: 0.874964 mse:  90.9637604289 - -train accuracy: 0.713069\n",
      "epoch: 765 - cost: 0.743568 mse:  96.1923286844 - -train accuracy: 0.661964\n",
      "epoch: 766 - cost: 0.872261 mse:  91.0852119632 - -train accuracy: 0.713069\n",
      "epoch: 767 - cost: 0.742065 mse:  96.3082367083 - -train accuracy: 0.661964\n",
      "epoch: 768 - cost: 0.869733 mse:  91.2215489158 - -train accuracy: 0.713601\n",
      "epoch: 769 - cost: 0.740504 mse:  96.4335876405 - -train accuracy: 0.66223\n",
      "epoch: 770 - cost: 0.867072 mse:  91.3484913321 - -train accuracy: 0.713867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 771 - cost: 0.738997 mse:  96.5372731834 - -train accuracy: 0.66223\n",
      "epoch: 772 - cost: 0.864682 mse:  91.4603246676 - -train accuracy: 0.713601\n",
      "epoch: 773 - cost: 0.737405 mse:  96.6348963831 - -train accuracy: 0.662497\n",
      "epoch: 774 - cost: 0.862023 mse:  91.5551299292 - -train accuracy: 0.7144\n",
      "epoch: 775 - cost: 0.735999 mse:  96.7069895643 - -train accuracy: 0.663029\n",
      "epoch: 776 - cost: 0.859957 mse:  91.6502270558 - -train accuracy: 0.714932\n",
      "epoch: 777 - cost: 0.734726 mse:  96.7882472222 - -train accuracy: 0.663561\n",
      "epoch: 778 - cost: 0.857921 mse:  91.7381915651 - -train accuracy: 0.714932\n",
      "epoch: 779 - cost: 0.733565 mse:  96.87260265 - -train accuracy: 0.664626\n",
      "epoch: 780 - cost: 0.855821 mse:  91.8324527348 - -train accuracy: 0.714932\n",
      "epoch: 781 - cost: 0.732157 mse:  96.9357942165 - -train accuracy: 0.664626\n",
      "epoch: 782 - cost: 0.853466 mse:  91.9165699403 - -train accuracy: 0.714932\n",
      "epoch: 783 - cost: 0.730886 mse:  97.015402692 - -train accuracy: 0.663828\n",
      "epoch: 784 - cost: 0.851495 mse:  91.9934318863 - -train accuracy: 0.715198\n",
      "epoch: 785 - cost: 0.729744 mse:  97.0837735969 - -train accuracy: 0.663828\n",
      "epoch: 786 - cost: 0.849552 mse:  92.0738694257 - -train accuracy: 0.715198\n",
      "epoch: 787 - cost: 0.728354 mse:  97.167455959 - -train accuracy: 0.66436\n",
      "epoch: 788 - cost: 0.847175 mse:  92.1801688819 - -train accuracy: 0.715731\n",
      "epoch: 789 - cost: 0.726969 mse:  97.2674670747 - -train accuracy: 0.664626\n",
      "epoch: 790 - cost: 0.844908 mse:  92.2809217423 - -train accuracy: 0.715997\n",
      "epoch: 791 - cost: 0.725473 mse:  97.3314710031 - -train accuracy: 0.664892\n",
      "epoch: 792 - cost: 0.842763 mse:  92.3643792565 - -train accuracy: 0.715997\n",
      "epoch: 793 - cost: 0.724134 mse:  97.4023463646 - -train accuracy: 0.665425\n",
      "epoch: 794 - cost: 0.840878 mse:  92.4465442511 - -train accuracy: 0.716263\n",
      "epoch: 795 - cost: 0.722932 mse:  97.4599878605 - -train accuracy: 0.665425\n",
      "epoch: 796 - cost: 0.839072 mse:  92.5408779598 - -train accuracy: 0.715997\n",
      "epoch: 797 - cost: 0.721544 mse:  97.5387747012 - -train accuracy: 0.665957\n",
      "epoch: 798 - cost: 0.836584 mse:  92.6389545143 - -train accuracy: 0.716529\n",
      "epoch: 799 - cost: 0.720065 mse:  97.6237628599 - -train accuracy: 0.665425\n",
      "epoch: 800 - cost: 0.834133 mse:  92.7322356686 - -train accuracy: 0.716529\n",
      "epoch: 801 - cost: 0.718544 mse:  97.7057618582 - -train accuracy: 0.665425\n",
      "epoch: 802 - cost: 0.83189 mse:  92.8260150829 - -train accuracy: 0.716795\n",
      "epoch: 803 - cost: 0.717187 mse:  97.7701083341 - -train accuracy: 0.665158\n",
      "epoch: 804 - cost: 0.829845 mse:  92.8992463058 - -train accuracy: 0.717061\n",
      "epoch: 805 - cost: 0.715827 mse:  97.8135597272 - -train accuracy: 0.665425\n",
      "epoch: 806 - cost: 0.827686 mse:  92.9620632078 - -train accuracy: 0.716795\n",
      "epoch: 807 - cost: 0.714497 mse:  97.8643292882 - -train accuracy: 0.665957\n",
      "epoch: 808 - cost: 0.82564 mse:  93.017982177 - -train accuracy: 0.717594\n",
      "epoch: 809 - cost: 0.713399 mse:  97.9085324899 - -train accuracy: 0.665957\n",
      "epoch: 810 - cost: 0.823966 mse:  93.0689645893 - -train accuracy: 0.717328\n",
      "epoch: 811 - cost: 0.71224 mse:  97.9275975286 - -train accuracy: 0.666223\n",
      "epoch: 812 - cost: 0.822418 mse:  93.0904397515 - -train accuracy: 0.718126\n",
      "epoch: 813 - cost: 0.711354 mse:  97.9319479454 - -train accuracy: 0.666223\n",
      "epoch: 814 - cost: 0.821163 mse:  93.1168203144 - -train accuracy: 0.718659\n",
      "epoch: 815 - cost: 0.710369 mse:  97.9491457977 - -train accuracy: 0.666755\n",
      "epoch: 816 - cost: 0.819456 mse:  93.1538919459 - -train accuracy: 0.718659\n",
      "epoch: 817 - cost: 0.709296 mse:  97.975377832 - -train accuracy: 0.666755\n",
      "epoch: 818 - cost: 0.817576 mse:  93.190973182 - -train accuracy: 0.718659\n",
      "epoch: 819 - cost: 0.70808 mse:  97.9922085772 - -train accuracy: 0.667288\n",
      "epoch: 820 - cost: 0.815683 mse:  93.2272142822 - -train accuracy: 0.718925\n",
      "epoch: 821 - cost: 0.706743 mse:  98.0118595613 - -train accuracy: 0.667288\n",
      "epoch: 822 - cost: 0.813613 mse:  93.2638286594 - -train accuracy: 0.718925\n",
      "epoch: 823 - cost: 0.705461 mse:  98.0217355714 - -train accuracy: 0.667288\n",
      "epoch: 824 - cost: 0.81179 mse:  93.2828222272 - -train accuracy: 0.719191\n",
      "epoch: 825 - cost: 0.7043 mse:  98.0336517568 - -train accuracy: 0.66782\n",
      "epoch: 826 - cost: 0.810022 mse:  93.3371263989 - -train accuracy: 0.719457\n",
      "epoch: 827 - cost: 0.70297 mse:  98.0656416173 - -train accuracy: 0.668619\n",
      "epoch: 828 - cost: 0.807941 mse:  93.3736566637 - -train accuracy: 0.719457\n",
      "epoch: 829 - cost: 0.701689 mse:  98.0802130929 - -train accuracy: 0.668619\n",
      "epoch: 830 - cost: 0.806298 mse:  93.4036412026 - -train accuracy: 0.719191\n",
      "epoch: 831 - cost: 0.70104 mse:  98.1102614958 - -train accuracy: 0.66782\n",
      "epoch: 832 - cost: 0.80538 mse:  93.4489478591 - -train accuracy: 0.719191\n",
      "epoch: 833 - cost: 0.699969 mse:  98.1160817939 - -train accuracy: 0.66782\n",
      "epoch: 834 - cost: 0.804055 mse:  93.4846308907 - -train accuracy: 0.719191\n",
      "epoch: 835 - cost: 0.699195 mse:  98.1475075013 - -train accuracy: 0.668086\n",
      "epoch: 836 - cost: 0.802739 mse:  93.534509512 - -train accuracy: 0.719723\n",
      "epoch: 837 - cost: 0.697986 mse:  98.1671768442 - -train accuracy: 0.668619\n",
      "epoch: 838 - cost: 0.800779 mse:  93.5893015348 - -train accuracy: 0.719723\n",
      "epoch: 839 - cost: 0.696734 mse:  98.2011690979 - -train accuracy: 0.668885\n",
      "epoch: 840 - cost: 0.798735 mse:  93.6319304809 - -train accuracy: 0.719989\n",
      "epoch: 841 - cost: 0.695417 mse:  98.2233054123 - -train accuracy: 0.669683\n",
      "epoch: 842 - cost: 0.796684 mse:  93.6655387663 - -train accuracy: 0.719989\n",
      "epoch: 843 - cost: 0.69424 mse:  98.2421413242 - -train accuracy: 0.670748\n",
      "epoch: 844 - cost: 0.794779 mse:  93.6993598869 - -train accuracy: 0.721054\n",
      "epoch: 845 - cost: 0.693061 mse:  98.2592539072 - -train accuracy: 0.670748\n",
      "epoch: 846 - cost: 0.793004 mse:  93.726634452 - -train accuracy: 0.72132\n",
      "epoch: 847 - cost: 0.692094 mse:  98.2884416068 - -train accuracy: 0.670748\n",
      "epoch: 848 - cost: 0.791508 mse:  93.7696780583 - -train accuracy: 0.72132\n",
      "epoch: 849 - cost: 0.691132 mse:  98.3068187925 - -train accuracy: 0.670482\n",
      "epoch: 850 - cost: 0.790104 mse:  93.8072577881 - -train accuracy: 0.72132\n",
      "epoch: 851 - cost: 0.69014 mse:  98.3211357847 - -train accuracy: 0.670216\n",
      "epoch: 852 - cost: 0.78853 mse:  93.8427120343 - -train accuracy: 0.721586\n",
      "epoch: 853 - cost: 0.689021 mse:  98.3344840963 - -train accuracy: 0.670216\n",
      "epoch: 854 - cost: 0.786729 mse:  93.8733462949 - -train accuracy: 0.721586\n",
      "epoch: 855 - cost: 0.68778 mse:  98.347085983 - -train accuracy: 0.670216\n",
      "epoch: 856 - cost: 0.784763 mse:  93.8973468123 - -train accuracy: 0.721586\n",
      "epoch: 857 - cost: 0.686435 mse:  98.331359745 - -train accuracy: 0.670482\n",
      "epoch: 858 - cost: 0.782782 mse:  93.9003900061 - -train accuracy: 0.722119\n",
      "epoch: 859 - cost: 0.685292 mse:  98.3202159164 - -train accuracy: 0.669683\n",
      "epoch: 860 - cost: 0.780987 mse:  93.9110942269 - -train accuracy: 0.722385\n",
      "epoch: 861 - cost: 0.684049 mse:  98.3159326514 - -train accuracy: 0.669949\n",
      "epoch: 862 - cost: 0.778953 mse:  93.920995661 - -train accuracy: 0.722651\n",
      "epoch: 863 - cost: 0.682888 mse:  98.3022242537 - -train accuracy: 0.670482\n",
      "epoch: 864 - cost: 0.776847 mse:  93.9226355873 - -train accuracy: 0.722651\n",
      "epoch: 865 - cost: 0.681584 mse:  98.2925435987 - -train accuracy: 0.671014\n",
      "epoch: 866 - cost: 0.774642 mse:  93.9196260619 - -train accuracy: 0.722651\n",
      "epoch: 867 - cost: 0.680181 mse:  98.2641016464 - -train accuracy: 0.670748\n",
      "epoch: 868 - cost: 0.772176 mse:  93.9184307521 - -train accuracy: 0.723716\n",
      "epoch: 869 - cost: 0.678677 mse:  98.2362127634 - -train accuracy: 0.670748\n",
      "epoch: 870 - cost: 0.769861 mse:  93.915543692 - -train accuracy: 0.723716\n",
      "epoch: 871 - cost: 0.677469 mse:  98.2252101685 - -train accuracy: 0.671014\n",
      "epoch: 872 - cost: 0.768022 mse:  93.9192608723 - -train accuracy: 0.724248\n",
      "epoch: 873 - cost: 0.676455 mse:  98.2116668389 - -train accuracy: 0.671546\n",
      "epoch: 874 - cost: 0.766297 mse:  93.9232850885 - -train accuracy: 0.724248\n",
      "epoch: 875 - cost: 0.675278 mse:  98.1967661953 - -train accuracy: 0.67128\n",
      "epoch: 876 - cost: 0.764391 mse:  93.9240605474 - -train accuracy: 0.724248\n",
      "epoch: 877 - cost: 0.673974 mse:  98.176032757 - -train accuracy: 0.671546\n",
      "epoch: 878 - cost: 0.762241 mse:  93.920528771 - -train accuracy: 0.72478\n",
      "epoch: 879 - cost: 0.672874 mse:  98.1415600786 - -train accuracy: 0.67128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 880 - cost: 0.760591 mse:  93.9032219113 - -train accuracy: 0.725047\n",
      "epoch: 881 - cost: 0.671834 mse:  98.1006907843 - -train accuracy: 0.67128\n",
      "epoch: 882 - cost: 0.758851 mse:  93.8777760268 - -train accuracy: 0.725313\n",
      "epoch: 883 - cost: 0.670754 mse:  98.0553365009 - -train accuracy: 0.671813\n",
      "epoch: 884 - cost: 0.757363 mse:  93.8444839196 - -train accuracy: 0.725047\n",
      "epoch: 885 - cost: 0.669683 mse:  97.9765674141 - -train accuracy: 0.672877\n",
      "epoch: 886 - cost: 0.755759 mse:  93.8080333809 - -train accuracy: 0.725313\n",
      "epoch: 887 - cost: 0.668353 mse:  97.910283283 - -train accuracy: 0.673942\n",
      "epoch: 888 - cost: 0.753644 mse:  93.7748065052 - -train accuracy: 0.725313\n",
      "epoch: 889 - cost: 0.667255 mse:  97.8387763688 - -train accuracy: 0.674474\n",
      "epoch: 890 - cost: 0.752195 mse:  93.7176134567 - -train accuracy: 0.725047\n",
      "epoch: 891 - cost: 0.666321 mse:  97.7557233908 - -train accuracy: 0.674208\n",
      "epoch: 892 - cost: 0.750996 mse:  93.6580464096 - -train accuracy: 0.72478\n",
      "epoch: 893 - cost: 0.665605 mse:  97.7113390586 - -train accuracy: 0.674208\n",
      "epoch: 894 - cost: 0.749906 mse:  93.6316100781 - -train accuracy: 0.72478\n",
      "epoch: 895 - cost: 0.664621 mse:  97.6379507131 - -train accuracy: 0.67474\n",
      "epoch: 896 - cost: 0.748216 mse:  93.5814744109 - -train accuracy: 0.725579\n",
      "epoch: 897 - cost: 0.663464 mse:  97.5652427677 - -train accuracy: 0.67474\n",
      "epoch: 898 - cost: 0.746385 mse:  93.5473435627 - -train accuracy: 0.725579\n",
      "epoch: 899 - cost: 0.66226 mse:  97.5040896533 - -train accuracy: 0.675805\n",
      "epoch: 900 - cost: 0.744531 mse:  93.5209225702 - -train accuracy: 0.726111\n",
      "epoch: 901 - cost: 0.661078 mse:  97.4727877953 - -train accuracy: 0.676071\n",
      "epoch: 902 - cost: 0.742856 mse:  93.5186854117 - -train accuracy: 0.726644\n",
      "epoch: 903 - cost: 0.660164 mse:  97.4665205264 - -train accuracy: 0.675805\n",
      "epoch: 904 - cost: 0.741529 mse:  93.5459216903 - -train accuracy: 0.727442\n",
      "epoch: 905 - cost: 0.659027 mse:  97.4604079628 - -train accuracy: 0.677136\n",
      "epoch: 906 - cost: 0.739638 mse:  93.5591245949 - -train accuracy: 0.727442\n",
      "epoch: 907 - cost: 0.657827 mse:  97.4611300902 - -train accuracy: 0.677136\n",
      "epoch: 908 - cost: 0.737863 mse:  93.5614807407 - -train accuracy: 0.727974\n",
      "epoch: 909 - cost: 0.65674 mse:  97.4492952118 - -train accuracy: 0.677136\n",
      "epoch: 910 - cost: 0.736356 mse:  93.5603539381 - -train accuracy: 0.728241\n",
      "epoch: 911 - cost: 0.655814 mse:  97.4440768873 - -train accuracy: 0.67687\n",
      "epoch: 912 - cost: 0.735012 mse:  93.5662338117 - -train accuracy: 0.728507\n",
      "epoch: 913 - cost: 0.654911 mse:  97.4338282553 - -train accuracy: 0.677136\n",
      "epoch: 914 - cost: 0.733771 mse:  93.5833524833 - -train accuracy: 0.729305\n",
      "epoch: 915 - cost: 0.654096 mse:  97.4248547213 - -train accuracy: 0.677136\n",
      "epoch: 916 - cost: 0.732588 mse:  93.5820724462 - -train accuracy: 0.729571\n",
      "epoch: 917 - cost: 0.653176 mse:  97.3940572296 - -train accuracy: 0.677136\n",
      "epoch: 918 - cost: 0.730955 mse:  93.6063388034 - -train accuracy: 0.729838\n",
      "epoch: 919 - cost: 0.651908 mse:  97.4137402206 - -train accuracy: 0.677668\n",
      "epoch: 920 - cost: 0.729003 mse:  93.6084551407 - -train accuracy: 0.729571\n",
      "epoch: 921 - cost: 0.650785 mse:  97.4064020237 - -train accuracy: 0.677668\n",
      "epoch: 922 - cost: 0.727422 mse:  93.6243103868 - -train accuracy: 0.730104\n",
      "epoch: 923 - cost: 0.649581 mse:  97.4059359679 - -train accuracy: 0.677668\n",
      "epoch: 924 - cost: 0.725792 mse:  93.6420050966 - -train accuracy: 0.73037\n",
      "epoch: 925 - cost: 0.648659 mse:  97.4057800508 - -train accuracy: 0.678201\n",
      "epoch: 926 - cost: 0.724362 mse:  93.6674236094 - -train accuracy: 0.73037\n",
      "epoch: 927 - cost: 0.647602 mse:  97.4198336385 - -train accuracy: 0.678999\n",
      "epoch: 928 - cost: 0.722835 mse:  93.6955562093 - -train accuracy: 0.730902\n",
      "epoch: 929 - cost: 0.646524 mse:  97.4328633006 - -train accuracy: 0.678999\n",
      "epoch: 930 - cost: 0.721151 mse:  93.7316495586 - -train accuracy: 0.731169\n",
      "epoch: 931 - cost: 0.64524 mse:  97.4665445051 - -train accuracy: 0.679265\n",
      "epoch: 932 - cost: 0.719236 mse:  93.7855042891 - -train accuracy: 0.731169\n",
      "epoch: 933 - cost: 0.644133 mse:  97.4865206247 - -train accuracy: 0.679265\n",
      "epoch: 934 - cost: 0.717665 mse:  93.8120815067 - -train accuracy: 0.731169\n",
      "epoch: 935 - cost: 0.643026 mse:  97.4997727923 - -train accuracy: 0.68033\n",
      "epoch: 936 - cost: 0.716035 mse:  93.8329571402 - -train accuracy: 0.731435\n",
      "epoch: 937 - cost: 0.642014 mse:  97.5150263388 - -train accuracy: 0.68033\n",
      "epoch: 938 - cost: 0.714451 mse:  93.873682893 - -train accuracy: 0.731967\n",
      "epoch: 939 - cost: 0.640962 mse:  97.5453805495 - -train accuracy: 0.680596\n",
      "epoch: 940 - cost: 0.712806 mse:  93.9032971265 - -train accuracy: 0.733032\n",
      "epoch: 941 - cost: 0.639926 mse:  97.560689749 - -train accuracy: 0.680596\n",
      "epoch: 942 - cost: 0.711242 mse:  93.9267384794 - -train accuracy: 0.733564\n",
      "epoch: 943 - cost: 0.638962 mse:  97.5692379913 - -train accuracy: 0.680596\n",
      "epoch: 944 - cost: 0.709823 mse:  93.9473011758 - -train accuracy: 0.733564\n",
      "epoch: 945 - cost: 0.637961 mse:  97.5854799385 - -train accuracy: 0.681395\n",
      "epoch: 946 - cost: 0.708293 mse:  93.9742153736 - -train accuracy: 0.73383\n",
      "epoch: 947 - cost: 0.636856 mse:  97.5976529419 - -train accuracy: 0.681395\n",
      "epoch: 948 - cost: 0.706605 mse:  93.988460889 - -train accuracy: 0.73383\n",
      "epoch: 949 - cost: 0.635751 mse:  97.5976094659 - -train accuracy: 0.681661\n",
      "epoch: 950 - cost: 0.70487 mse:  94.0111813694 - -train accuracy: 0.733564\n",
      "epoch: 951 - cost: 0.634641 mse:  97.6134134593 - -train accuracy: 0.681661\n",
      "epoch: 952 - cost: 0.703205 mse:  94.040794766 - -train accuracy: 0.73383\n",
      "epoch: 953 - cost: 0.633529 mse:  97.6243642256 - -train accuracy: 0.682193\n",
      "epoch: 954 - cost: 0.701678 mse:  94.07745327 - -train accuracy: 0.734096\n",
      "epoch: 955 - cost: 0.632668 mse:  97.6588791974 - -train accuracy: 0.682992\n",
      "epoch: 956 - cost: 0.700286 mse:  94.1227691158 - -train accuracy: 0.734096\n",
      "epoch: 957 - cost: 0.631689 mse:  97.6908602346 - -train accuracy: 0.68379\n",
      "epoch: 958 - cost: 0.698677 mse:  94.1572684866 - -train accuracy: 0.734096\n",
      "epoch: 959 - cost: 0.63069 mse:  97.7182376104 - -train accuracy: 0.684056\n",
      "epoch: 960 - cost: 0.697226 mse:  94.1893403618 - -train accuracy: 0.734629\n",
      "epoch: 961 - cost: 0.629848 mse:  97.7429997273 - -train accuracy: 0.684056\n",
      "epoch: 962 - cost: 0.695848 mse:  94.2324611551 - -train accuracy: 0.734895\n",
      "epoch: 963 - cost: 0.628854 mse:  97.7866307152 - -train accuracy: 0.684589\n",
      "epoch: 964 - cost: 0.694409 mse:  94.2816027927 - -train accuracy: 0.734895\n",
      "epoch: 965 - cost: 0.628079 mse:  97.8226625087 - -train accuracy: 0.685121\n",
      "epoch: 966 - cost: 0.693242 mse:  94.3253432724 - -train accuracy: 0.735427\n",
      "epoch: 967 - cost: 0.627175 mse:  97.8565880848 - -train accuracy: 0.68592\n",
      "epoch: 968 - cost: 0.692189 mse:  94.3656489447 - -train accuracy: 0.735693\n",
      "epoch: 969 - cost: 0.626649 mse:  97.8875389661 - -train accuracy: 0.686186\n",
      "epoch: 970 - cost: 0.691571 mse:  94.4111350713 - -train accuracy: 0.735161\n",
      "epoch: 971 - cost: 0.626045 mse:  97.9163879896 - -train accuracy: 0.686186\n",
      "epoch: 972 - cost: 0.690632 mse:  94.4559469132 - -train accuracy: 0.735427\n",
      "epoch: 973 - cost: 0.625206 mse:  97.9567519598 - -train accuracy: 0.686186\n",
      "epoch: 974 - cost: 0.689366 mse:  94.5094912413 - -train accuracy: 0.735693\n",
      "epoch: 975 - cost: 0.624466 mse:  98.0073769196 - -train accuracy: 0.686186\n",
      "epoch: 976 - cost: 0.688079 mse:  94.572793937 - -train accuracy: 0.73596\n",
      "epoch: 977 - cost: 0.623329 mse:  98.0702111736 - -train accuracy: 0.68725\n",
      "epoch: 978 - cost: 0.686495 mse:  94.6344968661 - -train accuracy: 0.735693\n",
      "epoch: 979 - cost: 0.622548 mse:  98.1178647775 - -train accuracy: 0.68725\n",
      "epoch: 980 - cost: 0.685361 mse:  94.6995390185 - -train accuracy: 0.735693\n",
      "epoch: 981 - cost: 0.621688 mse:  98.1604695082 - -train accuracy: 0.68725\n",
      "epoch: 982 - cost: 0.684025 mse:  94.7506566083 - -train accuracy: 0.73596\n",
      "epoch: 983 - cost: 0.620717 mse:  98.1949943549 - -train accuracy: 0.68725\n",
      "epoch: 984 - cost: 0.682644 mse:  94.7953387916 - -train accuracy: 0.73596\n",
      "epoch: 985 - cost: 0.619899 mse:  98.2212540506 - -train accuracy: 0.68725\n",
      "epoch: 986 - cost: 0.68147 mse:  94.8435415967 - -train accuracy: 0.73596\n",
      "epoch: 987 - cost: 0.619063 mse:  98.2575201749 - -train accuracy: 0.688049\n",
      "epoch: 988 - cost: 0.680174 mse:  94.8975300564 - -train accuracy: 0.73596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 989 - cost: 0.618234 mse:  98.294133046 - -train accuracy: 0.688581\n",
      "epoch: 990 - cost: 0.678865 mse:  94.9385162386 - -train accuracy: 0.736226\n",
      "epoch: 991 - cost: 0.617311 mse:  98.3157544048 - -train accuracy: 0.68938\n",
      "epoch: 992 - cost: 0.677455 mse:  94.960168238 - -train accuracy: 0.736758\n",
      "epoch: 993 - cost: 0.616359 mse:  98.3310710166 - -train accuracy: 0.690445\n",
      "epoch: 994 - cost: 0.676074 mse:  95.0025157792 - -train accuracy: 0.736758\n",
      "epoch: 995 - cost: 0.615464 mse:  98.3508679893 - -train accuracy: 0.690977\n",
      "epoch: 996 - cost: 0.674762 mse:  95.0278036038 - -train accuracy: 0.737024\n",
      "epoch: 997 - cost: 0.614544 mse:  98.3618827825 - -train accuracy: 0.691509\n",
      "epoch: 998 - cost: 0.673484 mse:  95.0697573212 - -train accuracy: 0.73729\n",
      "epoch: 999 - cost: 0.613703 mse:  98.4101008863 - -train accuracy: 0.693639\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    sess.run(train_step,feed_dict={x:x_train,y_:y_train})\n",
    "    cost=sess.run(cross_entropy,feed_dict={x:x_train,y_:y_train})\n",
    "    cost_history.append(np.append(cost_history,cost))\n",
    "    correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    \n",
    "    pred_y=sess.run(y,feed_dict={x:x_test})\n",
    "    mse=tf.reduce_mean(tf.square(pred_y-y_test))\n",
    "    mse_=sess.run(mse)\n",
    "    mse_history.append(mse_)\n",
    "    accuracy=sess.run(accuracy,feed_dict={x:x_train,y_:y_train})\n",
    "    accuracy_history.append(accuracy)\n",
    "    \n",
    "    print('epoch:',epoch,'-','cost:',cost,'mse: ',mse_,'-','-train accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.683955\n"
     ]
    }
   ],
   "source": [
    "correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "print('test accuracy:',sess.run(accuracy,feed_dict={x:x_test,y_:y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:98.4101\n"
     ]
    }
   ],
   "source": [
    "pred_y=sess.run(y,feed_dict={x:x_test})\n",
    "mse=tf.reduce_mean(tf.square(pred_y-y_test))\n",
    "print('mse:%.4f'%sess.run(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
