{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('/home/saloni/Documents/ML/Mortality/train.csv')\n",
    "labels=pd.read_csv('/home/saloni/Documents/ML/Mortality/labels_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dailydata=df.copy()\n",
    "result=pd.concat([dailydata,labels],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>...</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Temp</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Weight</th>\n",
       "      <th>pH</th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>54</td>\n",
       "      <td>2.973333</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>97.25</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>37.357143</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>171.052632</td>\n",
       "      <td>10.3</td>\n",
       "      <td>80.060976</td>\n",
       "      <td>7.387273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ALP   ALT   AST  Age   Albumin   BUN  Bilirubin  Cholesterol  Creatinine  \\\n",
       "0  77.0  31.0  46.0   54  2.973333  10.5        0.7        154.0        0.75   \n",
       "\n",
       "     DiasABP        ...           SaO2      SysABP       Temp  TroponinI  \\\n",
       "0  58.795833        ...          97.25  116.891892  37.357143        2.1   \n",
       "\n",
       "   TroponinT       Urine   WBC     Weight        pH  In-hospital_death  \n",
       "0       0.14  171.052632  10.3  80.060976  7.387273                  0  \n",
       "\n",
       "[1 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_variables = ['Age', 'Albumin', 'ALP', 'ALT', 'AST', 'Bilirubin', 'BUN', 'Cholesterol', 'Creatinine',\n",
    "                             'DiasABP', 'FiO2', 'GCS', 'Gender', 'Glucose', 'HCO3', 'HCT', 'Height', 'HR', 'ICUType', 'K',\n",
    "                             'Lactate', 'Mg', 'MAP', 'MechVent', 'Na', 'NIDiasABP', 'NIMAP', 'NISysABP', 'PaCO2', 'PaO2',\n",
    "                             'pH', 'Platelets', 'RecordID', 'RespRate', 'SaO2', 'SysABP', 'Temp', 'TroponinI','TroponinT','Urine',\n",
    "                             'WBC', 'Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datawithoutoutliers=result.copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3169, 43)\n"
     ]
    }
   ],
   "source": [
    "for i in list_of_variables:\n",
    "    datawithoutoutliers=datawithoutoutliers[np.abs(datawithoutoutliers[i]-datawithoutoutliers[i].mean())<=(4*datawithoutoutliers[i].std())]\n",
    "    outliers=datawithoutoutliers[np.abs(datawithoutoutliers[i]-datawithoutoutliers[i].mean())>=(4*datawithoutoutliers[i].std())]\n",
    "    \n",
    "print(datawithoutoutliers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels=datawithoutoutliers.pop(\"In-hospital_death\")\n",
    "df=datawithoutoutliers.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3169,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3169, 42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#normalization\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df = scaler.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "df_res,labels_res=SMOTE(random_state=9).fit_sample(df,labels) #balancing the data\n",
    "df_res=pd.DataFrame(df_res)\n",
    "labels_res=pd.DataFrame(labels_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc=OneHotEncoder(sparse=False)\n",
    "onehot_encoded = enc.fit_transform(labels_res)\n",
    "\n",
    "labels_res=onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(df_res,labels_res,test_size=0.33,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden_1=60\n",
    "n_hidden_2=60\n",
    "n_hidden_3=60\n",
    "n_hidden_4=60\n",
    "n_hidden_5=60\n",
    "\n",
    "\n",
    "x=tf.placeholder(tf.float32,shape=[None,42])\n",
    "y_=tf.placeholder(tf.float32,shape=[None,2])\n",
    "w =tf.Variable(tf.zeros([42,2]))\n",
    "b=tf.Variable(tf.zeros([2]))\n",
    "\n",
    "def multilayer_perceptron(x,weights,biases):\n",
    "    layer_1=tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    layer_1=tf.nn.sigmoid(layer_1)\n",
    "    \n",
    "    layer_2=tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
    "    layer_2=tf.nn.sigmoid(layer_2)\n",
    "    \n",
    "    layer_3=tf.add(tf.matmul(layer_2,weights['h3']),biases['b3'])\n",
    "    layer_3=tf.nn.sigmoid(layer_3)\n",
    "    \n",
    "    layer_4=tf.add(tf.matmul(layer_3,weights['h4']),biases['b4'])\n",
    "    layer_4=tf.nn.sigmoid(layer_4)\n",
    "    \n",
    "    layer_5=tf.add(tf.matmul(layer_4,weights['h5']),biases['b5'])\n",
    "    layer_5=tf.nn.relu(layer_5)\n",
    "    \n",
    "    \n",
    "    out_layer=tf.add(tf.matmul(layer_5,weights['out']),biases['out'])\n",
    "    return out_layer\n",
    "\n",
    "weights={\n",
    "       \n",
    "    'h1':tf.Variable(tf.truncated_normal([42,n_hidden_1])),\n",
    "    'h2':tf.Variable(tf.truncated_normal([n_hidden_1,n_hidden_2])),\n",
    "    'h3':tf.Variable(tf.truncated_normal([n_hidden_2,n_hidden_3])),\n",
    "    'h4':tf.Variable(tf.truncated_normal([n_hidden_3,n_hidden_4])),\n",
    "    'h5':tf.Variable(tf.truncated_normal([n_hidden_4,n_hidden_5])),\n",
    "    'out':tf.Variable(tf.truncated_normal([n_hidden_5,2]))\n",
    "}\n",
    "\n",
    "biases={\n",
    "    'b1':tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3':tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'b4':tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    'b5':tf.Variable(tf.truncated_normal([n_hidden_5])),\n",
    "    'out':tf.Variable(tf.truncated_normal([2]))\n",
    "}\n",
    "    \n",
    "y=multilayer_perceptron(x,weights,biases)\n",
    "cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_,logits=y))  \n",
    "train_step=tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "sess.run(tf.global_variables_initializer())                     \n",
    "                     \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_history=[]\n",
    "cost_history=[]\n",
    "accuracy_history=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_epochs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - cost: 4.13997 mse:  23.0395371825 - -train accuracy: 0.507852\n",
      "epoch: 1 - cost: 3.36464 mse:  16.470584732 - -train accuracy: 0.491083\n",
      "epoch: 2 - cost: 4.02057 mse:  22.1605490725 - -train accuracy: 0.507852\n",
      "epoch: 3 - cost: 3.26303 mse:  15.9814954779 - -train accuracy: 0.490551\n",
      "epoch: 4 - cost: 3.90712 mse:  21.3599912802 - -train accuracy: 0.507852\n",
      "epoch: 5 - cost: 3.18228 mse:  15.6339458892 - -train accuracy: 0.490285\n",
      "epoch: 6 - cost: 3.80241 mse:  20.6500972006 - -train accuracy: 0.507852\n",
      "epoch: 7 - cost: 3.11775 mse:  15.3812176505 - -train accuracy: 0.490019\n",
      "epoch: 8 - cost: 3.71088 mse:  20.0508240843 - -train accuracy: 0.507852\n",
      "epoch: 9 - cost: 3.06137 mse:  15.1774259407 - -train accuracy: 0.489486\n",
      "epoch: 10 - cost: 3.62867 mse:  19.5326504279 - -train accuracy: 0.507852\n",
      "epoch: 11 - cost: 3.01166 mse:  15.0109660611 - -train accuracy: 0.488954\n",
      "epoch: 12 - cost: 3.55403 mse:  19.0684070257 - -train accuracy: 0.507852\n",
      "epoch: 13 - cost: 2.96834 mse:  14.877117109 - -train accuracy: 0.488954\n",
      "epoch: 14 - cost: 3.48572 mse:  18.6585277669 - -train accuracy: 0.507852\n",
      "epoch: 15 - cost: 2.92944 mse:  14.7713617997 - -train accuracy: 0.488954\n",
      "epoch: 16 - cost: 3.42133 mse:  18.2811827845 - -train accuracy: 0.507852\n",
      "epoch: 17 - cost: 2.89527 mse:  14.6892155613 - -train accuracy: 0.488954\n",
      "epoch: 18 - cost: 3.36058 mse:  17.9289176835 - -train accuracy: 0.507852\n",
      "epoch: 19 - cost: 2.86401 mse:  14.6124344008 - -train accuracy: 0.48922\n",
      "epoch: 20 - cost: 3.30287 mse:  17.6008427457 - -train accuracy: 0.507852\n",
      "epoch: 21 - cost: 2.83468 mse:  14.5470284016 - -train accuracy: 0.489486\n",
      "epoch: 22 - cost: 3.24815 mse:  17.3023007892 - -train accuracy: 0.507852\n",
      "epoch: 23 - cost: 2.80654 mse:  14.4884034121 - -train accuracy: 0.489486\n",
      "epoch: 24 - cost: 3.19428 mse:  17.0117372282 - -train accuracy: 0.507852\n",
      "epoch: 25 - cost: 2.78146 mse:  14.4465153444 - -train accuracy: 0.488954\n",
      "epoch: 26 - cost: 3.14326 mse:  16.7406155988 - -train accuracy: 0.507852\n",
      "epoch: 27 - cost: 2.75689 mse:  14.4009163498 - -train accuracy: 0.48922\n",
      "epoch: 28 - cost: 3.09477 mse:  16.4845536115 - -train accuracy: 0.507852\n",
      "epoch: 29 - cost: 2.73264 mse:  14.3521351699 - -train accuracy: 0.48922\n",
      "epoch: 30 - cost: 3.04826 mse:  16.2477737839 - -train accuracy: 0.507852\n",
      "epoch: 31 - cost: 2.70904 mse:  14.3049179256 - -train accuracy: 0.48922\n",
      "epoch: 32 - cost: 3.00337 mse:  16.0145453959 - -train accuracy: 0.507852\n",
      "epoch: 33 - cost: 2.68634 mse:  14.2528175764 - -train accuracy: 0.48922\n",
      "epoch: 34 - cost: 2.96074 mse:  15.7911214296 - -train accuracy: 0.507586\n",
      "epoch: 35 - cost: 2.66419 mse:  14.1956805257 - -train accuracy: 0.488688\n",
      "epoch: 36 - cost: 2.92049 mse:  15.585477154 - -train accuracy: 0.507586\n",
      "epoch: 37 - cost: 2.64211 mse:  14.1292711824 - -train accuracy: 0.488688\n",
      "epoch: 38 - cost: 2.88237 mse:  15.3836072287 - -train accuracy: 0.507586\n",
      "epoch: 39 - cost: 2.62041 mse:  14.0558892861 - -train accuracy: 0.488422\n",
      "epoch: 40 - cost: 2.84656 mse:  15.194569885 - -train accuracy: 0.507586\n",
      "epoch: 41 - cost: 2.59813 mse:  13.9710977494 - -train accuracy: 0.488688\n",
      "epoch: 42 - cost: 2.81244 mse:  15.0129608994 - -train accuracy: 0.507586\n",
      "epoch: 43 - cost: 2.57597 mse:  13.8825925707 - -train accuracy: 0.488954\n",
      "epoch: 44 - cost: 2.77964 mse:  14.8372431649 - -train accuracy: 0.507586\n",
      "epoch: 45 - cost: 2.55388 mse:  13.7893094148 - -train accuracy: 0.488422\n",
      "epoch: 46 - cost: 2.74741 mse:  14.6665006151 - -train accuracy: 0.507586\n",
      "epoch: 47 - cost: 2.53189 mse:  13.6912795886 - -train accuracy: 0.488422\n",
      "epoch: 48 - cost: 2.71665 mse:  14.4995053142 - -train accuracy: 0.507586\n",
      "epoch: 49 - cost: 2.51018 mse:  13.5912129343 - -train accuracy: 0.488422\n",
      "epoch: 50 - cost: 2.68624 mse:  14.3347721186 - -train accuracy: 0.507586\n",
      "epoch: 51 - cost: 2.48928 mse:  13.4885656481 - -train accuracy: 0.488155\n",
      "epoch: 52 - cost: 2.65712 mse:  14.1753457604 - -train accuracy: 0.507586\n",
      "epoch: 53 - cost: 2.46886 mse:  13.3849607772 - -train accuracy: 0.487623\n",
      "epoch: 54 - cost: 2.62919 mse:  14.0243807255 - -train accuracy: 0.507586\n",
      "epoch: 55 - cost: 2.44841 mse:  13.2817331409 - -train accuracy: 0.487889\n",
      "epoch: 56 - cost: 2.60186 mse:  13.8719138914 - -train accuracy: 0.507586\n",
      "epoch: 57 - cost: 2.42863 mse:  13.1726592705 - -train accuracy: 0.487889\n",
      "epoch: 58 - cost: 2.57544 mse:  13.7205423438 - -train accuracy: 0.507586\n",
      "epoch: 59 - cost: 2.40917 mse:  13.061788961 - -train accuracy: 0.488688\n",
      "epoch: 60 - cost: 2.55054 mse:  13.5779913415 - -train accuracy: 0.507586\n",
      "epoch: 61 - cost: 2.39008 mse:  12.9469768043 - -train accuracy: 0.488954\n",
      "epoch: 62 - cost: 2.52661 mse:  13.4352580417 - -train accuracy: 0.507586\n",
      "epoch: 63 - cost: 2.37161 mse:  12.8322234601 - -train accuracy: 0.488954\n",
      "epoch: 64 - cost: 2.50322 mse:  13.2910462295 - -train accuracy: 0.507586\n",
      "epoch: 65 - cost: 2.35401 mse:  12.7172783601 - -train accuracy: 0.488954\n",
      "epoch: 66 - cost: 2.48079 mse:  13.14695413 - -train accuracy: 0.507586\n",
      "epoch: 67 - cost: 2.3371 mse:  12.6006641509 - -train accuracy: 0.489486\n",
      "epoch: 68 - cost: 2.45955 mse:  13.0073204963 - -train accuracy: 0.507852\n",
      "epoch: 69 - cost: 2.32056 mse:  12.4797055679 - -train accuracy: 0.48922\n",
      "epoch: 70 - cost: 2.43955 mse:  12.869461176 - -train accuracy: 0.507852\n",
      "epoch: 71 - cost: 2.30446 mse:  12.3535754246 - -train accuracy: 0.48922\n",
      "epoch: 72 - cost: 2.42054 mse:  12.7342957347 - -train accuracy: 0.508118\n",
      "epoch: 73 - cost: 2.28822 mse:  12.229458278 - -train accuracy: 0.48922\n",
      "epoch: 74 - cost: 2.40218 mse:  12.6051205337 - -train accuracy: 0.508118\n",
      "epoch: 75 - cost: 2.2729 mse:  12.1061530962 - -train accuracy: 0.48922\n",
      "epoch: 76 - cost: 2.38433 mse:  12.4766022369 - -train accuracy: 0.508118\n",
      "epoch: 77 - cost: 2.25789 mse:  11.9850732379 - -train accuracy: 0.489752\n",
      "epoch: 78 - cost: 2.36701 mse:  12.350488375 - -train accuracy: 0.508118\n",
      "epoch: 79 - cost: 2.24336 mse:  11.8657065316 - -train accuracy: 0.489752\n",
      "epoch: 80 - cost: 2.34989 mse:  12.2247989702 - -train accuracy: 0.508384\n",
      "epoch: 81 - cost: 2.22941 mse:  11.7491906978 - -train accuracy: 0.489752\n",
      "epoch: 82 - cost: 2.33329 mse:  12.102410516 - -train accuracy: 0.508384\n",
      "epoch: 83 - cost: 2.21584 mse:  11.6337222863 - -train accuracy: 0.489752\n",
      "epoch: 84 - cost: 2.31736 mse:  11.9846842434 - -train accuracy: 0.508384\n",
      "epoch: 85 - cost: 2.20263 mse:  11.5221840941 - -train accuracy: 0.489752\n",
      "epoch: 86 - cost: 2.30171 mse:  11.8700109271 - -train accuracy: 0.508384\n",
      "epoch: 87 - cost: 2.18981 mse:  11.4128179014 - -train accuracy: 0.490019\n",
      "epoch: 88 - cost: 2.28663 mse:  11.7591742484 - -train accuracy: 0.508384\n",
      "epoch: 89 - cost: 2.17734 mse:  11.3049174343 - -train accuracy: 0.490019\n",
      "epoch: 90 - cost: 2.27196 mse:  11.6501080437 - -train accuracy: 0.508384\n",
      "epoch: 91 - cost: 2.16514 mse:  11.1996516074 - -train accuracy: 0.490285\n",
      "epoch: 92 - cost: 2.25762 mse:  11.5430786017 - -train accuracy: 0.508384\n",
      "epoch: 93 - cost: 2.15314 mse:  11.0953768692 - -train accuracy: 0.490551\n",
      "epoch: 94 - cost: 2.24373 mse:  11.4392981075 - -train accuracy: 0.508384\n",
      "epoch: 95 - cost: 2.14144 mse:  10.9940649439 - -train accuracy: 0.490551\n",
      "epoch: 96 - cost: 2.2298 mse:  11.33596681 - -train accuracy: 0.508384\n",
      "epoch: 97 - cost: 2.13005 mse:  10.8956283366 - -train accuracy: 0.490551\n",
      "epoch: 98 - cost: 2.21641 mse:  11.2369159086 - -train accuracy: 0.508384\n",
      "epoch: 99 - cost: 2.11886 mse:  10.8000918631 - -train accuracy: 0.490817\n",
      "epoch: 100 - cost: 2.20338 mse:  11.1414858482 - -train accuracy: 0.508384\n",
      "epoch: 101 - cost: 2.10791 mse:  10.7075318187 - -train accuracy: 0.491616\n",
      "epoch: 102 - cost: 2.19045 mse:  11.0469764208 - -train accuracy: 0.508651\n",
      "epoch: 103 - cost: 2.09711 mse:  10.6165581248 - -train accuracy: 0.491616\n",
      "epoch: 104 - cost: 2.17765 mse:  10.9534818629 - -train accuracy: 0.508917\n",
      "epoch: 105 - cost: 2.08674 mse:  10.5291114632 - -train accuracy: 0.491616\n",
      "epoch: 106 - cost: 2.16505 mse:  10.8632548679 - -train accuracy: 0.508917\n",
      "epoch: 107 - cost: 2.07657 mse:  10.4442652818 - -train accuracy: 0.491616\n",
      "epoch: 108 - cost: 2.15275 mse:  10.7771525037 - -train accuracy: 0.508917\n",
      "epoch: 109 - cost: 2.0665 mse:  10.3615680232 - -train accuracy: 0.491616\n",
      "epoch: 110 - cost: 2.14076 mse:  10.6943358801 - -train accuracy: 0.508917\n",
      "epoch: 111 - cost: 2.05654 mse:  10.2807095601 - -train accuracy: 0.492148\n",
      "epoch: 112 - cost: 2.12887 mse:  10.6130757867 - -train accuracy: 0.508917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 113 - cost: 2.04683 mse:  10.2018393729 - -train accuracy: 0.492148\n",
      "epoch: 114 - cost: 2.11726 mse:  10.533943857 - -train accuracy: 0.508917\n",
      "epoch: 115 - cost: 2.03706 mse:  10.1245182543 - -train accuracy: 0.492414\n",
      "epoch: 116 - cost: 2.10572 mse:  10.4564802944 - -train accuracy: 0.509183\n",
      "epoch: 117 - cost: 2.02754 mse:  10.0491555465 - -train accuracy: 0.492414\n",
      "epoch: 118 - cost: 2.09482 mse:  10.3844182708 - -train accuracy: 0.509183\n",
      "epoch: 119 - cost: 2.01812 mse:  9.97598454539 - -train accuracy: 0.49268\n",
      "epoch: 120 - cost: 2.08391 mse:  10.3125759316 - -train accuracy: 0.508917\n",
      "epoch: 121 - cost: 2.00852 mse:  9.9031901039 - -train accuracy: 0.492947\n",
      "epoch: 122 - cost: 2.07317 mse:  10.2423971304 - -train accuracy: 0.508917\n",
      "epoch: 123 - cost: 1.99941 mse:  9.83254705888 - -train accuracy: 0.492947\n",
      "epoch: 124 - cost: 2.06278 mse:  10.175064847 - -train accuracy: 0.508917\n",
      "epoch: 125 - cost: 1.9902 mse:  9.76429609048 - -train accuracy: 0.492947\n",
      "epoch: 126 - cost: 2.05245 mse:  10.1109353491 - -train accuracy: 0.508917\n",
      "epoch: 127 - cost: 1.98096 mse:  9.69870226675 - -train accuracy: 0.493213\n",
      "epoch: 128 - cost: 2.04205 mse:  10.0485474482 - -train accuracy: 0.508917\n",
      "epoch: 129 - cost: 1.97202 mse:  9.636536439 - -train accuracy: 0.493479\n",
      "epoch: 130 - cost: 2.03165 mse:  9.98684106074 - -train accuracy: 0.508917\n",
      "epoch: 131 - cost: 1.96307 mse:  9.5763910077 - -train accuracy: 0.493745\n",
      "epoch: 132 - cost: 2.02139 mse:  9.92725750989 - -train accuracy: 0.508384\n",
      "epoch: 133 - cost: 1.95427 mse:  9.51742976453 - -train accuracy: 0.493745\n",
      "epoch: 134 - cost: 2.01147 mse:  9.8703198936 - -train accuracy: 0.508384\n",
      "epoch: 135 - cost: 1.94554 mse:  9.45975821166 - -train accuracy: 0.493745\n",
      "epoch: 136 - cost: 2.00147 mse:  9.81343805054 - -train accuracy: 0.508384\n",
      "epoch: 137 - cost: 1.93712 mse:  9.40345245476 - -train accuracy: 0.494277\n",
      "epoch: 138 - cost: 1.99174 mse:  9.75856947493 - -train accuracy: 0.508384\n",
      "epoch: 139 - cost: 1.92867 mse:  9.34893259665 - -train accuracy: 0.494544\n",
      "epoch: 140 - cost: 1.98222 mse:  9.7063523934 - -train accuracy: 0.508384\n",
      "epoch: 141 - cost: 1.92035 mse:  9.29646672093 - -train accuracy: 0.494544\n",
      "epoch: 142 - cost: 1.97259 mse:  9.65427277093 - -train accuracy: 0.508384\n",
      "epoch: 143 - cost: 1.91225 mse:  9.24450026382 - -train accuracy: 0.494544\n",
      "epoch: 144 - cost: 1.96325 mse:  9.6028845102 - -train accuracy: 0.508384\n",
      "epoch: 145 - cost: 1.90425 mse:  9.19384579474 - -train accuracy: 0.494544\n",
      "epoch: 146 - cost: 1.95404 mse:  9.55194816934 - -train accuracy: 0.508384\n",
      "epoch: 147 - cost: 1.89622 mse:  9.14282496208 - -train accuracy: 0.494544\n",
      "epoch: 148 - cost: 1.94494 mse:  9.50109344835 - -train accuracy: 0.508384\n",
      "epoch: 149 - cost: 1.88838 mse:  9.09316260958 - -train accuracy: 0.494544\n",
      "epoch: 150 - cost: 1.93597 mse:  9.45172805328 - -train accuracy: 0.508384\n",
      "epoch: 151 - cost: 1.88058 mse:  9.04531562014 - -train accuracy: 0.494544\n",
      "epoch: 152 - cost: 1.92692 mse:  9.4035433098 - -train accuracy: 0.508384\n",
      "epoch: 153 - cost: 1.8729 mse:  8.99803756357 - -train accuracy: 0.494544\n",
      "epoch: 154 - cost: 1.91804 mse:  9.35549748398 - -train accuracy: 0.508384\n",
      "epoch: 155 - cost: 1.86533 mse:  8.95076683501 - -train accuracy: 0.49481\n",
      "epoch: 156 - cost: 1.90927 mse:  9.30708217076 - -train accuracy: 0.508384\n",
      "epoch: 157 - cost: 1.85809 mse:  8.90424821169 - -train accuracy: 0.495076\n",
      "epoch: 158 - cost: 1.9006 mse:  9.25900306414 - -train accuracy: 0.508384\n",
      "epoch: 159 - cost: 1.85069 mse:  8.85788478749 - -train accuracy: 0.495608\n",
      "epoch: 160 - cost: 1.89207 mse:  9.21165887715 - -train accuracy: 0.508384\n",
      "epoch: 161 - cost: 1.84341 mse:  8.81164228628 - -train accuracy: 0.495608\n",
      "epoch: 162 - cost: 1.88365 mse:  9.16494297648 - -train accuracy: 0.508384\n",
      "epoch: 163 - cost: 1.83619 mse:  8.76652438113 - -train accuracy: 0.495874\n",
      "epoch: 164 - cost: 1.87532 mse:  9.11808821558 - -train accuracy: 0.508384\n",
      "epoch: 165 - cost: 1.82902 mse:  8.72167212307 - -train accuracy: 0.496141\n",
      "epoch: 166 - cost: 1.86713 mse:  9.07247488295 - -train accuracy: 0.508384\n",
      "epoch: 167 - cost: 1.82188 mse:  8.67779019195 - -train accuracy: 0.496407\n",
      "epoch: 168 - cost: 1.85895 mse:  9.02747014349 - -train accuracy: 0.508651\n",
      "epoch: 169 - cost: 1.81481 mse:  8.63436815439 - -train accuracy: 0.496407\n",
      "epoch: 170 - cost: 1.85085 mse:  8.98315772245 - -train accuracy: 0.508651\n",
      "epoch: 171 - cost: 1.80771 mse:  8.59108141767 - -train accuracy: 0.496673\n",
      "epoch: 172 - cost: 1.84274 mse:  8.93807929071 - -train accuracy: 0.508651\n",
      "epoch: 173 - cost: 1.8007 mse:  8.54879623461 - -train accuracy: 0.497205\n",
      "epoch: 174 - cost: 1.83464 mse:  8.89465720046 - -train accuracy: 0.508651\n",
      "epoch: 175 - cost: 1.79382 mse:  8.50735236151 - -train accuracy: 0.497471\n",
      "epoch: 176 - cost: 1.82673 mse:  8.85228480111 - -train accuracy: 0.508651\n",
      "epoch: 177 - cost: 1.78681 mse:  8.46552532242 - -train accuracy: 0.497205\n",
      "epoch: 178 - cost: 1.81893 mse:  8.8097162726 - -train accuracy: 0.508651\n",
      "epoch: 179 - cost: 1.7799 mse:  8.42403926653 - -train accuracy: 0.497471\n",
      "epoch: 180 - cost: 1.81117 mse:  8.76747078552 - -train accuracy: 0.508651\n",
      "epoch: 181 - cost: 1.77318 mse:  8.38248633615 - -train accuracy: 0.497471\n",
      "epoch: 182 - cost: 1.8036 mse:  8.72558505438 - -train accuracy: 0.508651\n",
      "epoch: 183 - cost: 1.76638 mse:  8.34196280511 - -train accuracy: 0.497738\n",
      "epoch: 184 - cost: 1.79603 mse:  8.68463184721 - -train accuracy: 0.508651\n",
      "epoch: 185 - cost: 1.75957 mse:  8.30239473121 - -train accuracy: 0.497738\n",
      "epoch: 186 - cost: 1.78846 mse:  8.64446778304 - -train accuracy: 0.508651\n",
      "epoch: 187 - cost: 1.75279 mse:  8.26364849857 - -train accuracy: 0.497738\n",
      "epoch: 188 - cost: 1.78088 mse:  8.60516370289 - -train accuracy: 0.508651\n",
      "epoch: 189 - cost: 1.74618 mse:  8.22567004384 - -train accuracy: 0.497738\n",
      "epoch: 190 - cost: 1.7735 mse:  8.56622882401 - -train accuracy: 0.508917\n",
      "epoch: 191 - cost: 1.73956 mse:  8.18776435145 - -train accuracy: 0.497738\n",
      "epoch: 192 - cost: 1.76611 mse:  8.52732183223 - -train accuracy: 0.508917\n",
      "epoch: 193 - cost: 1.7329 mse:  8.14978875301 - -train accuracy: 0.497738\n",
      "epoch: 194 - cost: 1.75882 mse:  8.48993336351 - -train accuracy: 0.508917\n",
      "epoch: 195 - cost: 1.72634 mse:  8.11331136251 - -train accuracy: 0.497471\n",
      "epoch: 196 - cost: 1.75159 mse:  8.45432789869 - -train accuracy: 0.508917\n",
      "epoch: 197 - cost: 1.71985 mse:  8.07858489048 - -train accuracy: 0.497205\n",
      "epoch: 198 - cost: 1.74427 mse:  8.41946072895 - -train accuracy: 0.509183\n",
      "epoch: 199 - cost: 1.71328 mse:  8.044159421 - -train accuracy: 0.497205\n",
      "epoch: 200 - cost: 1.73701 mse:  8.38576469251 - -train accuracy: 0.509449\n",
      "epoch: 201 - cost: 1.7067 mse:  8.01032714771 - -train accuracy: 0.497471\n",
      "epoch: 202 - cost: 1.72979 mse:  8.35262168356 - -train accuracy: 0.509449\n",
      "epoch: 203 - cost: 1.70017 mse:  7.97714277956 - -train accuracy: 0.498004\n",
      "epoch: 204 - cost: 1.72262 mse:  8.31994681005 - -train accuracy: 0.509449\n",
      "epoch: 205 - cost: 1.69366 mse:  7.94432378015 - -train accuracy: 0.49827\n",
      "epoch: 206 - cost: 1.7156 mse:  8.28764448408 - -train accuracy: 0.509449\n",
      "epoch: 207 - cost: 1.6872 mse:  7.91186391551 - -train accuracy: 0.49827\n",
      "epoch: 208 - cost: 1.70858 mse:  8.25589622442 - -train accuracy: 0.509449\n",
      "epoch: 209 - cost: 1.68068 mse:  7.88021200722 - -train accuracy: 0.49827\n",
      "epoch: 210 - cost: 1.70146 mse:  8.22416988407 - -train accuracy: 0.509449\n",
      "epoch: 211 - cost: 1.67436 mse:  7.84928973779 - -train accuracy: 0.498536\n",
      "epoch: 212 - cost: 1.69458 mse:  8.19460547603 - -train accuracy: 0.509449\n",
      "epoch: 213 - cost: 1.66807 mse:  7.81788134823 - -train accuracy: 0.498802\n",
      "epoch: 214 - cost: 1.68764 mse:  8.16383152618 - -train accuracy: 0.509449\n",
      "epoch: 215 - cost: 1.66173 mse:  7.78695520386 - -train accuracy: 0.499068\n",
      "epoch: 216 - cost: 1.68086 mse:  8.13415476468 - -train accuracy: 0.509449\n",
      "epoch: 217 - cost: 1.65534 mse:  7.75548909291 - -train accuracy: 0.499068\n",
      "epoch: 218 - cost: 1.67419 mse:  8.10524241457 - -train accuracy: 0.509449\n",
      "epoch: 219 - cost: 1.64891 mse:  7.72415420731 - -train accuracy: 0.499601\n",
      "epoch: 220 - cost: 1.66738 mse:  8.07474417887 - -train accuracy: 0.509449\n",
      "epoch: 221 - cost: 1.64261 mse:  7.69324626604 - -train accuracy: 0.499601\n",
      "epoch: 222 - cost: 1.66067 mse:  8.04547657279 - -train accuracy: 0.509449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 223 - cost: 1.63641 mse:  7.66283667428 - -train accuracy: 0.499601\n",
      "epoch: 224 - cost: 1.65407 mse:  8.01642374724 - -train accuracy: 0.509715\n",
      "epoch: 225 - cost: 1.63018 mse:  7.63211584389 - -train accuracy: 0.499601\n",
      "epoch: 226 - cost: 1.64751 mse:  7.98707568926 - -train accuracy: 0.509981\n",
      "epoch: 227 - cost: 1.62401 mse:  7.60137136526 - -train accuracy: 0.499601\n",
      "epoch: 228 - cost: 1.64113 mse:  7.95766792604 - -train accuracy: 0.509981\n",
      "epoch: 229 - cost: 1.61784 mse:  7.57056917821 - -train accuracy: 0.500399\n",
      "epoch: 230 - cost: 1.63477 mse:  7.92865292319 - -train accuracy: 0.509981\n",
      "epoch: 231 - cost: 1.61183 mse:  7.54155656993 - -train accuracy: 0.501198\n",
      "epoch: 232 - cost: 1.62841 mse:  7.90141135904 - -train accuracy: 0.510248\n",
      "epoch: 233 - cost: 1.60569 mse:  7.51301067641 - -train accuracy: 0.501198\n",
      "epoch: 234 - cost: 1.622 mse:  7.87438854647 - -train accuracy: 0.510248\n",
      "epoch: 235 - cost: 1.59967 mse:  7.48521588701 - -train accuracy: 0.50173\n",
      "epoch: 236 - cost: 1.6157 mse:  7.84810402378 - -train accuracy: 0.510248\n",
      "epoch: 237 - cost: 1.59361 mse:  7.45828208174 - -train accuracy: 0.50173\n",
      "epoch: 238 - cost: 1.60938 mse:  7.82195441751 - -train accuracy: 0.510248\n",
      "epoch: 239 - cost: 1.58762 mse:  7.43073622728 - -train accuracy: 0.501996\n",
      "epoch: 240 - cost: 1.60314 mse:  7.79485449376 - -train accuracy: 0.509981\n",
      "epoch: 241 - cost: 1.58173 mse:  7.40288369992 - -train accuracy: 0.502262\n",
      "epoch: 242 - cost: 1.597 mse:  7.76761903915 - -train accuracy: 0.510248\n",
      "epoch: 243 - cost: 1.57592 mse:  7.37415376831 - -train accuracy: 0.502262\n",
      "epoch: 244 - cost: 1.59101 mse:  7.73972345502 - -train accuracy: 0.510248\n",
      "epoch: 245 - cost: 1.57026 mse:  7.34581504713 - -train accuracy: 0.502529\n",
      "epoch: 246 - cost: 1.58508 mse:  7.71214583003 - -train accuracy: 0.510248\n",
      "epoch: 247 - cost: 1.56461 mse:  7.31810488172 - -train accuracy: 0.502529\n",
      "epoch: 248 - cost: 1.57914 mse:  7.6849229752 - -train accuracy: 0.510248\n",
      "epoch: 249 - cost: 1.55893 mse:  7.29020202675 - -train accuracy: 0.502795\n",
      "epoch: 250 - cost: 1.57325 mse:  7.65816540135 - -train accuracy: 0.51078\n",
      "epoch: 251 - cost: 1.55326 mse:  7.26246692533 - -train accuracy: 0.503061\n",
      "epoch: 252 - cost: 1.56731 mse:  7.63028051893 - -train accuracy: 0.511046\n",
      "epoch: 253 - cost: 1.54771 mse:  7.23515257274 - -train accuracy: 0.503061\n",
      "epoch: 254 - cost: 1.56156 mse:  7.60346363015 - -train accuracy: 0.511046\n",
      "epoch: 255 - cost: 1.54226 mse:  7.20833455531 - -train accuracy: 0.503327\n",
      "epoch: 256 - cost: 1.55591 mse:  7.57783121921 - -train accuracy: 0.511046\n",
      "epoch: 257 - cost: 1.5367 mse:  7.18218807354 - -train accuracy: 0.503859\n",
      "epoch: 258 - cost: 1.55019 mse:  7.55330859538 - -train accuracy: 0.511312\n",
      "epoch: 259 - cost: 1.53125 mse:  7.15696764757 - -train accuracy: 0.503859\n",
      "epoch: 260 - cost: 1.54441 mse:  7.52809992696 - -train accuracy: 0.511312\n",
      "epoch: 261 - cost: 1.5258 mse:  7.1312532975 - -train accuracy: 0.504126\n",
      "epoch: 262 - cost: 1.53888 mse:  7.50409132072 - -train accuracy: 0.511312\n",
      "epoch: 263 - cost: 1.52035 mse:  7.10591276624 - -train accuracy: 0.504392\n",
      "epoch: 264 - cost: 1.53331 mse:  7.47956225612 - -train accuracy: 0.511578\n",
      "epoch: 265 - cost: 1.51498 mse:  7.08029951871 - -train accuracy: 0.504392\n",
      "epoch: 266 - cost: 1.52774 mse:  7.45431072827 - -train accuracy: 0.512111\n",
      "epoch: 267 - cost: 1.50957 mse:  7.05447068577 - -train accuracy: 0.504658\n",
      "epoch: 268 - cost: 1.5222 mse:  7.42852004889 - -train accuracy: 0.512111\n",
      "epoch: 269 - cost: 1.50432 mse:  7.02886413307 - -train accuracy: 0.504658\n",
      "epoch: 270 - cost: 1.51673 mse:  7.40329808415 - -train accuracy: 0.512377\n",
      "epoch: 271 - cost: 1.49908 mse:  7.00408449022 - -train accuracy: 0.504658\n",
      "epoch: 272 - cost: 1.51131 mse:  7.37934935813 - -train accuracy: 0.512909\n",
      "epoch: 273 - cost: 1.49383 mse:  6.97952697105 - -train accuracy: 0.504658\n",
      "epoch: 274 - cost: 1.50595 mse:  7.35484500041 - -train accuracy: 0.512909\n",
      "epoch: 275 - cost: 1.4886 mse:  6.95491363863 - -train accuracy: 0.504658\n",
      "epoch: 276 - cost: 1.50066 mse:  7.33145710851 - -train accuracy: 0.513442\n",
      "epoch: 277 - cost: 1.48335 mse:  6.93073012658 - -train accuracy: 0.504658\n",
      "epoch: 278 - cost: 1.49541 mse:  7.30839076804 - -train accuracy: 0.513442\n",
      "epoch: 279 - cost: 1.47817 mse:  6.90779085164 - -train accuracy: 0.50519\n",
      "epoch: 280 - cost: 1.49002 mse:  7.28629209256 - -train accuracy: 0.513708\n",
      "epoch: 281 - cost: 1.47307 mse:  6.88547477543 - -train accuracy: 0.505457\n",
      "epoch: 282 - cost: 1.48473 mse:  7.26532930641 - -train accuracy: 0.513708\n",
      "epoch: 283 - cost: 1.46791 mse:  6.86335923853 - -train accuracy: 0.505457\n",
      "epoch: 284 - cost: 1.47947 mse:  7.24387648679 - -train accuracy: 0.51424\n",
      "epoch: 285 - cost: 1.46271 mse:  6.84106393564 - -train accuracy: 0.505457\n",
      "epoch: 286 - cost: 1.47429 mse:  7.22280452099 - -train accuracy: 0.514772\n",
      "epoch: 287 - cost: 1.45759 mse:  6.81959358062 - -train accuracy: 0.505723\n",
      "epoch: 288 - cost: 1.46909 mse:  7.20234339761 - -train accuracy: 0.515305\n",
      "epoch: 289 - cost: 1.45249 mse:  6.79833255435 - -train accuracy: 0.506255\n",
      "epoch: 290 - cost: 1.46392 mse:  7.1817699819 - -train accuracy: 0.515571\n",
      "epoch: 291 - cost: 1.44747 mse:  6.77664921742 - -train accuracy: 0.506521\n",
      "epoch: 292 - cost: 1.45881 mse:  7.16045902179 - -train accuracy: 0.515571\n",
      "epoch: 293 - cost: 1.4424 mse:  6.7548296931 - -train accuracy: 0.506521\n",
      "epoch: 294 - cost: 1.45378 mse:  7.14011627498 - -train accuracy: 0.515571\n",
      "epoch: 295 - cost: 1.43741 mse:  6.7335951398 - -train accuracy: 0.506787\n",
      "epoch: 296 - cost: 1.44869 mse:  7.11972488796 - -train accuracy: 0.515571\n",
      "epoch: 297 - cost: 1.43239 mse:  6.71281061717 - -train accuracy: 0.506787\n",
      "epoch: 298 - cost: 1.44357 mse:  7.10017365019 - -train accuracy: 0.515837\n",
      "epoch: 299 - cost: 1.42743 mse:  6.69217212916 - -train accuracy: 0.506787\n",
      "epoch: 300 - cost: 1.43856 mse:  7.08140949075 - -train accuracy: 0.515837\n",
      "epoch: 301 - cost: 1.42246 mse:  6.67211085673 - -train accuracy: 0.507053\n",
      "epoch: 302 - cost: 1.43352 mse:  7.06229341794 - -train accuracy: 0.516369\n",
      "epoch: 303 - cost: 1.41758 mse:  6.65290677877 - -train accuracy: 0.506787\n",
      "epoch: 304 - cost: 1.42856 mse:  7.04379861856 - -train accuracy: 0.516902\n",
      "epoch: 305 - cost: 1.41266 mse:  6.63352175387 - -train accuracy: 0.507053\n",
      "epoch: 306 - cost: 1.42358 mse:  7.02482987009 - -train accuracy: 0.517168\n",
      "epoch: 307 - cost: 1.40785 mse:  6.61395936926 - -train accuracy: 0.507053\n",
      "epoch: 308 - cost: 1.41865 mse:  7.00571215727 - -train accuracy: 0.517434\n",
      "epoch: 309 - cost: 1.40309 mse:  6.59428923108 - -train accuracy: 0.507852\n",
      "epoch: 310 - cost: 1.41386 mse:  6.98688140228 - -train accuracy: 0.517434\n",
      "epoch: 311 - cost: 1.3983 mse:  6.57481113797 - -train accuracy: 0.507852\n",
      "epoch: 312 - cost: 1.40904 mse:  6.96743038999 - -train accuracy: 0.517434\n",
      "epoch: 313 - cost: 1.39364 mse:  6.55551548264 - -train accuracy: 0.508118\n",
      "epoch: 314 - cost: 1.4043 mse:  6.94848396945 - -train accuracy: 0.517434\n",
      "epoch: 315 - cost: 1.38899 mse:  6.53680168169 - -train accuracy: 0.508118\n",
      "epoch: 316 - cost: 1.39953 mse:  6.93068599883 - -train accuracy: 0.5177\n",
      "epoch: 317 - cost: 1.38421 mse:  6.51831349438 - -train accuracy: 0.508384\n",
      "epoch: 318 - cost: 1.3948 mse:  6.9138964776 - -train accuracy: 0.5177\n",
      "epoch: 319 - cost: 1.3795 mse:  6.49983791601 - -train accuracy: 0.508384\n",
      "epoch: 320 - cost: 1.39008 mse:  6.89566977826 - -train accuracy: 0.517966\n",
      "epoch: 321 - cost: 1.37487 mse:  6.48126502418 - -train accuracy: 0.508917\n",
      "epoch: 322 - cost: 1.38535 mse:  6.87699883477 - -train accuracy: 0.5177\n",
      "epoch: 323 - cost: 1.37028 mse:  6.46226395698 - -train accuracy: 0.509715\n",
      "epoch: 324 - cost: 1.38075 mse:  6.858248874 - -train accuracy: 0.517966\n",
      "epoch: 325 - cost: 1.36568 mse:  6.44305428679 - -train accuracy: 0.509981\n",
      "epoch: 326 - cost: 1.37612 mse:  6.8396885619 - -train accuracy: 0.518499\n",
      "epoch: 327 - cost: 1.36116 mse:  6.42476466037 - -train accuracy: 0.510248\n",
      "epoch: 328 - cost: 1.37153 mse:  6.82117249682 - -train accuracy: 0.519031\n",
      "epoch: 329 - cost: 1.35661 mse:  6.40598096412 - -train accuracy: 0.510248\n",
      "epoch: 330 - cost: 1.36704 mse:  6.80319619799 - -train accuracy: 0.519297\n",
      "epoch: 331 - cost: 1.35208 mse:  6.38804550704 - -train accuracy: 0.510514\n",
      "epoch: 332 - cost: 1.36245 mse:  6.78545308187 - -train accuracy: 0.519563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 333 - cost: 1.34758 mse:  6.37076599421 - -train accuracy: 0.51078\n",
      "epoch: 334 - cost: 1.35791 mse:  6.76924208852 - -train accuracy: 0.520362\n",
      "epoch: 335 - cost: 1.34306 mse:  6.35444203094 - -train accuracy: 0.510514\n",
      "epoch: 336 - cost: 1.3533 mse:  6.75287327166 - -train accuracy: 0.520628\n",
      "epoch: 337 - cost: 1.3385 mse:  6.33726813012 - -train accuracy: 0.51078\n",
      "epoch: 338 - cost: 1.34884 mse:  6.7364259979 - -train accuracy: 0.52116\n",
      "epoch: 339 - cost: 1.334 mse:  6.32030167765 - -train accuracy: 0.51078\n",
      "epoch: 340 - cost: 1.34439 mse:  6.72050137385 - -train accuracy: 0.521427\n",
      "epoch: 341 - cost: 1.3295 mse:  6.30347961627 - -train accuracy: 0.51078\n",
      "epoch: 342 - cost: 1.33989 mse:  6.70415650651 - -train accuracy: 0.521427\n",
      "epoch: 343 - cost: 1.32504 mse:  6.2859675388 - -train accuracy: 0.51078\n",
      "epoch: 344 - cost: 1.3355 mse:  6.68776683772 - -train accuracy: 0.522225\n",
      "epoch: 345 - cost: 1.32067 mse:  6.27006426575 - -train accuracy: 0.511312\n",
      "epoch: 346 - cost: 1.33104 mse:  6.67175897141 - -train accuracy: 0.522225\n",
      "epoch: 347 - cost: 1.31632 mse:  6.25450092404 - -train accuracy: 0.511312\n",
      "epoch: 348 - cost: 1.32669 mse:  6.65682756148 - -train accuracy: 0.522491\n",
      "epoch: 349 - cost: 1.31194 mse:  6.23917709558 - -train accuracy: 0.511312\n",
      "epoch: 350 - cost: 1.32222 mse:  6.64215793456 - -train accuracy: 0.522491\n",
      "epoch: 351 - cost: 1.30761 mse:  6.2243080477 - -train accuracy: 0.511845\n",
      "epoch: 352 - cost: 1.31787 mse:  6.62830074659 - -train accuracy: 0.522491\n",
      "epoch: 353 - cost: 1.30323 mse:  6.20855986271 - -train accuracy: 0.511845\n",
      "epoch: 354 - cost: 1.31357 mse:  6.61301946298 - -train accuracy: 0.522491\n",
      "epoch: 355 - cost: 1.29903 mse:  6.19297293463 - -train accuracy: 0.512377\n",
      "epoch: 356 - cost: 1.30931 mse:  6.59782582875 - -train accuracy: 0.522758\n",
      "epoch: 357 - cost: 1.29476 mse:  6.17794113643 - -train accuracy: 0.512111\n",
      "epoch: 358 - cost: 1.305 mse:  6.58300796232 - -train accuracy: 0.522758\n",
      "epoch: 359 - cost: 1.29049 mse:  6.16265495345 - -train accuracy: 0.512643\n",
      "epoch: 360 - cost: 1.30077 mse:  6.56832006832 - -train accuracy: 0.523556\n",
      "epoch: 361 - cost: 1.28625 mse:  6.14748252172 - -train accuracy: 0.512643\n",
      "epoch: 362 - cost: 1.29656 mse:  6.55281116818 - -train accuracy: 0.523556\n",
      "epoch: 363 - cost: 1.28206 mse:  6.1318351632 - -train accuracy: 0.512909\n",
      "epoch: 364 - cost: 1.29243 mse:  6.537500636 - -train accuracy: 0.524355\n",
      "epoch: 365 - cost: 1.27791 mse:  6.11676603721 - -train accuracy: 0.512909\n",
      "epoch: 366 - cost: 1.2883 mse:  6.52252148544 - -train accuracy: 0.524887\n",
      "epoch: 367 - cost: 1.27381 mse:  6.10210653922 - -train accuracy: 0.512909\n",
      "epoch: 368 - cost: 1.28417 mse:  6.50828291684 - -train accuracy: 0.525685\n",
      "epoch: 369 - cost: 1.26976 mse:  6.08776096606 - -train accuracy: 0.513175\n",
      "epoch: 370 - cost: 1.28012 mse:  6.49447139634 - -train accuracy: 0.526218\n",
      "epoch: 371 - cost: 1.26569 mse:  6.07367947058 - -train accuracy: 0.513442\n",
      "epoch: 372 - cost: 1.27611 mse:  6.48141563876 - -train accuracy: 0.526484\n",
      "epoch: 373 - cost: 1.26159 mse:  6.05899258449 - -train accuracy: 0.513442\n",
      "epoch: 374 - cost: 1.27205 mse:  6.46793670639 - -train accuracy: 0.52675\n",
      "epoch: 375 - cost: 1.25744 mse:  6.04407315046 - -train accuracy: 0.513974\n",
      "epoch: 376 - cost: 1.26804 mse:  6.45313801243 - -train accuracy: 0.52675\n",
      "epoch: 377 - cost: 1.25346 mse:  6.02999555128 - -train accuracy: 0.51424\n",
      "epoch: 378 - cost: 1.26409 mse:  6.44030405145 - -train accuracy: 0.527016\n",
      "epoch: 379 - cost: 1.24944 mse:  6.01649785596 - -train accuracy: 0.513974\n",
      "epoch: 380 - cost: 1.26013 mse:  6.42682481388 - -train accuracy: 0.527016\n",
      "epoch: 381 - cost: 1.24551 mse:  6.00334133639 - -train accuracy: 0.514772\n",
      "epoch: 382 - cost: 1.2562 mse:  6.41337980928 - -train accuracy: 0.527549\n",
      "epoch: 383 - cost: 1.24157 mse:  5.9890943716 - -train accuracy: 0.515305\n",
      "epoch: 384 - cost: 1.25231 mse:  6.39946274198 - -train accuracy: 0.527549\n",
      "epoch: 385 - cost: 1.23769 mse:  5.97588698085 - -train accuracy: 0.516103\n",
      "epoch: 386 - cost: 1.24838 mse:  6.3860769957 - -train accuracy: 0.527549\n",
      "epoch: 387 - cost: 1.23373 mse:  5.96221775474 - -train accuracy: 0.516636\n",
      "epoch: 388 - cost: 1.24442 mse:  6.37221486756 - -train accuracy: 0.527815\n",
      "epoch: 389 - cost: 1.22983 mse:  5.94884865827 - -train accuracy: 0.516902\n",
      "epoch: 390 - cost: 1.24047 mse:  6.35841368234 - -train accuracy: 0.528081\n",
      "epoch: 391 - cost: 1.22594 mse:  5.93553089991 - -train accuracy: 0.517434\n",
      "epoch: 392 - cost: 1.23659 mse:  6.34507659181 - -train accuracy: 0.528081\n",
      "epoch: 393 - cost: 1.22211 mse:  5.92192339353 - -train accuracy: 0.517434\n",
      "epoch: 394 - cost: 1.23277 mse:  6.33108981237 - -train accuracy: 0.528081\n",
      "epoch: 395 - cost: 1.21821 mse:  5.90878852845 - -train accuracy: 0.517434\n",
      "epoch: 396 - cost: 1.22892 mse:  6.31777867756 - -train accuracy: 0.528613\n",
      "epoch: 397 - cost: 1.21441 mse:  5.89619509972 - -train accuracy: 0.517966\n",
      "epoch: 398 - cost: 1.22514 mse:  6.30494255938 - -train accuracy: 0.528613\n",
      "epoch: 399 - cost: 1.21066 mse:  5.88338667399 - -train accuracy: 0.518765\n",
      "epoch: 400 - cost: 1.22138 mse:  6.29226445408 - -train accuracy: 0.529146\n",
      "epoch: 401 - cost: 1.20691 mse:  5.87058940941 - -train accuracy: 0.519031\n",
      "epoch: 402 - cost: 1.21765 mse:  6.27910001109 - -train accuracy: 0.529146\n",
      "epoch: 403 - cost: 1.20319 mse:  5.85814448629 - -train accuracy: 0.518765\n",
      "epoch: 404 - cost: 1.21394 mse:  6.26602674127 - -train accuracy: 0.529412\n",
      "epoch: 405 - cost: 1.19945 mse:  5.84504413922 - -train accuracy: 0.519031\n",
      "epoch: 406 - cost: 1.21026 mse:  6.25260509725 - -train accuracy: 0.53021\n",
      "epoch: 407 - cost: 1.19578 mse:  5.83260694578 - -train accuracy: 0.519031\n",
      "epoch: 408 - cost: 1.20661 mse:  6.2398539502 - -train accuracy: 0.531009\n",
      "epoch: 409 - cost: 1.19219 mse:  5.82023216343 - -train accuracy: 0.519563\n",
      "epoch: 410 - cost: 1.20305 mse:  6.22702921195 - -train accuracy: 0.531275\n",
      "epoch: 411 - cost: 1.18862 mse:  5.80763838068 - -train accuracy: 0.520096\n",
      "epoch: 412 - cost: 1.19947 mse:  6.21369621917 - -train accuracy: 0.531541\n",
      "epoch: 413 - cost: 1.18503 mse:  5.79465432974 - -train accuracy: 0.520362\n",
      "epoch: 414 - cost: 1.19594 mse:  6.2004406669 - -train accuracy: 0.531807\n",
      "epoch: 415 - cost: 1.18146 mse:  5.78197410842 - -train accuracy: 0.520096\n",
      "epoch: 416 - cost: 1.19236 mse:  6.18689320584 - -train accuracy: 0.53234\n",
      "epoch: 417 - cost: 1.17795 mse:  5.76921805896 - -train accuracy: 0.520362\n",
      "epoch: 418 - cost: 1.18887 mse:  6.17338169831 - -train accuracy: 0.532606\n",
      "epoch: 419 - cost: 1.17443 mse:  5.75710988506 - -train accuracy: 0.52116\n",
      "epoch: 420 - cost: 1.1853 mse:  6.16081358609 - -train accuracy: 0.53234\n",
      "epoch: 421 - cost: 1.17092 mse:  5.74521763572 - -train accuracy: 0.52116\n",
      "epoch: 422 - cost: 1.18182 mse:  6.14805985716 - -train accuracy: 0.53234\n",
      "epoch: 423 - cost: 1.16746 mse:  5.73308327556 - -train accuracy: 0.521427\n",
      "epoch: 424 - cost: 1.1783 mse:  6.13541664112 - -train accuracy: 0.53234\n",
      "epoch: 425 - cost: 1.16392 mse:  5.7207878584 - -train accuracy: 0.522491\n",
      "epoch: 426 - cost: 1.17482 mse:  6.12211418449 - -train accuracy: 0.53234\n",
      "epoch: 427 - cost: 1.16046 mse:  5.70834473616 - -train accuracy: 0.522491\n",
      "epoch: 428 - cost: 1.17137 mse:  6.10921677868 - -train accuracy: 0.53234\n",
      "epoch: 429 - cost: 1.15697 mse:  5.69655822617 - -train accuracy: 0.523024\n",
      "epoch: 430 - cost: 1.16792 mse:  6.09679812926 - -train accuracy: 0.532606\n",
      "epoch: 431 - cost: 1.15351 mse:  5.68492925106 - -train accuracy: 0.52329\n",
      "epoch: 432 - cost: 1.16446 mse:  6.08421112765 - -train accuracy: 0.532872\n",
      "epoch: 433 - cost: 1.15003 mse:  5.67273011127 - -train accuracy: 0.52329\n",
      "epoch: 434 - cost: 1.16103 mse:  6.07168161909 - -train accuracy: 0.533138\n",
      "epoch: 435 - cost: 1.14661 mse:  5.66154555135 - -train accuracy: 0.523556\n",
      "epoch: 436 - cost: 1.15761 mse:  6.0600115864 - -train accuracy: 0.533138\n",
      "epoch: 437 - cost: 1.14325 mse:  5.65051153449 - -train accuracy: 0.523556\n",
      "epoch: 438 - cost: 1.15425 mse:  6.04841481035 - -train accuracy: 0.533404\n",
      "epoch: 439 - cost: 1.13986 mse:  5.63929239864 - -train accuracy: 0.524088\n",
      "epoch: 440 - cost: 1.15088 mse:  6.03635921179 - -train accuracy: 0.533937\n",
      "epoch: 441 - cost: 1.13647 mse:  5.62772713208 - -train accuracy: 0.524621\n",
      "epoch: 442 - cost: 1.14759 mse:  6.02485349541 - -train accuracy: 0.533937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 443 - cost: 1.13314 mse:  5.61671691671 - -train accuracy: 0.525685\n",
      "epoch: 444 - cost: 1.14426 mse:  6.01467834515 - -train accuracy: 0.534203\n",
      "epoch: 445 - cost: 1.12974 mse:  5.60694834735 - -train accuracy: 0.526218\n",
      "epoch: 446 - cost: 1.14088 mse:  6.0050486914 - -train accuracy: 0.534469\n",
      "epoch: 447 - cost: 1.12637 mse:  5.5979432235 - -train accuracy: 0.526484\n",
      "epoch: 448 - cost: 1.13753 mse:  5.9958650694 - -train accuracy: 0.535534\n",
      "epoch: 449 - cost: 1.12297 mse:  5.58856809045 - -train accuracy: 0.526484\n",
      "epoch: 450 - cost: 1.13423 mse:  5.98665553563 - -train accuracy: 0.536332\n",
      "epoch: 451 - cost: 1.1196 mse:  5.57945253937 - -train accuracy: 0.52675\n",
      "epoch: 452 - cost: 1.13097 mse:  5.97760669748 - -train accuracy: 0.536598\n",
      "epoch: 453 - cost: 1.11626 mse:  5.57052671011 - -train accuracy: 0.527016\n",
      "epoch: 454 - cost: 1.12765 mse:  5.96773281837 - -train accuracy: 0.536598\n",
      "epoch: 455 - cost: 1.11295 mse:  5.56092737928 - -train accuracy: 0.527016\n",
      "epoch: 456 - cost: 1.12443 mse:  5.95832676562 - -train accuracy: 0.536332\n",
      "epoch: 457 - cost: 1.10967 mse:  5.55210784177 - -train accuracy: 0.527549\n",
      "epoch: 458 - cost: 1.1212 mse:  5.94933580792 - -train accuracy: 0.536865\n",
      "epoch: 459 - cost: 1.1064 mse:  5.54380904181 - -train accuracy: 0.527815\n",
      "epoch: 460 - cost: 1.11797 mse:  5.94095002701 - -train accuracy: 0.537663\n",
      "epoch: 461 - cost: 1.10312 mse:  5.53530913296 - -train accuracy: 0.528081\n",
      "epoch: 462 - cost: 1.11474 mse:  5.93223939286 - -train accuracy: 0.538195\n",
      "epoch: 463 - cost: 1.09986 mse:  5.5263486923 - -train accuracy: 0.528081\n",
      "epoch: 464 - cost: 1.1115 mse:  5.92242600117 - -train accuracy: 0.538728\n",
      "epoch: 465 - cost: 1.09666 mse:  5.51715363333 - -train accuracy: 0.527815\n",
      "epoch: 466 - cost: 1.10832 mse:  5.91283731078 - -train accuracy: 0.538994\n",
      "epoch: 467 - cost: 1.09345 mse:  5.507750215 - -train accuracy: 0.527815\n",
      "epoch: 468 - cost: 1.1051 mse:  5.90289439173 - -train accuracy: 0.538994\n",
      "epoch: 469 - cost: 1.09025 mse:  5.49847389832 - -train accuracy: 0.528081\n",
      "epoch: 470 - cost: 1.10197 mse:  5.89308177557 - -train accuracy: 0.539792\n",
      "epoch: 471 - cost: 1.08707 mse:  5.48917595309 - -train accuracy: 0.528081\n",
      "epoch: 472 - cost: 1.09881 mse:  5.88241511388 - -train accuracy: 0.540325\n",
      "epoch: 473 - cost: 1.08394 mse:  5.47959238995 - -train accuracy: 0.528081\n",
      "epoch: 474 - cost: 1.0957 mse:  5.87227594283 - -train accuracy: 0.541389\n",
      "epoch: 475 - cost: 1.08079 mse:  5.46977048775 - -train accuracy: 0.528347\n",
      "epoch: 476 - cost: 1.09262 mse:  5.86144718051 - -train accuracy: 0.541656\n",
      "epoch: 477 - cost: 1.07775 mse:  5.4601256587 - -train accuracy: 0.528879\n",
      "epoch: 478 - cost: 1.08955 mse:  5.85087752476 - -train accuracy: 0.541922\n",
      "epoch: 479 - cost: 1.07471 mse:  5.45042251089 - -train accuracy: 0.528879\n",
      "epoch: 480 - cost: 1.08651 mse:  5.84002445335 - -train accuracy: 0.542454\n",
      "epoch: 481 - cost: 1.07168 mse:  5.44015104077 - -train accuracy: 0.529412\n",
      "epoch: 482 - cost: 1.08348 mse:  5.82902648577 - -train accuracy: 0.542188\n",
      "epoch: 483 - cost: 1.06865 mse:  5.43057453355 - -train accuracy: 0.529412\n",
      "epoch: 484 - cost: 1.0805 mse:  5.81878454647 - -train accuracy: 0.542188\n",
      "epoch: 485 - cost: 1.06564 mse:  5.42110049947 - -train accuracy: 0.529944\n",
      "epoch: 486 - cost: 1.07751 mse:  5.80872453175 - -train accuracy: 0.542986\n",
      "epoch: 487 - cost: 1.06267 mse:  5.4118652766 - -train accuracy: 0.530476\n",
      "epoch: 488 - cost: 1.07452 mse:  5.79911379691 - -train accuracy: 0.543253\n",
      "epoch: 489 - cost: 1.0597 mse:  5.40324974967 - -train accuracy: 0.530476\n",
      "epoch: 490 - cost: 1.07155 mse:  5.79012003002 - -train accuracy: 0.543519\n",
      "epoch: 491 - cost: 1.05674 mse:  5.39514400421 - -train accuracy: 0.53021\n",
      "epoch: 492 - cost: 1.06856 mse:  5.78088907888 - -train accuracy: 0.543785\n",
      "epoch: 493 - cost: 1.05377 mse:  5.38672138716 - -train accuracy: 0.53021\n",
      "epoch: 494 - cost: 1.06552 mse:  5.7714509097 - -train accuracy: 0.544583\n",
      "epoch: 495 - cost: 1.0508 mse:  5.37840870282 - -train accuracy: 0.529944\n",
      "epoch: 496 - cost: 1.06257 mse:  5.76311947531 - -train accuracy: 0.545382\n",
      "epoch: 497 - cost: 1.04785 mse:  5.37050263671 - -train accuracy: 0.53021\n",
      "epoch: 498 - cost: 1.05962 mse:  5.75451823374 - -train accuracy: 0.54618\n",
      "epoch: 499 - cost: 1.04489 mse:  5.36264505194 - -train accuracy: 0.53021\n",
      "epoch: 500 - cost: 1.05666 mse:  5.74601075502 - -train accuracy: 0.54618\n",
      "epoch: 501 - cost: 1.04197 mse:  5.35470140687 - -train accuracy: 0.530743\n",
      "epoch: 502 - cost: 1.05374 mse:  5.73729207458 - -train accuracy: 0.547245\n",
      "epoch: 503 - cost: 1.03908 mse:  5.34639280535 - -train accuracy: 0.531009\n",
      "epoch: 504 - cost: 1.05083 mse:  5.72801348837 - -train accuracy: 0.547777\n",
      "epoch: 505 - cost: 1.03617 mse:  5.33841559523 - -train accuracy: 0.531009\n",
      "epoch: 506 - cost: 1.04791 mse:  5.71925783479 - -train accuracy: 0.548576\n",
      "epoch: 507 - cost: 1.03326 mse:  5.33011439132 - -train accuracy: 0.531009\n",
      "epoch: 508 - cost: 1.04501 mse:  5.70970815403 - -train accuracy: 0.548576\n",
      "epoch: 509 - cost: 1.03043 mse:  5.32146388738 - -train accuracy: 0.530476\n",
      "epoch: 510 - cost: 1.04214 mse:  5.69982295876 - -train accuracy: 0.549108\n",
      "epoch: 511 - cost: 1.02756 mse:  5.31217035017 - -train accuracy: 0.531275\n",
      "epoch: 512 - cost: 1.03933 mse:  5.68939622785 - -train accuracy: 0.549907\n",
      "epoch: 513 - cost: 1.02482 mse:  5.30382128034 - -train accuracy: 0.532073\n",
      "epoch: 514 - cost: 1.03654 mse:  5.67933005785 - -train accuracy: 0.550439\n",
      "epoch: 515 - cost: 1.02203 mse:  5.29539266606 - -train accuracy: 0.532606\n",
      "epoch: 516 - cost: 1.03375 mse:  5.67021916088 - -train accuracy: 0.550972\n",
      "epoch: 517 - cost: 1.01925 mse:  5.2870437648 - -train accuracy: 0.532872\n",
      "epoch: 518 - cost: 1.03098 mse:  5.66075715158 - -train accuracy: 0.550972\n",
      "epoch: 519 - cost: 1.01652 mse:  5.27910603156 - -train accuracy: 0.532606\n",
      "epoch: 520 - cost: 1.02826 mse:  5.65154864726 - -train accuracy: 0.551504\n",
      "epoch: 521 - cost: 1.01376 mse:  5.27095466317 - -train accuracy: 0.533404\n",
      "epoch: 522 - cost: 1.02549 mse:  5.64199813529 - -train accuracy: 0.552569\n",
      "epoch: 523 - cost: 1.01095 mse:  5.26242117857 - -train accuracy: 0.534469\n",
      "epoch: 524 - cost: 1.02273 mse:  5.63300359109 - -train accuracy: 0.552835\n",
      "epoch: 525 - cost: 1.00825 mse:  5.25439191934 - -train accuracy: 0.534469\n",
      "epoch: 526 - cost: 1.02 mse:  5.62373209078 - -train accuracy: 0.552835\n",
      "epoch: 527 - cost: 1.00553 mse:  5.24616470547 - -train accuracy: 0.534203\n",
      "epoch: 528 - cost: 1.01729 mse:  5.61383516016 - -train accuracy: 0.553633\n",
      "epoch: 529 - cost: 1.00286 mse:  5.23747183491 - -train accuracy: 0.534735\n",
      "epoch: 530 - cost: 1.01467 mse:  5.6039761623 - -train accuracy: 0.553899\n",
      "epoch: 531 - cost: 1.00023 mse:  5.22915804374 - -train accuracy: 0.535001\n",
      "epoch: 532 - cost: 1.01207 mse:  5.59463307474 - -train accuracy: 0.554698\n",
      "epoch: 533 - cost: 0.997591 mse:  5.22112740887 - -train accuracy: 0.535267\n",
      "epoch: 534 - cost: 1.00942 mse:  5.58560583688 - -train accuracy: 0.55523\n",
      "epoch: 535 - cost: 0.995003 mse:  5.21359444292 - -train accuracy: 0.536332\n",
      "epoch: 536 - cost: 1.00679 mse:  5.57662274998 - -train accuracy: 0.555763\n",
      "epoch: 537 - cost: 0.992407 mse:  5.20574467581 - -train accuracy: 0.536865\n",
      "epoch: 538 - cost: 1.00418 mse:  5.56766875361 - -train accuracy: 0.556561\n",
      "epoch: 539 - cost: 0.98985 mse:  5.19798990512 - -train accuracy: 0.537663\n",
      "epoch: 540 - cost: 1.00161 mse:  5.55852205588 - -train accuracy: 0.556561\n",
      "epoch: 541 - cost: 0.987298 mse:  5.19001661353 - -train accuracy: 0.538462\n",
      "epoch: 542 - cost: 0.999102 mse:  5.54939591329 - -train accuracy: 0.55736\n",
      "epoch: 543 - cost: 0.984797 mse:  5.18213548979 - -train accuracy: 0.538994\n",
      "epoch: 544 - cost: 0.996605 mse:  5.54026641149 - -train accuracy: 0.55736\n",
      "epoch: 545 - cost: 0.982304 mse:  5.1745005712 - -train accuracy: 0.539526\n",
      "epoch: 546 - cost: 0.994126 mse:  5.53126036305 - -train accuracy: 0.557892\n",
      "epoch: 547 - cost: 0.979833 mse:  5.1669659832 - -train accuracy: 0.540059\n",
      "epoch: 548 - cost: 0.991662 mse:  5.52238736844 - -train accuracy: 0.558424\n",
      "epoch: 549 - cost: 0.977377 mse:  5.15935343391 - -train accuracy: 0.539792\n",
      "epoch: 550 - cost: 0.9892 mse:  5.51354025443 - -train accuracy: 0.55869\n",
      "epoch: 551 - cost: 0.974916 mse:  5.15183267355 - -train accuracy: 0.540325\n",
      "epoch: 552 - cost: 0.986718 mse:  5.50430028732 - -train accuracy: 0.558957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 553 - cost: 0.97244 mse:  5.14440295073 - -train accuracy: 0.541123\n",
      "epoch: 554 - cost: 0.984251 mse:  5.49604719741 - -train accuracy: 0.559755\n",
      "epoch: 555 - cost: 0.969998 mse:  5.13728794219 - -train accuracy: 0.542188\n",
      "epoch: 556 - cost: 0.981784 mse:  5.48731051602 - -train accuracy: 0.561086\n",
      "epoch: 557 - cost: 0.967575 mse:  5.12991124913 - -train accuracy: 0.542188\n",
      "epoch: 558 - cost: 0.979382 mse:  5.47812624629 - -train accuracy: 0.561618\n",
      "epoch: 559 - cost: 0.965156 mse:  5.12199565787 - -train accuracy: 0.542188\n",
      "epoch: 560 - cost: 0.976983 mse:  5.46983967614 - -train accuracy: 0.562417\n",
      "epoch: 561 - cost: 0.962776 mse:  5.11507513752 - -train accuracy: 0.542986\n",
      "epoch: 562 - cost: 0.974566 mse:  5.46158518434 - -train accuracy: 0.562683\n",
      "epoch: 563 - cost: 0.960346 mse:  5.1077820189 - -train accuracy: 0.543253\n",
      "epoch: 564 - cost: 0.972122 mse:  5.45314823278 - -train accuracy: 0.562683\n",
      "epoch: 565 - cost: 0.957919 mse:  5.10046341118 - -train accuracy: 0.543253\n",
      "epoch: 566 - cost: 0.969673 mse:  5.44468055628 - -train accuracy: 0.562683\n",
      "epoch: 567 - cost: 0.955499 mse:  5.09328299946 - -train accuracy: 0.543785\n",
      "epoch: 568 - cost: 0.967255 mse:  5.4364140949 - -train accuracy: 0.563215\n",
      "epoch: 569 - cost: 0.95311 mse:  5.08585218674 - -train accuracy: 0.543519\n",
      "epoch: 570 - cost: 0.964875 mse:  5.42767843074 - -train accuracy: 0.563215\n",
      "epoch: 571 - cost: 0.950761 mse:  5.0786258193 - -train accuracy: 0.543785\n",
      "epoch: 572 - cost: 0.962487 mse:  5.41910874656 - -train accuracy: 0.563482\n",
      "epoch: 573 - cost: 0.948382 mse:  5.07147185492 - -train accuracy: 0.544317\n",
      "epoch: 574 - cost: 0.960115 mse:  5.41023122683 - -train accuracy: 0.563748\n",
      "epoch: 575 - cost: 0.946032 mse:  5.06393787403 - -train accuracy: 0.54485\n",
      "epoch: 576 - cost: 0.957796 mse:  5.40117207766 - -train accuracy: 0.564546\n",
      "epoch: 577 - cost: 0.943698 mse:  5.05648599077 - -train accuracy: 0.545116\n",
      "epoch: 578 - cost: 0.955484 mse:  5.39238635916 - -train accuracy: 0.564546\n",
      "epoch: 579 - cost: 0.941415 mse:  5.04939339748 - -train accuracy: 0.54618\n",
      "epoch: 580 - cost: 0.953196 mse:  5.38421754075 - -train accuracy: 0.565345\n",
      "epoch: 581 - cost: 0.939139 mse:  5.04296262471 - -train accuracy: 0.54618\n",
      "epoch: 582 - cost: 0.950919 mse:  5.37645171018 - -train accuracy: 0.566409\n",
      "epoch: 583 - cost: 0.936867 mse:  5.03639188973 - -train accuracy: 0.54618\n",
      "epoch: 584 - cost: 0.948626 mse:  5.36860375537 - -train accuracy: 0.566676\n",
      "epoch: 585 - cost: 0.934583 mse:  5.02967533592 - -train accuracy: 0.546447\n",
      "epoch: 586 - cost: 0.946318 mse:  5.36031189479 - -train accuracy: 0.566942\n",
      "epoch: 587 - cost: 0.932321 mse:  5.02309226384 - -train accuracy: 0.547245\n",
      "epoch: 588 - cost: 0.944023 mse:  5.35271478879 - -train accuracy: 0.567208\n",
      "epoch: 589 - cost: 0.930049 mse:  5.01673651315 - -train accuracy: 0.548576\n",
      "epoch: 590 - cost: 0.941669 mse:  5.34443390636 - -train accuracy: 0.567208\n",
      "epoch: 591 - cost: 0.927744 mse:  5.01005282997 - -train accuracy: 0.548842\n",
      "epoch: 592 - cost: 0.939368 mse:  5.33669894222 - -train accuracy: 0.567208\n",
      "epoch: 593 - cost: 0.925509 mse:  5.00339543044 - -train accuracy: 0.549375\n",
      "epoch: 594 - cost: 0.937125 mse:  5.3288665301 - -train accuracy: 0.569337\n",
      "epoch: 595 - cost: 0.92328 mse:  4.99706231336 - -train accuracy: 0.549375\n",
      "epoch: 596 - cost: 0.934863 mse:  5.32128008991 - -train accuracy: 0.570402\n",
      "epoch: 597 - cost: 0.921018 mse:  4.99079600995 - -train accuracy: 0.549907\n",
      "epoch: 598 - cost: 0.93261 mse:  5.31395268666 - -train accuracy: 0.570668\n",
      "epoch: 599 - cost: 0.918785 mse:  4.98482569302 - -train accuracy: 0.550439\n",
      "epoch: 600 - cost: 0.930365 mse:  5.30700819246 - -train accuracy: 0.570668\n",
      "epoch: 601 - cost: 0.916551 mse:  4.9788148338 - -train accuracy: 0.552036\n",
      "epoch: 602 - cost: 0.92812 mse:  5.29990657557 - -train accuracy: 0.570668\n",
      "epoch: 603 - cost: 0.914316 mse:  4.97344840621 - -train accuracy: 0.552835\n",
      "epoch: 604 - cost: 0.925866 mse:  5.29339729975 - -train accuracy: 0.570934\n",
      "epoch: 605 - cost: 0.91209 mse:  4.96833780382 - -train accuracy: 0.552835\n",
      "epoch: 606 - cost: 0.923669 mse:  5.28704488901 - -train accuracy: 0.571733\n",
      "epoch: 607 - cost: 0.909928 mse:  4.96252444342 - -train accuracy: 0.553367\n",
      "epoch: 608 - cost: 0.921506 mse:  5.28013330479 - -train accuracy: 0.572531\n",
      "epoch: 609 - cost: 0.907798 mse:  4.95685649581 - -train accuracy: 0.554166\n",
      "epoch: 610 - cost: 0.919401 mse:  5.27312820576 - -train accuracy: 0.573064\n",
      "epoch: 611 - cost: 0.905706 mse:  4.95118356286 - -train accuracy: 0.554166\n",
      "epoch: 612 - cost: 0.917282 mse:  5.26605578518 - -train accuracy: 0.574128\n",
      "epoch: 613 - cost: 0.903587 mse:  4.94511807755 - -train accuracy: 0.554698\n",
      "epoch: 614 - cost: 0.91516 mse:  5.25857647299 - -train accuracy: 0.574661\n",
      "epoch: 615 - cost: 0.901491 mse:  4.93883833596 - -train accuracy: 0.555496\n",
      "epoch: 616 - cost: 0.913016 mse:  5.2507898162 - -train accuracy: 0.575459\n",
      "epoch: 617 - cost: 0.899391 mse:  4.93271168071 - -train accuracy: 0.555496\n",
      "epoch: 618 - cost: 0.910905 mse:  5.24304617694 - -train accuracy: 0.575725\n",
      "epoch: 619 - cost: 0.897302 mse:  4.92637957074 - -train accuracy: 0.556029\n",
      "epoch: 620 - cost: 0.90879 mse:  5.23546559098 - -train accuracy: 0.576258\n",
      "epoch: 621 - cost: 0.895204 mse:  4.92002951611 - -train accuracy: 0.556561\n",
      "epoch: 622 - cost: 0.906683 mse:  5.22774528019 - -train accuracy: 0.576258\n",
      "epoch: 623 - cost: 0.893145 mse:  4.91380639359 - -train accuracy: 0.556827\n",
      "epoch: 624 - cost: 0.904607 mse:  5.22009629502 - -train accuracy: 0.577056\n",
      "epoch: 625 - cost: 0.891118 mse:  4.90731211125 - -train accuracy: 0.556827\n",
      "epoch: 626 - cost: 0.902573 mse:  5.2119187763 - -train accuracy: 0.577588\n",
      "epoch: 627 - cost: 0.889084 mse:  4.90071477565 - -train accuracy: 0.55736\n",
      "epoch: 628 - cost: 0.900511 mse:  5.20381789124 - -train accuracy: 0.577588\n",
      "epoch: 629 - cost: 0.887124 mse:  4.89417720147 - -train accuracy: 0.55736\n",
      "epoch: 630 - cost: 0.898498 mse:  5.19565482129 - -train accuracy: 0.578387\n",
      "epoch: 631 - cost: 0.885125 mse:  4.88773189988 - -train accuracy: 0.55869\n",
      "epoch: 632 - cost: 0.896459 mse:  5.18800743265 - -train accuracy: 0.578653\n",
      "epoch: 633 - cost: 0.883102 mse:  4.88117436854 - -train accuracy: 0.558957\n",
      "epoch: 634 - cost: 0.89441 mse:  5.17985247952 - -train accuracy: 0.579186\n",
      "epoch: 635 - cost: 0.881107 mse:  4.87491134794 - -train accuracy: 0.559223\n",
      "epoch: 636 - cost: 0.89238 mse:  5.17211026484 - -train accuracy: 0.579718\n",
      "epoch: 637 - cost: 0.879118 mse:  4.86888591058 - -train accuracy: 0.559223\n",
      "epoch: 638 - cost: 0.890344 mse:  5.16496416755 - -train accuracy: 0.580783\n",
      "epoch: 639 - cost: 0.87711 mse:  4.86264783186 - -train accuracy: 0.559755\n",
      "epoch: 640 - cost: 0.888314 mse:  5.15679022834 - -train accuracy: 0.582113\n",
      "epoch: 641 - cost: 0.875152 mse:  4.85631713692 - -train accuracy: 0.560554\n",
      "epoch: 642 - cost: 0.886329 mse:  5.14874887007 - -train accuracy: 0.582912\n",
      "epoch: 643 - cost: 0.873199 mse:  4.84981132228 - -train accuracy: 0.560554\n",
      "epoch: 644 - cost: 0.884339 mse:  5.14062109986 - -train accuracy: 0.583444\n",
      "epoch: 645 - cost: 0.871321 mse:  4.84392824796 - -train accuracy: 0.561352\n",
      "epoch: 646 - cost: 0.882408 mse:  5.13332870528 - -train accuracy: 0.584243\n",
      "epoch: 647 - cost: 0.86937 mse:  4.83787248764 - -train accuracy: 0.562151\n",
      "epoch: 648 - cost: 0.880416 mse:  5.12566204441 - -train accuracy: 0.585307\n",
      "epoch: 649 - cost: 0.867428 mse:  4.8316129653 - -train accuracy: 0.562151\n",
      "epoch: 650 - cost: 0.878478 mse:  5.11809412507 - -train accuracy: 0.586106\n",
      "epoch: 651 - cost: 0.865536 mse:  4.82570015996 - -train accuracy: 0.562151\n",
      "epoch: 652 - cost: 0.876542 mse:  5.11048595551 - -train accuracy: 0.587437\n",
      "epoch: 653 - cost: 0.863647 mse:  4.81971845259 - -train accuracy: 0.562683\n",
      "epoch: 654 - cost: 0.874607 mse:  5.10289848746 - -train accuracy: 0.588501\n",
      "epoch: 655 - cost: 0.861766 mse:  4.81322423561 - -train accuracy: 0.562417\n",
      "epoch: 656 - cost: 0.872752 mse:  5.09489120044 - -train accuracy: 0.5893\n",
      "epoch: 657 - cost: 0.85992 mse:  4.80688195477 - -train accuracy: 0.562417\n",
      "epoch: 658 - cost: 0.870896 mse:  5.08739483789 - -train accuracy: 0.589832\n",
      "epoch: 659 - cost: 0.858113 mse:  4.80096448105 - -train accuracy: 0.562683\n",
      "epoch: 660 - cost: 0.869029 mse:  5.0797698078 - -train accuracy: 0.590897\n",
      "epoch: 661 - cost: 0.856289 mse:  4.79483380966 - -train accuracy: 0.562683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 662 - cost: 0.867171 mse:  5.07210310404 - -train accuracy: 0.590897\n",
      "epoch: 663 - cost: 0.854463 mse:  4.78874735262 - -train accuracy: 0.562683\n",
      "epoch: 664 - cost: 0.865313 mse:  5.06421215527 - -train accuracy: 0.591962\n",
      "epoch: 665 - cost: 0.852661 mse:  4.78258813265 - -train accuracy: 0.562949\n",
      "epoch: 666 - cost: 0.863474 mse:  5.05639322033 - -train accuracy: 0.59276\n",
      "epoch: 667 - cost: 0.850841 mse:  4.77643272317 - -train accuracy: 0.563215\n",
      "epoch: 668 - cost: 0.861609 mse:  5.04886175106 - -train accuracy: 0.593825\n",
      "epoch: 669 - cost: 0.84903 mse:  4.77044127229 - -train accuracy: 0.56428\n",
      "epoch: 670 - cost: 0.859752 mse:  5.04132491457 - -train accuracy: 0.594357\n",
      "epoch: 671 - cost: 0.847226 mse:  4.76425158401 - -train accuracy: 0.565078\n",
      "epoch: 672 - cost: 0.857914 mse:  5.03379390777 - -train accuracy: 0.595688\n",
      "epoch: 673 - cost: 0.84548 mse:  4.75875204074 - -train accuracy: 0.565877\n",
      "epoch: 674 - cost: 0.856097 mse:  5.02659549114 - -train accuracy: 0.595954\n",
      "epoch: 675 - cost: 0.843671 mse:  4.75286706707 - -train accuracy: 0.566409\n",
      "epoch: 676 - cost: 0.85424 mse:  5.01900979634 - -train accuracy: 0.597285\n",
      "epoch: 677 - cost: 0.841861 mse:  4.7468978642 - -train accuracy: 0.566676\n",
      "epoch: 678 - cost: 0.852393 mse:  5.01144770439 - -train accuracy: 0.598616\n",
      "epoch: 679 - cost: 0.840078 mse:  4.74109214717 - -train accuracy: 0.566676\n",
      "epoch: 680 - cost: 0.850596 mse:  5.0044115415 - -train accuracy: 0.598616\n",
      "epoch: 681 - cost: 0.838318 mse:  4.73526166533 - -train accuracy: 0.566676\n",
      "epoch: 682 - cost: 0.848806 mse:  4.99696418934 - -train accuracy: 0.59835\n",
      "epoch: 683 - cost: 0.836605 mse:  4.7293865788 - -train accuracy: 0.567208\n",
      "epoch: 684 - cost: 0.847049 mse:  4.9898087034 - -train accuracy: 0.598616\n",
      "epoch: 685 - cost: 0.834887 mse:  4.72355725006 - -train accuracy: 0.568805\n",
      "epoch: 686 - cost: 0.845288 mse:  4.98257829837 - -train accuracy: 0.598616\n",
      "epoch: 687 - cost: 0.833163 mse:  4.71773945884 - -train accuracy: 0.56987\n",
      "epoch: 688 - cost: 0.843527 mse:  4.97535318817 - -train accuracy: 0.599148\n",
      "epoch: 689 - cost: 0.831449 mse:  4.71224309175 - -train accuracy: 0.570402\n",
      "epoch: 690 - cost: 0.841786 mse:  4.96842684188 - -train accuracy: 0.600213\n",
      "epoch: 691 - cost: 0.829725 mse:  4.70680278687 - -train accuracy: 0.570934\n",
      "epoch: 692 - cost: 0.84001 mse:  4.96139089974 - -train accuracy: 0.600479\n",
      "epoch: 693 - cost: 0.828011 mse:  4.70115037226 - -train accuracy: 0.5712\n",
      "epoch: 694 - cost: 0.838284 mse:  4.95438260395 - -train accuracy: 0.601011\n",
      "epoch: 695 - cost: 0.826332 mse:  4.69573757977 - -train accuracy: 0.5712\n",
      "epoch: 696 - cost: 0.836557 mse:  4.94749594459 - -train accuracy: 0.601544\n",
      "epoch: 697 - cost: 0.82466 mse:  4.69019381575 - -train accuracy: 0.571733\n",
      "epoch: 698 - cost: 0.834864 mse:  4.94038609644 - -train accuracy: 0.601544\n",
      "epoch: 699 - cost: 0.823013 mse:  4.68461802642 - -train accuracy: 0.571999\n",
      "epoch: 700 - cost: 0.833194 mse:  4.93352177063 - -train accuracy: 0.602875\n",
      "epoch: 701 - cost: 0.8214 mse:  4.67933572477 - -train accuracy: 0.572797\n",
      "epoch: 702 - cost: 0.831549 mse:  4.92699530426 - -train accuracy: 0.603407\n",
      "epoch: 703 - cost: 0.819776 mse:  4.67399019308 - -train accuracy: 0.573064\n",
      "epoch: 704 - cost: 0.829912 mse:  4.92023313674 - -train accuracy: 0.603407\n",
      "epoch: 705 - cost: 0.818172 mse:  4.66855987534 - -train accuracy: 0.573064\n",
      "epoch: 706 - cost: 0.828292 mse:  4.91325046627 - -train accuracy: 0.603407\n",
      "epoch: 707 - cost: 0.816619 mse:  4.66322749619 - -train accuracy: 0.573596\n",
      "epoch: 708 - cost: 0.826713 mse:  4.90668113614 - -train accuracy: 0.603939\n",
      "epoch: 709 - cost: 0.815069 mse:  4.65800416014 - -train accuracy: 0.574394\n",
      "epoch: 710 - cost: 0.8251 mse:  4.90005819011 - -train accuracy: 0.604738\n",
      "epoch: 711 - cost: 0.813503 mse:  4.65272283512 - -train accuracy: 0.575459\n",
      "epoch: 712 - cost: 0.823511 mse:  4.89337129522 - -train accuracy: 0.605536\n",
      "epoch: 713 - cost: 0.811954 mse:  4.64753615281 - -train accuracy: 0.576524\n",
      "epoch: 714 - cost: 0.821915 mse:  4.88699176551 - -train accuracy: 0.605536\n",
      "epoch: 715 - cost: 0.810384 mse:  4.642464519 - -train accuracy: 0.575725\n",
      "epoch: 716 - cost: 0.820303 mse:  4.88044865504 - -train accuracy: 0.605802\n",
      "epoch: 717 - cost: 0.808823 mse:  4.63732604374 - -train accuracy: 0.575459\n",
      "epoch: 718 - cost: 0.818706 mse:  4.87408146361 - -train accuracy: 0.606069\n",
      "epoch: 719 - cost: 0.807265 mse:  4.63227104484 - -train accuracy: 0.575725\n",
      "epoch: 720 - cost: 0.817103 mse:  4.86767028202 - -train accuracy: 0.606335\n",
      "epoch: 721 - cost: 0.805726 mse:  4.62719236412 - -train accuracy: 0.577056\n",
      "epoch: 722 - cost: 0.815523 mse:  4.86120917676 - -train accuracy: 0.607133\n",
      "epoch: 723 - cost: 0.804192 mse:  4.62186175651 - -train accuracy: 0.578121\n",
      "epoch: 724 - cost: 0.813941 mse:  4.85446870282 - -train accuracy: 0.6074\n",
      "epoch: 725 - cost: 0.802681 mse:  4.61644145869 - -train accuracy: 0.577855\n",
      "epoch: 726 - cost: 0.812367 mse:  4.84760559277 - -train accuracy: 0.607932\n",
      "epoch: 727 - cost: 0.801147 mse:  4.61084753367 - -train accuracy: 0.577588\n",
      "epoch: 728 - cost: 0.810801 mse:  4.84071707548 - -train accuracy: 0.6074\n",
      "epoch: 729 - cost: 0.799636 mse:  4.60516917789 - -train accuracy: 0.578121\n",
      "epoch: 730 - cost: 0.809262 mse:  4.83376017539 - -train accuracy: 0.607932\n",
      "epoch: 731 - cost: 0.798124 mse:  4.59986361932 - -train accuracy: 0.578919\n",
      "epoch: 732 - cost: 0.807683 mse:  4.8269390058 - -train accuracy: 0.608997\n",
      "epoch: 733 - cost: 0.796576 mse:  4.59435305001 - -train accuracy: 0.579186\n",
      "epoch: 734 - cost: 0.806098 mse:  4.82021085869 - -train accuracy: 0.609529\n",
      "epoch: 735 - cost: 0.795035 mse:  4.58904049064 - -train accuracy: 0.579452\n",
      "epoch: 736 - cost: 0.804533 mse:  4.81368374182 - -train accuracy: 0.609529\n",
      "epoch: 737 - cost: 0.793538 mse:  4.58381443702 - -train accuracy: 0.579984\n",
      "epoch: 738 - cost: 0.802996 mse:  4.80714402356 - -train accuracy: 0.609529\n",
      "epoch: 739 - cost: 0.792064 mse:  4.57872635131 - -train accuracy: 0.58025\n",
      "epoch: 740 - cost: 0.801501 mse:  4.80082987147 - -train accuracy: 0.610594\n",
      "epoch: 741 - cost: 0.790602 mse:  4.57371405726 - -train accuracy: 0.580516\n",
      "epoch: 742 - cost: 0.800014 mse:  4.79462783935 - -train accuracy: 0.611392\n",
      "epoch: 743 - cost: 0.789155 mse:  4.56894222223 - -train accuracy: 0.581315\n",
      "epoch: 744 - cost: 0.79855 mse:  4.78841241085 - -train accuracy: 0.612457\n",
      "epoch: 745 - cost: 0.787733 mse:  4.56406731736 - -train accuracy: 0.581581\n",
      "epoch: 746 - cost: 0.797099 mse:  4.78278183728 - -train accuracy: 0.612723\n",
      "epoch: 747 - cost: 0.786314 mse:  4.55957564745 - -train accuracy: 0.581581\n",
      "epoch: 748 - cost: 0.795655 mse:  4.77732769147 - -train accuracy: 0.612723\n",
      "epoch: 749 - cost: 0.784901 mse:  4.55526821746 - -train accuracy: 0.581581\n",
      "epoch: 750 - cost: 0.794203 mse:  4.77207927093 - -train accuracy: 0.613255\n",
      "epoch: 751 - cost: 0.783503 mse:  4.55119689654 - -train accuracy: 0.581315\n",
      "epoch: 752 - cost: 0.792761 mse:  4.76666727494 - -train accuracy: 0.614054\n",
      "epoch: 753 - cost: 0.782087 mse:  4.54692893403 - -train accuracy: 0.581315\n",
      "epoch: 754 - cost: 0.791304 mse:  4.76113048911 - -train accuracy: 0.614054\n",
      "epoch: 755 - cost: 0.780649 mse:  4.54276863963 - -train accuracy: 0.581847\n",
      "epoch: 756 - cost: 0.78981 mse:  4.7556074678 - -train accuracy: 0.614852\n",
      "epoch: 757 - cost: 0.77919 mse:  4.53849977755 - -train accuracy: 0.582912\n",
      "epoch: 758 - cost: 0.788328 mse:  4.75003338977 - -train accuracy: 0.615651\n",
      "epoch: 759 - cost: 0.777759 mse:  4.53411616838 - -train accuracy: 0.583178\n",
      "epoch: 760 - cost: 0.786872 mse:  4.7443664793 - -train accuracy: 0.615651\n",
      "epoch: 761 - cost: 0.776365 mse:  4.52991871132 - -train accuracy: 0.583977\n",
      "epoch: 762 - cost: 0.785456 mse:  4.73898713418 - -train accuracy: 0.616982\n",
      "epoch: 763 - cost: 0.774982 mse:  4.5258832436 - -train accuracy: 0.584775\n",
      "epoch: 764 - cost: 0.784036 mse:  4.73363755216 - -train accuracy: 0.61778\n",
      "epoch: 765 - cost: 0.773601 mse:  4.52190301321 - -train accuracy: 0.58371\n",
      "epoch: 766 - cost: 0.782584 mse:  4.72813263399 - -train accuracy: 0.61778\n",
      "epoch: 767 - cost: 0.772208 mse:  4.5177059329 - -train accuracy: 0.583977\n",
      "epoch: 768 - cost: 0.781155 mse:  4.72260258193 - -train accuracy: 0.618579\n",
      "epoch: 769 - cost: 0.770857 mse:  4.51343221361 - -train accuracy: 0.584509\n",
      "epoch: 770 - cost: 0.779745 mse:  4.71722156026 - -train accuracy: 0.619111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 771 - cost: 0.76946 mse:  4.50932158874 - -train accuracy: 0.585041\n",
      "epoch: 772 - cost: 0.778296 mse:  4.7119734913 - -train accuracy: 0.620442\n",
      "epoch: 773 - cost: 0.768068 mse:  4.50514362265 - -train accuracy: 0.586106\n",
      "epoch: 774 - cost: 0.776819 mse:  4.70625419724 - -train accuracy: 0.620974\n",
      "epoch: 775 - cost: 0.766669 mse:  4.50073928236 - -train accuracy: 0.587703\n",
      "epoch: 776 - cost: 0.775375 mse:  4.70044889332 - -train accuracy: 0.622039\n",
      "epoch: 777 - cost: 0.765288 mse:  4.49614447636 - -train accuracy: 0.587969\n",
      "epoch: 778 - cost: 0.773944 mse:  4.69480434534 - -train accuracy: 0.623104\n",
      "epoch: 779 - cost: 0.76394 mse:  4.49158877024 - -train accuracy: 0.587969\n",
      "epoch: 780 - cost: 0.772563 mse:  4.68898655387 - -train accuracy: 0.623104\n",
      "epoch: 781 - cost: 0.762603 mse:  4.48702817128 - -train accuracy: 0.588768\n",
      "epoch: 782 - cost: 0.77117 mse:  4.68320137719 - -train accuracy: 0.623902\n",
      "epoch: 783 - cost: 0.76123 mse:  4.48261986262 - -train accuracy: 0.589832\n",
      "epoch: 784 - cost: 0.769798 mse:  4.67778691219 - -train accuracy: 0.623902\n",
      "epoch: 785 - cost: 0.759893 mse:  4.47837042843 - -train accuracy: 0.590365\n",
      "epoch: 786 - cost: 0.768414 mse:  4.67224195171 - -train accuracy: 0.624967\n",
      "epoch: 787 - cost: 0.758561 mse:  4.47412481452 - -train accuracy: 0.590897\n",
      "epoch: 788 - cost: 0.767039 mse:  4.66656820515 - -train accuracy: 0.625233\n",
      "epoch: 789 - cost: 0.757239 mse:  4.46953669097 - -train accuracy: 0.591163\n",
      "epoch: 790 - cost: 0.765646 mse:  4.66057933332 - -train accuracy: 0.625233\n",
      "epoch: 791 - cost: 0.755891 mse:  4.46494033463 - -train accuracy: 0.591695\n",
      "epoch: 792 - cost: 0.764244 mse:  4.65491029448 - -train accuracy: 0.625765\n",
      "epoch: 793 - cost: 0.75454 mse:  4.46061656367 - -train accuracy: 0.592228\n",
      "epoch: 794 - cost: 0.76287 mse:  4.64943917336 - -train accuracy: 0.626031\n",
      "epoch: 795 - cost: 0.753209 mse:  4.45625425549 - -train accuracy: 0.591962\n",
      "epoch: 796 - cost: 0.761496 mse:  4.64395917416 - -train accuracy: 0.625765\n",
      "epoch: 797 - cost: 0.751926 mse:  4.45202955293 - -train accuracy: 0.591695\n",
      "epoch: 798 - cost: 0.760158 mse:  4.63848301354 - -train accuracy: 0.626564\n",
      "epoch: 799 - cost: 0.750632 mse:  4.44771249314 - -train accuracy: 0.592228\n",
      "epoch: 800 - cost: 0.758829 mse:  4.63298610008 - -train accuracy: 0.627362\n",
      "epoch: 801 - cost: 0.749376 mse:  4.44333070835 - -train accuracy: 0.59276\n",
      "epoch: 802 - cost: 0.757542 mse:  4.62755804783 - -train accuracy: 0.628161\n",
      "epoch: 803 - cost: 0.748118 mse:  4.4391442731 - -train accuracy: 0.593293\n",
      "epoch: 804 - cost: 0.756242 mse:  4.62229647533 - -train accuracy: 0.627895\n",
      "epoch: 805 - cost: 0.746855 mse:  4.43511976896 - -train accuracy: 0.593293\n",
      "epoch: 806 - cost: 0.754948 mse:  4.61724191399 - -train accuracy: 0.628693\n",
      "epoch: 807 - cost: 0.745595 mse:  4.43117503172 - -train accuracy: 0.594357\n",
      "epoch: 808 - cost: 0.753643 mse:  4.61201340477 - -train accuracy: 0.628693\n",
      "epoch: 809 - cost: 0.744336 mse:  4.42710727344 - -train accuracy: 0.595422\n",
      "epoch: 810 - cost: 0.752365 mse:  4.60689508621 - -train accuracy: 0.629225\n",
      "epoch: 811 - cost: 0.743106 mse:  4.4232483161 - -train accuracy: 0.595688\n",
      "epoch: 812 - cost: 0.751112 mse:  4.6021788247 - -train accuracy: 0.629758\n",
      "epoch: 813 - cost: 0.741917 mse:  4.41942854268 - -train accuracy: 0.595422\n",
      "epoch: 814 - cost: 0.74987 mse:  4.59749635302 - -train accuracy: 0.630822\n",
      "epoch: 815 - cost: 0.740701 mse:  4.41581551913 - -train accuracy: 0.596487\n",
      "epoch: 816 - cost: 0.748624 mse:  4.59288772932 - -train accuracy: 0.631355\n",
      "epoch: 817 - cost: 0.739498 mse:  4.41212988621 - -train accuracy: 0.596753\n",
      "epoch: 818 - cost: 0.747365 mse:  4.58799426752 - -train accuracy: 0.631355\n",
      "epoch: 819 - cost: 0.73829 mse:  4.4084439771 - -train accuracy: 0.597551\n",
      "epoch: 820 - cost: 0.746144 mse:  4.58336730114 - -train accuracy: 0.631355\n",
      "epoch: 821 - cost: 0.737111 mse:  4.4048128244 - -train accuracy: 0.59835\n",
      "epoch: 822 - cost: 0.744915 mse:  4.57863269359 - -train accuracy: 0.631355\n",
      "epoch: 823 - cost: 0.735953 mse:  4.40150524152 - -train accuracy: 0.598616\n",
      "epoch: 824 - cost: 0.743719 mse:  4.57448826873 - -train accuracy: 0.631621\n",
      "epoch: 825 - cost: 0.734788 mse:  4.39793854541 - -train accuracy: 0.598616\n",
      "epoch: 826 - cost: 0.742515 mse:  4.56989074626 - -train accuracy: 0.631887\n",
      "epoch: 827 - cost: 0.733619 mse:  4.39432570878 - -train accuracy: 0.599148\n",
      "epoch: 828 - cost: 0.741279 mse:  4.56523122399 - -train accuracy: 0.632419\n",
      "epoch: 829 - cost: 0.732436 mse:  4.39070707846 - -train accuracy: 0.599681\n",
      "epoch: 830 - cost: 0.740058 mse:  4.5604334408 - -train accuracy: 0.633484\n",
      "epoch: 831 - cost: 0.731295 mse:  4.38699236823 - -train accuracy: 0.599681\n",
      "epoch: 832 - cost: 0.738878 mse:  4.55572840082 - -train accuracy: 0.634017\n",
      "epoch: 833 - cost: 0.730139 mse:  4.38340504416 - -train accuracy: 0.600479\n",
      "epoch: 834 - cost: 0.737693 mse:  4.55094103456 - -train accuracy: 0.634017\n",
      "epoch: 835 - cost: 0.729006 mse:  4.37977973088 - -train accuracy: 0.600745\n",
      "epoch: 836 - cost: 0.736496 mse:  4.54623568317 - -train accuracy: 0.634283\n",
      "epoch: 837 - cost: 0.727837 mse:  4.37621564955 - -train accuracy: 0.601544\n",
      "epoch: 838 - cost: 0.735294 mse:  4.5415774334 - -train accuracy: 0.634815\n",
      "epoch: 839 - cost: 0.726654 mse:  4.37270162807 - -train accuracy: 0.601011\n",
      "epoch: 840 - cost: 0.734064 mse:  4.53705973811 - -train accuracy: 0.635081\n",
      "epoch: 841 - cost: 0.725497 mse:  4.3693158146 - -train accuracy: 0.602076\n",
      "epoch: 842 - cost: 0.732865 mse:  4.53256447354 - -train accuracy: 0.636146\n",
      "epoch: 843 - cost: 0.724358 mse:  4.36580219723 - -train accuracy: 0.602342\n",
      "epoch: 844 - cost: 0.731677 mse:  4.52803428355 - -train accuracy: 0.636944\n",
      "epoch: 845 - cost: 0.72322 mse:  4.36218196728 - -train accuracy: 0.603141\n",
      "epoch: 846 - cost: 0.730492 mse:  4.52347170436 - -train accuracy: 0.637743\n",
      "epoch: 847 - cost: 0.722114 mse:  4.35835249278 - -train accuracy: 0.603407\n",
      "epoch: 848 - cost: 0.72937 mse:  4.51883081278 - -train accuracy: 0.638808\n",
      "epoch: 849 - cost: 0.721007 mse:  4.3546372127 - -train accuracy: 0.603673\n",
      "epoch: 850 - cost: 0.728252 mse:  4.51416948263 - -train accuracy: 0.63934\n",
      "epoch: 851 - cost: 0.719925 mse:  4.35096923255 - -train accuracy: 0.604472\n",
      "epoch: 852 - cost: 0.727149 mse:  4.50960813556 - -train accuracy: 0.640138\n",
      "epoch: 853 - cost: 0.718856 mse:  4.34750858316 - -train accuracy: 0.605004\n",
      "epoch: 854 - cost: 0.726046 mse:  4.50524810022 - -train accuracy: 0.640138\n",
      "epoch: 855 - cost: 0.717796 mse:  4.34402111489 - -train accuracy: 0.60527\n",
      "epoch: 856 - cost: 0.724961 mse:  4.50094732076 - -train accuracy: 0.640138\n",
      "epoch: 857 - cost: 0.71675 mse:  4.34075588594 - -train accuracy: 0.605536\n",
      "epoch: 858 - cost: 0.723891 mse:  4.49691336679 - -train accuracy: 0.640671\n",
      "epoch: 859 - cost: 0.715737 mse:  4.33792514722 - -train accuracy: 0.606335\n",
      "epoch: 860 - cost: 0.72283 mse:  4.49306221751 - -train accuracy: 0.641203\n",
      "epoch: 861 - cost: 0.714705 mse:  4.33480853428 - -train accuracy: 0.606867\n",
      "epoch: 862 - cost: 0.721722 mse:  4.48875637349 - -train accuracy: 0.641735\n",
      "epoch: 863 - cost: 0.713639 mse:  4.3314426992 - -train accuracy: 0.6074\n",
      "epoch: 864 - cost: 0.720631 mse:  4.4846075608 - -train accuracy: 0.642268\n",
      "epoch: 865 - cost: 0.712589 mse:  4.32812257242 - -train accuracy: 0.607932\n",
      "epoch: 866 - cost: 0.719537 mse:  4.48047440235 - -train accuracy: 0.642002\n",
      "epoch: 867 - cost: 0.711552 mse:  4.32481446745 - -train accuracy: 0.609263\n",
      "epoch: 868 - cost: 0.718461 mse:  4.4762510705 - -train accuracy: 0.642002\n",
      "epoch: 869 - cost: 0.710535 mse:  4.3215776938 - -train accuracy: 0.609529\n",
      "epoch: 870 - cost: 0.717407 mse:  4.47211505418 - -train accuracy: 0.642534\n",
      "epoch: 871 - cost: 0.709499 mse:  4.31823199267 - -train accuracy: 0.610061\n",
      "epoch: 872 - cost: 0.716328 mse:  4.46779748086 - -train accuracy: 0.6428\n",
      "epoch: 873 - cost: 0.708478 mse:  4.3150240383 - -train accuracy: 0.610594\n",
      "epoch: 874 - cost: 0.715277 mse:  4.46390290689 - -train accuracy: 0.643066\n",
      "epoch: 875 - cost: 0.707461 mse:  4.3119568821 - -train accuracy: 0.611658\n",
      "epoch: 876 - cost: 0.714207 mse:  4.45977945265 - -train accuracy: 0.6428\n",
      "epoch: 877 - cost: 0.706422 mse:  4.30878590438 - -train accuracy: 0.612191\n",
      "epoch: 878 - cost: 0.713109 mse:  4.45571204561 - -train accuracy: 0.643332\n",
      "epoch: 879 - cost: 0.705392 mse:  4.30563596969 - -train accuracy: 0.612457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 880 - cost: 0.712017 mse:  4.45160675695 - -train accuracy: 0.644131\n",
      "epoch: 881 - cost: 0.704352 mse:  4.30224216874 - -train accuracy: 0.612723\n",
      "epoch: 882 - cost: 0.710937 mse:  4.44732522631 - -train accuracy: 0.644397\n",
      "epoch: 883 - cost: 0.703327 mse:  4.29875259024 - -train accuracy: 0.612989\n",
      "epoch: 884 - cost: 0.709863 mse:  4.44294433761 - -train accuracy: 0.644663\n",
      "epoch: 885 - cost: 0.702305 mse:  4.29521028217 - -train accuracy: 0.613255\n",
      "epoch: 886 - cost: 0.70879 mse:  4.43856322692 - -train accuracy: 0.644929\n",
      "epoch: 887 - cost: 0.701266 mse:  4.29164399051 - -train accuracy: 0.614852\n",
      "epoch: 888 - cost: 0.707727 mse:  4.43416679349 - -train accuracy: 0.645728\n",
      "epoch: 889 - cost: 0.700244 mse:  4.28809797743 - -train accuracy: 0.615118\n",
      "epoch: 890 - cost: 0.706667 mse:  4.42965268001 - -train accuracy: 0.645994\n",
      "epoch: 891 - cost: 0.699249 mse:  4.28451644607 - -train accuracy: 0.614852\n",
      "epoch: 892 - cost: 0.705643 mse:  4.4253978021 - -train accuracy: 0.64626\n",
      "epoch: 893 - cost: 0.698281 mse:  4.2811371886 - -train accuracy: 0.615651\n",
      "epoch: 894 - cost: 0.704603 mse:  4.42094974366 - -train accuracy: 0.645994\n",
      "epoch: 895 - cost: 0.697305 mse:  4.27757970198 - -train accuracy: 0.616982\n",
      "epoch: 896 - cost: 0.703573 mse:  4.41650459812 - -train accuracy: 0.645994\n",
      "epoch: 897 - cost: 0.696342 mse:  4.2738798571 - -train accuracy: 0.617514\n",
      "epoch: 898 - cost: 0.702553 mse:  4.41211580313 - -train accuracy: 0.64626\n",
      "epoch: 899 - cost: 0.695357 mse:  4.2704316072 - -train accuracy: 0.617248\n",
      "epoch: 900 - cost: 0.701496 mse:  4.40762776284 - -train accuracy: 0.646793\n",
      "epoch: 901 - cost: 0.694332 mse:  4.26682451669 - -train accuracy: 0.616982\n",
      "epoch: 902 - cost: 0.700449 mse:  4.40333075418 - -train accuracy: 0.646526\n",
      "epoch: 903 - cost: 0.693341 mse:  4.26326459174 - -train accuracy: 0.618312\n",
      "epoch: 904 - cost: 0.699426 mse:  4.39904427623 - -train accuracy: 0.647325\n",
      "epoch: 905 - cost: 0.692383 mse:  4.25971410516 - -train accuracy: 0.619377\n",
      "epoch: 906 - cost: 0.698433 mse:  4.39485037809 - -train accuracy: 0.648124\n",
      "epoch: 907 - cost: 0.691425 mse:  4.25637929399 - -train accuracy: 0.61991\n",
      "epoch: 908 - cost: 0.697449 mse:  4.3908060036 - -train accuracy: 0.648124\n",
      "epoch: 909 - cost: 0.69048 mse:  4.25313603234 - -train accuracy: 0.620176\n",
      "epoch: 910 - cost: 0.696468 mse:  4.38686193137 - -train accuracy: 0.648124\n",
      "epoch: 911 - cost: 0.689542 mse:  4.25003637125 - -train accuracy: 0.620974\n",
      "epoch: 912 - cost: 0.695491 mse:  4.38285459001 - -train accuracy: 0.64839\n",
      "epoch: 913 - cost: 0.688583 mse:  4.24681289567 - -train accuracy: 0.620708\n",
      "epoch: 914 - cost: 0.694499 mse:  4.37892751197 - -train accuracy: 0.648922\n",
      "epoch: 915 - cost: 0.687641 mse:  4.24373323321 - -train accuracy: 0.62124\n",
      "epoch: 916 - cost: 0.693526 mse:  4.37511990391 - -train accuracy: 0.648922\n",
      "epoch: 917 - cost: 0.686706 mse:  4.24084195313 - -train accuracy: 0.620974\n",
      "epoch: 918 - cost: 0.692549 mse:  4.37143674281 - -train accuracy: 0.648922\n",
      "epoch: 919 - cost: 0.685741 mse:  4.23805672853 - -train accuracy: 0.620974\n",
      "epoch: 920 - cost: 0.691557 mse:  4.36808068767 - -train accuracy: 0.649721\n",
      "epoch: 921 - cost: 0.684796 mse:  4.23537685165 - -train accuracy: 0.62124\n",
      "epoch: 922 - cost: 0.690587 mse:  4.36468241607 - -train accuracy: 0.649454\n",
      "epoch: 923 - cost: 0.683874 mse:  4.23273694968 - -train accuracy: 0.621507\n",
      "epoch: 924 - cost: 0.689627 mse:  4.36123928754 - -train accuracy: 0.650785\n",
      "epoch: 925 - cost: 0.682946 mse:  4.23000425784 - -train accuracy: 0.621773\n",
      "epoch: 926 - cost: 0.68867 mse:  4.35786132328 - -train accuracy: 0.651051\n",
      "epoch: 927 - cost: 0.682032 mse:  4.22743198954 - -train accuracy: 0.62124\n",
      "epoch: 928 - cost: 0.687719 mse:  4.35446520851 - -train accuracy: 0.651051\n",
      "epoch: 929 - cost: 0.681126 mse:  4.22492206691 - -train accuracy: 0.621507\n",
      "epoch: 930 - cost: 0.686778 mse:  4.35132947172 - -train accuracy: 0.65185\n",
      "epoch: 931 - cost: 0.680239 mse:  4.22254218678 - -train accuracy: 0.621507\n",
      "epoch: 932 - cost: 0.685857 mse:  4.34823545351 - -train accuracy: 0.652382\n",
      "epoch: 933 - cost: 0.679351 mse:  4.22000885086 - -train accuracy: 0.621507\n",
      "epoch: 934 - cost: 0.684935 mse:  4.3449541607 - -train accuracy: 0.652382\n",
      "epoch: 935 - cost: 0.678463 mse:  4.21748364518 - -train accuracy: 0.621773\n",
      "epoch: 936 - cost: 0.684043 mse:  4.34192273171 - -train accuracy: 0.653979\n",
      "epoch: 937 - cost: 0.677619 mse:  4.21519266889 - -train accuracy: 0.622305\n",
      "epoch: 938 - cost: 0.683167 mse:  4.33888987739 - -train accuracy: 0.654245\n",
      "epoch: 939 - cost: 0.676783 mse:  4.2128030377 - -train accuracy: 0.622039\n",
      "epoch: 940 - cost: 0.682294 mse:  4.33571441855 - -train accuracy: 0.655044\n",
      "epoch: 941 - cost: 0.675934 mse:  4.21043916109 - -train accuracy: 0.623104\n",
      "epoch: 942 - cost: 0.681417 mse:  4.33269569728 - -train accuracy: 0.655044\n",
      "epoch: 943 - cost: 0.675102 mse:  4.2081524727 - -train accuracy: 0.623104\n",
      "epoch: 944 - cost: 0.680567 mse:  4.32979207991 - -train accuracy: 0.655576\n",
      "epoch: 945 - cost: 0.67427 mse:  4.20597794293 - -train accuracy: 0.623636\n",
      "epoch: 946 - cost: 0.679723 mse:  4.32716991729 - -train accuracy: 0.656907\n",
      "epoch: 947 - cost: 0.673463 mse:  4.20390115705 - -train accuracy: 0.624168\n",
      "epoch: 948 - cost: 0.678883 mse:  4.32439864183 - -train accuracy: 0.657972\n",
      "epoch: 949 - cost: 0.672649 mse:  4.20190006309 - -train accuracy: 0.624434\n",
      "epoch: 950 - cost: 0.678043 mse:  4.32168751295 - -train accuracy: 0.658238\n",
      "epoch: 951 - cost: 0.671851 mse:  4.19985936215 - -train accuracy: 0.624967\n",
      "epoch: 952 - cost: 0.677211 mse:  4.31894101866 - -train accuracy: 0.65877\n",
      "epoch: 953 - cost: 0.671039 mse:  4.19766032979 - -train accuracy: 0.624967\n",
      "epoch: 954 - cost: 0.676368 mse:  4.31595590615 - -train accuracy: 0.659036\n",
      "epoch: 955 - cost: 0.670232 mse:  4.1953777434 - -train accuracy: 0.625233\n",
      "epoch: 956 - cost: 0.675516 mse:  4.31280607353 - -train accuracy: 0.659835\n",
      "epoch: 957 - cost: 0.669411 mse:  4.19302709005 - -train accuracy: 0.624701\n",
      "epoch: 958 - cost: 0.674681 mse:  4.30965815758 - -train accuracy: 0.6609\n",
      "epoch: 959 - cost: 0.668633 mse:  4.19057576051 - -train accuracy: 0.624434\n",
      "epoch: 960 - cost: 0.673877 mse:  4.30648903624 - -train accuracy: 0.661166\n",
      "epoch: 961 - cost: 0.667857 mse:  4.18797572469 - -train accuracy: 0.624168\n",
      "epoch: 962 - cost: 0.673065 mse:  4.30321794643 - -train accuracy: 0.661964\n",
      "epoch: 963 - cost: 0.667082 mse:  4.18544321145 - -train accuracy: 0.625233\n",
      "epoch: 964 - cost: 0.672275 mse:  4.30008788335 - -train accuracy: 0.662497\n",
      "epoch: 965 - cost: 0.666329 mse:  4.18291696518 - -train accuracy: 0.625499\n",
      "epoch: 966 - cost: 0.671487 mse:  4.29683656925 - -train accuracy: 0.662763\n",
      "epoch: 967 - cost: 0.665558 mse:  4.1802044467 - -train accuracy: 0.626298\n",
      "epoch: 968 - cost: 0.670688 mse:  4.29339039626 - -train accuracy: 0.663295\n",
      "epoch: 969 - cost: 0.664796 mse:  4.1775452227 - -train accuracy: 0.625765\n",
      "epoch: 970 - cost: 0.669888 mse:  4.28995143317 - -train accuracy: 0.663828\n",
      "epoch: 971 - cost: 0.664037 mse:  4.17498976246 - -train accuracy: 0.626031\n",
      "epoch: 972 - cost: 0.669085 mse:  4.28668791724 - -train accuracy: 0.66436\n",
      "epoch: 973 - cost: 0.66327 mse:  4.17239028947 - -train accuracy: 0.626298\n",
      "epoch: 974 - cost: 0.668294 mse:  4.28344891119 - -train accuracy: 0.664626\n",
      "epoch: 975 - cost: 0.662522 mse:  4.16974357758 - -train accuracy: 0.626564\n",
      "epoch: 976 - cost: 0.667511 mse:  4.28010735981 - -train accuracy: 0.665957\n",
      "epoch: 977 - cost: 0.661765 mse:  4.16711681605 - -train accuracy: 0.627096\n",
      "epoch: 978 - cost: 0.666708 mse:  4.27656854533 - -train accuracy: 0.667022\n",
      "epoch: 979 - cost: 0.661002 mse:  4.16438378087 - -train accuracy: 0.627895\n",
      "epoch: 980 - cost: 0.66594 mse:  4.27331855976 - -train accuracy: 0.668086\n",
      "epoch: 981 - cost: 0.660254 mse:  4.16185711046 - -train accuracy: 0.628693\n",
      "epoch: 982 - cost: 0.665149 mse:  4.26999804615 - -train accuracy: 0.668885\n",
      "epoch: 983 - cost: 0.659513 mse:  4.1592639038 - -train accuracy: 0.628693\n",
      "epoch: 984 - cost: 0.664367 mse:  4.26664388786 - -train accuracy: 0.669417\n",
      "epoch: 985 - cost: 0.658758 mse:  4.1567565853 - -train accuracy: 0.628427\n",
      "epoch: 986 - cost: 0.663602 mse:  4.26367215324 - -train accuracy: 0.670216\n",
      "epoch: 987 - cost: 0.65802 mse:  4.1544347395 - -train accuracy: 0.628693\n",
      "epoch: 988 - cost: 0.662821 mse:  4.26056985213 - -train accuracy: 0.670482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 989 - cost: 0.657264 mse:  4.15200002041 - -train accuracy: 0.628693\n",
      "epoch: 990 - cost: 0.662036 mse:  4.25741684092 - -train accuracy: 0.670482\n",
      "epoch: 991 - cost: 0.65652 mse:  4.14955305052 - -train accuracy: 0.628959\n",
      "epoch: 992 - cost: 0.661268 mse:  4.25436774608 - -train accuracy: 0.671014\n",
      "epoch: 993 - cost: 0.655794 mse:  4.14707179704 - -train accuracy: 0.629492\n",
      "epoch: 994 - cost: 0.660511 mse:  4.25113945165 - -train accuracy: 0.671546\n",
      "epoch: 995 - cost: 0.655064 mse:  4.14452916256 - -train accuracy: 0.629492\n",
      "epoch: 996 - cost: 0.659792 mse:  4.24812603948 - -train accuracy: 0.671546\n",
      "epoch: 997 - cost: 0.65438 mse:  4.14215823065 - -train accuracy: 0.629758\n",
      "epoch: 998 - cost: 0.659068 mse:  4.24505112758 - -train accuracy: 0.672345\n",
      "epoch: 999 - cost: 0.653683 mse:  4.13977063811 - -train accuracy: 0.629492\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    sess.run(train_step,feed_dict={x:x_train,y_:y_train})\n",
    "    cost=sess.run(cross_entropy,feed_dict={x:x_train,y_:y_train})\n",
    "    cost_history.append(np.append(cost_history,cost))\n",
    "    correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    \n",
    "    pred_y=sess.run(y,feed_dict={x:x_test})\n",
    "    mse=tf.reduce_mean(tf.square(pred_y-y_test))\n",
    "    mse_=sess.run(mse)\n",
    "    mse_history.append(mse_)\n",
    "    accuracy=sess.run(accuracy,feed_dict={x:x_train,y_:y_train})\n",
    "    accuracy_history.append(accuracy)\n",
    "    \n",
    "    print('epoch:',epoch,'-','cost:',cost,'mse: ',mse_,'-','-train accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.633171\n"
     ]
    }
   ],
   "source": [
    "correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "print('test accuracy:',sess.run(accuracy,feed_dict={x:x_test,y_:y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:4.1398\n"
     ]
    }
   ],
   "source": [
    "pred_y=sess.run(y,feed_dict={x:x_test})\n",
    "mse=tf.reduce_mean(tf.square(pred_y-y_test))\n",
    "print('mse:%.4f'%sess.run(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
