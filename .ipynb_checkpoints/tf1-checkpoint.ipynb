{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('/home/saloni/Documents/ML/Mortality/train.csv')\n",
    "labels=pd.read_csv('/home/saloni/Documents/ML/Mortality/labels_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dailydata=df.copy()\n",
    "result=pd.concat([dailydata,labels],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>...</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Temp</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Weight</th>\n",
       "      <th>pH</th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>54</td>\n",
       "      <td>2.973333</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>97.25</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>37.357143</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>171.052632</td>\n",
       "      <td>10.3</td>\n",
       "      <td>80.060976</td>\n",
       "      <td>7.387273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ALP   ALT   AST  Age   Albumin   BUN  Bilirubin  Cholesterol  Creatinine  \\\n",
       "0  77.0  31.0  46.0   54  2.973333  10.5        0.7        154.0        0.75   \n",
       "\n",
       "     DiasABP        ...           SaO2      SysABP       Temp  TroponinI  \\\n",
       "0  58.795833        ...          97.25  116.891892  37.357143        2.1   \n",
       "\n",
       "   TroponinT       Urine   WBC     Weight        pH  In-hospital_death  \n",
       "0       0.14  171.052632  10.3  80.060976  7.387273                  0  \n",
       "\n",
       "[1 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_variables = ['Age', 'Albumin', 'ALP', 'ALT', 'AST', 'Bilirubin', 'BUN', 'Cholesterol', 'Creatinine',\n",
    "                             'DiasABP', 'FiO2', 'GCS', 'Gender', 'Glucose', 'HCO3', 'HCT', 'Height', 'HR', 'ICUType', 'K',\n",
    "                             'Lactate', 'Mg', 'MAP', 'MechVent', 'Na', 'NIDiasABP', 'NIMAP', 'NISysABP', 'PaCO2', 'PaO2',\n",
    "                             'pH', 'Platelets', 'RecordID', 'RespRate', 'SaO2', 'SysABP', 'Temp', 'TroponinI','TroponinT','Urine',\n",
    "                             'WBC', 'Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datawithoutoutliers=result.copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3169, 43)\n"
     ]
    }
   ],
   "source": [
    "for i in list_of_variables:\n",
    "    datawithoutoutliers=datawithoutoutliers[np.abs(datawithoutoutliers[i]-datawithoutoutliers[i].mean())<=(4*datawithoutoutliers[i].std())]\n",
    "    outliers=datawithoutoutliers[np.abs(datawithoutoutliers[i]-datawithoutoutliers[i].mean())>=(4*datawithoutoutliers[i].std())]\n",
    "    \n",
    "print(datawithoutoutliers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels=datawithoutoutliers.pop(\"In-hospital_death\")\n",
    "df=datawithoutoutliers.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3169,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3169, 42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#normalization\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df = scaler.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "df_res,labels_res=SMOTE(random_state=9).fit_sample(df,labels) #balancing the data\n",
    "df_res=pd.DataFrame(df_res)\n",
    "labels_res=pd.DataFrame(labels_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc=OneHotEncoder(sparse=False)\n",
    "onehot_encoded = enc.fit_transform(labels_res)\n",
    "\n",
    "labels_res=onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(df_res,labels_res,test_size=0.33,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden_1=100\n",
    "n_hidden_2=100\n",
    "n_hidden_3=100\n",
    "n_hidden_4=100\n",
    "n_hidden_5=100\n",
    "\n",
    "\n",
    "x=tf.placeholder(tf.float32,shape=[None,42])\n",
    "y_=tf.placeholder(tf.float32,shape=[None,2])\n",
    "w =tf.Variable(tf.zeros([42,2]))\n",
    "b=tf.Variable(tf.zeros([2]))\n",
    "\n",
    "def multilayer_perceptron(x,weights,biases):\n",
    "    layer_1=tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    layer_1=tf.nn.sigmoid(layer_1)\n",
    "    \n",
    "    layer_2=tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
    "    layer_2=tf.nn.sigmoid(layer_2)\n",
    "    \n",
    "    layer_3=tf.add(tf.matmul(layer_2,weights['h3']),biases['b3'])\n",
    "    layer_3=tf.nn.sigmoid(layer_3)\n",
    "    \n",
    "    layer_4=tf.add(tf.matmul(layer_3,weights['h4']),biases['b4'])\n",
    "    layer_4=tf.nn.sigmoid(layer_4)\n",
    "    \n",
    "    layer_5=tf.add(tf.matmul(layer_4,weights['h5']),biases['b5'])\n",
    "    layer_5=tf.nn.relu(layer_5)\n",
    "    \n",
    "    \n",
    "    out_layer=tf.add(tf.matmul(layer_5,weights['out']),biases['out'])\n",
    "    return out_layer\n",
    "\n",
    "weights={\n",
    "       \n",
    "    'h1':tf.Variable(tf.truncated_normal([42,n_hidden_1])),\n",
    "    'h2':tf.Variable(tf.truncated_normal([n_hidden_1,n_hidden_2])),\n",
    "    'h3':tf.Variable(tf.truncated_normal([n_hidden_2,n_hidden_3])),\n",
    "    'h4':tf.Variable(tf.truncated_normal([n_hidden_3,n_hidden_4])),\n",
    "    'h5':tf.Variable(tf.truncated_normal([n_hidden_4,n_hidden_5])),\n",
    "    'out':tf.Variable(tf.truncated_normal([n_hidden_5,2]))\n",
    "}\n",
    "\n",
    "biases={\n",
    "    'b1':tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3':tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'b4':tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    'b5':tf.Variable(tf.truncated_normal([n_hidden_5])),\n",
    "    'out':tf.Variable(tf.truncated_normal([2]))\n",
    "}\n",
    "    \n",
    "y=multilayer_perceptron(x,weights,biases)\n",
    "cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_,logits=y))  \n",
    "train_step=tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "sess.run(tf.global_variables_initializer())                     \n",
    "                     \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_history=[]\n",
    "cost_history=[]\n",
    "accuracy_history=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_epochs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - cost: 22.9537 mse:  1223.83258829 - -train accuracy: 0.492148\n",
      "epoch: 1 - cost: 2.08667 mse:  496.114656481 - -train accuracy: 0.505723\n",
      "epoch: 2 - cost: 2.0675 mse:  486.9876501 - -train accuracy: 0.509981\n",
      "epoch: 3 - cost: 7.45405 mse:  669.71113152 - -train accuracy: 0.493213\n",
      "epoch: 4 - cost: 13.0206 mse:  573.562475193 - -train accuracy: 0.507852\n",
      "epoch: 5 - cost: 7.25867 mse:  766.34326515 - -train accuracy: 0.491882\n",
      "epoch: 6 - cost: 9.62419 mse:  680.139543172 - -train accuracy: 0.507852\n",
      "epoch: 7 - cost: 6.82365 mse:  768.706871602 - -train accuracy: 0.492148\n",
      "epoch: 8 - cost: 9.25136 mse:  707.957624891 - -train accuracy: 0.507852\n",
      "epoch: 9 - cost: 6.3877 mse:  767.866727868 - -train accuracy: 0.492148\n",
      "epoch: 10 - cost: 9.13473 mse:  727.768266911 - -train accuracy: 0.507852\n",
      "epoch: 11 - cost: 5.95986 mse:  765.327602683 - -train accuracy: 0.492148\n",
      "epoch: 12 - cost: 9.13614 mse:  741.488091037 - -train accuracy: 0.507852\n",
      "epoch: 13 - cost: 5.55543 mse:  761.193559904 - -train accuracy: 0.492148\n",
      "epoch: 14 - cost: 9.17725 mse:  750.419547964 - -train accuracy: 0.507852\n",
      "epoch: 15 - cost: 5.18339 mse:  756.277093994 - -train accuracy: 0.492947\n",
      "epoch: 16 - cost: 9.22405 mse:  756.061324988 - -train accuracy: 0.507852\n",
      "epoch: 17 - cost: 4.86132 mse:  751.693870945 - -train accuracy: 0.493479\n",
      "epoch: 18 - cost: 9.25488 mse:  759.668950396 - -train accuracy: 0.507852\n",
      "epoch: 19 - cost: 4.58898 mse:  748.425138872 - -train accuracy: 0.493479\n",
      "epoch: 20 - cost: 9.26598 mse:  762.03107683 - -train accuracy: 0.507852\n",
      "epoch: 21 - cost: 4.36365 mse:  746.06373055 - -train accuracy: 0.493479\n",
      "epoch: 22 - cost: 9.25072 mse:  763.160140982 - -train accuracy: 0.507852\n",
      "epoch: 23 - cost: 4.17663 mse:  744.163397603 - -train accuracy: 0.494277\n",
      "epoch: 24 - cost: 9.2138 mse:  763.874223372 - -train accuracy: 0.507852\n",
      "epoch: 25 - cost: 4.02699 mse:  743.480252985 - -train accuracy: 0.49481\n",
      "epoch: 26 - cost: 9.15894 mse:  764.462774758 - -train accuracy: 0.507852\n",
      "epoch: 27 - cost: 3.90795 mse:  743.39119963 - -train accuracy: 0.495076\n",
      "epoch: 28 - cost: 9.09066 mse:  765.362331218 - -train accuracy: 0.507852\n",
      "epoch: 29 - cost: 3.81037 mse:  743.496617005 - -train accuracy: 0.495608\n",
      "epoch: 30 - cost: 9.02217 mse:  766.166415752 - -train accuracy: 0.507852\n",
      "epoch: 31 - cost: 3.72995 mse:  743.847490284 - -train accuracy: 0.496673\n",
      "epoch: 32 - cost: 8.95087 mse:  766.350163757 - -train accuracy: 0.507852\n",
      "epoch: 33 - cost: 3.66766 mse:  744.302848646 - -train accuracy: 0.497205\n",
      "epoch: 34 - cost: 8.8706 mse:  766.136040176 - -train accuracy: 0.507852\n",
      "epoch: 35 - cost: 3.62085 mse:  744.467582149 - -train accuracy: 0.497205\n",
      "epoch: 36 - cost: 8.78454 mse:  765.282851321 - -train accuracy: 0.507852\n",
      "epoch: 37 - cost: 3.58613 mse:  744.045002749 - -train accuracy: 0.497471\n",
      "epoch: 38 - cost: 8.69534 mse:  763.495321683 - -train accuracy: 0.507852\n",
      "epoch: 39 - cost: 3.56095 mse:  743.663319873 - -train accuracy: 0.497471\n",
      "epoch: 40 - cost: 8.60327 mse:  761.793268658 - -train accuracy: 0.507852\n",
      "epoch: 41 - cost: 3.54119 mse:  743.43272543 - -train accuracy: 0.497205\n",
      "epoch: 42 - cost: 8.50982 mse:  759.667522834 - -train accuracy: 0.507852\n",
      "epoch: 43 - cost: 3.5282 mse:  742.648763942 - -train accuracy: 0.497205\n",
      "epoch: 44 - cost: 8.41504 mse:  756.844284096 - -train accuracy: 0.507852\n",
      "epoch: 45 - cost: 3.5181 mse:  741.517165516 - -train accuracy: 0.497205\n",
      "epoch: 46 - cost: 8.32175 mse:  753.600308176 - -train accuracy: 0.507852\n",
      "epoch: 47 - cost: 3.50982 mse:  739.516883673 - -train accuracy: 0.497205\n",
      "epoch: 48 - cost: 8.22759 mse:  749.397416009 - -train accuracy: 0.507852\n",
      "epoch: 49 - cost: 3.50706 mse:  737.517836878 - -train accuracy: 0.497205\n",
      "epoch: 50 - cost: 8.133 mse:  745.09701584 - -train accuracy: 0.507852\n",
      "epoch: 51 - cost: 3.50704 mse:  735.557335496 - -train accuracy: 0.497205\n",
      "epoch: 52 - cost: 8.03943 mse:  741.043747577 - -train accuracy: 0.507852\n",
      "epoch: 53 - cost: 3.50863 mse:  733.284902987 - -train accuracy: 0.497738\n",
      "epoch: 54 - cost: 7.94594 mse:  736.965362397 - -train accuracy: 0.507852\n",
      "epoch: 55 - cost: 3.50959 mse:  731.327061253 - -train accuracy: 0.497738\n",
      "epoch: 56 - cost: 7.85416 mse:  732.900737129 - -train accuracy: 0.507852\n",
      "epoch: 57 - cost: 3.51016 mse:  729.437172592 - -train accuracy: 0.497738\n",
      "epoch: 58 - cost: 7.7654 mse:  728.744349274 - -train accuracy: 0.507852\n",
      "epoch: 59 - cost: 3.51316 mse:  727.398775626 - -train accuracy: 0.497471\n",
      "epoch: 60 - cost: 7.67696 mse:  724.702205847 - -train accuracy: 0.507852\n",
      "epoch: 61 - cost: 3.51616 mse:  725.14909702 - -train accuracy: 0.497738\n",
      "epoch: 62 - cost: 7.58952 mse:  720.669971097 - -train accuracy: 0.507852\n",
      "epoch: 63 - cost: 3.52098 mse:  723.414772966 - -train accuracy: 0.497738\n",
      "epoch: 64 - cost: 7.50068 mse:  717.084200376 - -train accuracy: 0.507852\n",
      "epoch: 65 - cost: 3.52567 mse:  721.326683677 - -train accuracy: 0.497738\n",
      "epoch: 66 - cost: 7.41374 mse:  713.0315533 - -train accuracy: 0.507852\n",
      "epoch: 67 - cost: 3.53258 mse:  719.662162299 - -train accuracy: 0.497738\n",
      "epoch: 68 - cost: 7.32696 mse:  709.442115309 - -train accuracy: 0.507852\n",
      "epoch: 69 - cost: 3.54039 mse:  718.010486295 - -train accuracy: 0.498004\n",
      "epoch: 70 - cost: 7.24004 mse:  705.688800974 - -train accuracy: 0.507852\n",
      "epoch: 71 - cost: 3.54405 mse:  715.888661961 - -train accuracy: 0.49827\n",
      "epoch: 72 - cost: 7.15674 mse:  701.860991136 - -train accuracy: 0.507852\n",
      "epoch: 73 - cost: 3.55207 mse:  714.127250943 - -train accuracy: 0.49827\n",
      "epoch: 74 - cost: 7.0727 mse:  698.312134165 - -train accuracy: 0.507852\n",
      "epoch: 75 - cost: 3.5598 mse:  712.344734822 - -train accuracy: 0.49827\n",
      "epoch: 76 - cost: 6.99028 mse:  694.777379719 - -train accuracy: 0.507852\n",
      "epoch: 77 - cost: 3.56828 mse:  710.776781825 - -train accuracy: 0.498536\n",
      "epoch: 78 - cost: 6.90762 mse:  691.396593184 - -train accuracy: 0.507852\n",
      "epoch: 79 - cost: 3.57883 mse:  709.044868822 - -train accuracy: 0.498536\n",
      "epoch: 80 - cost: 6.82449 mse:  688.140942276 - -train accuracy: 0.507852\n",
      "epoch: 81 - cost: 3.58972 mse:  707.645361624 - -train accuracy: 0.498536\n",
      "epoch: 82 - cost: 6.74179 mse:  685.111810715 - -train accuracy: 0.507852\n",
      "epoch: 83 - cost: 3.60216 mse:  706.553349036 - -train accuracy: 0.498536\n",
      "epoch: 84 - cost: 6.65908 mse:  682.577111414 - -train accuracy: 0.507852\n",
      "epoch: 85 - cost: 3.61295 mse:  705.248421466 - -train accuracy: 0.498802\n",
      "epoch: 86 - cost: 6.57823 mse:  679.529825609 - -train accuracy: 0.507852\n",
      "epoch: 87 - cost: 3.62352 mse:  703.850382149 - -train accuracy: 0.499068\n",
      "epoch: 88 - cost: 6.4963 mse:  676.744952892 - -train accuracy: 0.507852\n",
      "epoch: 89 - cost: 3.63592 mse:  702.373792767 - -train accuracy: 0.499068\n",
      "epoch: 90 - cost: 6.41559 mse:  673.865601855 - -train accuracy: 0.507852\n",
      "epoch: 91 - cost: 3.64691 mse:  700.875950294 - -train accuracy: 0.499601\n",
      "epoch: 92 - cost: 6.33555 mse:  670.409931565 - -train accuracy: 0.507852\n",
      "epoch: 93 - cost: 3.66028 mse:  699.253877336 - -train accuracy: 0.500133\n",
      "epoch: 94 - cost: 6.25357 mse:  667.468003809 - -train accuracy: 0.507852\n",
      "epoch: 95 - cost: 3.67548 mse:  697.842607262 - -train accuracy: 0.500133\n",
      "epoch: 96 - cost: 6.17236 mse:  664.723784635 - -train accuracy: 0.507852\n",
      "epoch: 97 - cost: 3.69041 mse:  696.756818314 - -train accuracy: 0.500399\n",
      "epoch: 98 - cost: 6.0914 mse:  662.100185278 - -train accuracy: 0.507852\n",
      "epoch: 99 - cost: 3.70451 mse:  696.134123599 - -train accuracy: 0.500399\n",
      "epoch: 100 - cost: 6.00981 mse:  659.96377472 - -train accuracy: 0.507852\n",
      "epoch: 101 - cost: 3.71895 mse:  695.69961226 - -train accuracy: 0.500665\n",
      "epoch: 102 - cost: 5.92973 mse:  658.245746451 - -train accuracy: 0.507852\n",
      "epoch: 103 - cost: 3.73382 mse:  695.359393378 - -train accuracy: 0.500665\n",
      "epoch: 104 - cost: 5.84904 mse:  656.362185705 - -train accuracy: 0.507852\n",
      "epoch: 105 - cost: 3.74948 mse:  695.02906601 - -train accuracy: 0.500665\n",
      "epoch: 106 - cost: 5.76736 mse:  654.733018894 - -train accuracy: 0.507852\n",
      "epoch: 107 - cost: 3.76538 mse:  694.48595502 - -train accuracy: 0.500932\n",
      "epoch: 108 - cost: 5.68704 mse:  652.947709271 - -train accuracy: 0.507852\n",
      "epoch: 109 - cost: 3.78128 mse:  694.472020005 - -train accuracy: 0.501198\n",
      "epoch: 110 - cost: 5.6081 mse:  651.883398003 - -train accuracy: 0.507852\n",
      "epoch: 111 - cost: 3.79647 mse:  694.307594689 - -train accuracy: 0.501198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 112 - cost: 5.5314 mse:  650.880821775 - -train accuracy: 0.507852\n",
      "epoch: 113 - cost: 3.80874 mse:  694.221233921 - -train accuracy: 0.501198\n",
      "epoch: 114 - cost: 5.45736 mse:  649.479121902 - -train accuracy: 0.507852\n",
      "epoch: 115 - cost: 3.82239 mse:  694.077276389 - -train accuracy: 0.501198\n",
      "epoch: 116 - cost: 5.38125 mse:  648.409799379 - -train accuracy: 0.507852\n",
      "epoch: 117 - cost: 3.83343 mse:  693.330973446 - -train accuracy: 0.501198\n",
      "epoch: 118 - cost: 5.31008 mse:  646.714131106 - -train accuracy: 0.507852\n",
      "epoch: 119 - cost: 3.84232 mse:  692.971405001 - -train accuracy: 0.501198\n",
      "epoch: 120 - cost: 5.24014 mse:  645.812975981 - -train accuracy: 0.507852\n",
      "epoch: 121 - cost: 3.84807 mse:  691.884564953 - -train accuracy: 0.501464\n",
      "epoch: 122 - cost: 5.17319 mse:  644.299782541 - -train accuracy: 0.508118\n",
      "epoch: 123 - cost: 3.8521 mse:  690.793409094 - -train accuracy: 0.501198\n",
      "epoch: 124 - cost: 5.10883 mse:  642.719886141 - -train accuracy: 0.508118\n",
      "epoch: 125 - cost: 3.8557 mse:  689.681034067 - -train accuracy: 0.501464\n",
      "epoch: 126 - cost: 5.04475 mse:  641.315664852 - -train accuracy: 0.508118\n",
      "epoch: 127 - cost: 3.85759 mse:  688.596401853 - -train accuracy: 0.501996\n",
      "epoch: 128 - cost: 4.98295 mse:  639.698722555 - -train accuracy: 0.508118\n",
      "epoch: 129 - cost: 3.85944 mse:  687.043627406 - -train accuracy: 0.501996\n",
      "epoch: 130 - cost: 4.91942 mse:  638.499554798 - -train accuracy: 0.508118\n",
      "epoch: 131 - cost: 3.85934 mse:  685.507988089 - -train accuracy: 0.501996\n",
      "epoch: 132 - cost: 4.85826 mse:  637.160609805 - -train accuracy: 0.508651\n",
      "epoch: 133 - cost: 3.8597 mse:  684.350769563 - -train accuracy: 0.502262\n",
      "epoch: 134 - cost: 4.79569 mse:  635.933878293 - -train accuracy: 0.508917\n",
      "epoch: 135 - cost: 3.85843 mse:  682.860312955 - -train accuracy: 0.502262\n",
      "epoch: 136 - cost: 4.73673 mse:  634.461673084 - -train accuracy: 0.509449\n",
      "epoch: 137 - cost: 3.85491 mse:  681.331374258 - -train accuracy: 0.502262\n",
      "epoch: 138 - cost: 4.6808 mse:  632.816018951 - -train accuracy: 0.509449\n",
      "epoch: 139 - cost: 3.85086 mse:  679.737265469 - -train accuracy: 0.503061\n",
      "epoch: 140 - cost: 4.62484 mse:  631.211945278 - -train accuracy: 0.509449\n",
      "epoch: 141 - cost: 3.84716 mse:  677.992322843 - -train accuracy: 0.503593\n",
      "epoch: 142 - cost: 4.57078 mse:  629.368843404 - -train accuracy: 0.509715\n",
      "epoch: 143 - cost: 3.8409 mse:  675.815839425 - -train accuracy: 0.503859\n",
      "epoch: 144 - cost: 4.51904 mse:  627.229308823 - -train accuracy: 0.510514\n",
      "epoch: 145 - cost: 3.83435 mse:  673.522297553 - -train accuracy: 0.504392\n",
      "epoch: 146 - cost: 4.46678 mse:  625.060558954 - -train accuracy: 0.51078\n",
      "epoch: 147 - cost: 3.82635 mse:  670.846193241 - -train accuracy: 0.504392\n",
      "epoch: 148 - cost: 4.4169 mse:  622.499324396 - -train accuracy: 0.51078\n",
      "epoch: 149 - cost: 3.8188 mse:  668.409460643 - -train accuracy: 0.504392\n",
      "epoch: 150 - cost: 4.36595 mse:  619.957873958 - -train accuracy: 0.51078\n",
      "epoch: 151 - cost: 3.8073 mse:  665.44396557 - -train accuracy: 0.504924\n",
      "epoch: 152 - cost: 4.32133 mse:  616.625706118 - -train accuracy: 0.511046\n",
      "epoch: 153 - cost: 3.79697 mse:  662.457605233 - -train accuracy: 0.50519\n",
      "epoch: 154 - cost: 4.27396 mse:  613.913392664 - -train accuracy: 0.511312\n",
      "epoch: 155 - cost: 3.78581 mse:  659.601095528 - -train accuracy: 0.50519\n",
      "epoch: 156 - cost: 4.22822 mse:  611.407250718 - -train accuracy: 0.511578\n",
      "epoch: 157 - cost: 3.7747 mse:  656.332783152 - -train accuracy: 0.50519\n",
      "epoch: 158 - cost: 4.18087 mse:  608.429178912 - -train accuracy: 0.512111\n",
      "epoch: 159 - cost: 3.7609 mse:  653.578088806 - -train accuracy: 0.505457\n",
      "epoch: 160 - cost: 4.135 mse:  605.720102814 - -train accuracy: 0.512377\n",
      "epoch: 161 - cost: 3.74828 mse:  650.69779736 - -train accuracy: 0.505723\n",
      "epoch: 162 - cost: 4.08977 mse:  602.981279145 - -train accuracy: 0.513175\n",
      "epoch: 163 - cost: 3.73136 mse:  647.340183846 - -train accuracy: 0.505989\n",
      "epoch: 164 - cost: 4.04838 mse:  599.879724196 - -train accuracy: 0.513442\n",
      "epoch: 165 - cost: 3.71463 mse:  644.273319755 - -train accuracy: 0.506521\n",
      "epoch: 166 - cost: 4.00608 mse:  597.16855394 - -train accuracy: 0.513974\n",
      "epoch: 167 - cost: 3.69905 mse:  641.063486522 - -train accuracy: 0.506255\n",
      "epoch: 168 - cost: 3.96338 mse:  593.859344333 - -train accuracy: 0.51424\n",
      "epoch: 169 - cost: 3.68416 mse:  638.174345187 - -train accuracy: 0.506255\n",
      "epoch: 170 - cost: 3.92318 mse:  590.902779163 - -train accuracy: 0.514506\n",
      "epoch: 171 - cost: 3.66611 mse:  635.087055388 - -train accuracy: 0.506255\n",
      "epoch: 172 - cost: 3.88368 mse:  587.80196867 - -train accuracy: 0.514772\n",
      "epoch: 173 - cost: 3.64749 mse:  631.641262838 - -train accuracy: 0.506255\n",
      "epoch: 174 - cost: 3.8459 mse:  584.600804599 - -train accuracy: 0.515039\n",
      "epoch: 175 - cost: 3.62593 mse:  628.266319738 - -train accuracy: 0.507053\n",
      "epoch: 176 - cost: 3.80955 mse:  581.286412235 - -train accuracy: 0.515305\n",
      "epoch: 177 - cost: 3.60595 mse:  624.835243441 - -train accuracy: 0.506787\n",
      "epoch: 178 - cost: 3.7717 mse:  577.967641028 - -train accuracy: 0.515837\n",
      "epoch: 179 - cost: 3.58624 mse:  621.583509059 - -train accuracy: 0.507586\n",
      "epoch: 180 - cost: 3.7334 mse:  574.9433273 - -train accuracy: 0.516369\n",
      "epoch: 181 - cost: 3.56524 mse:  618.398281156 - -train accuracy: 0.507586\n",
      "epoch: 182 - cost: 3.69627 mse:  571.812077811 - -train accuracy: 0.516902\n",
      "epoch: 183 - cost: 3.54574 mse:  615.294315612 - -train accuracy: 0.507852\n",
      "epoch: 184 - cost: 3.65968 mse:  568.723523478 - -train accuracy: 0.5177\n",
      "epoch: 185 - cost: 3.52338 mse:  611.902905505 - -train accuracy: 0.508384\n",
      "epoch: 186 - cost: 3.62413 mse:  565.555092068 - -train accuracy: 0.518499\n",
      "epoch: 187 - cost: 3.50143 mse:  608.493723539 - -train accuracy: 0.508917\n",
      "epoch: 188 - cost: 3.58964 mse:  562.210837255 - -train accuracy: 0.519031\n",
      "epoch: 189 - cost: 3.47901 mse:  604.988448709 - -train accuracy: 0.509183\n",
      "epoch: 190 - cost: 3.55464 mse:  558.724894675 - -train accuracy: 0.519563\n",
      "epoch: 191 - cost: 3.45792 mse:  601.411806307 - -train accuracy: 0.508917\n",
      "epoch: 192 - cost: 3.51867 mse:  555.656239106 - -train accuracy: 0.520362\n",
      "epoch: 193 - cost: 3.43586 mse:  598.344275787 - -train accuracy: 0.509183\n",
      "epoch: 194 - cost: 3.48341 mse:  552.756709977 - -train accuracy: 0.520894\n",
      "epoch: 195 - cost: 3.41379 mse:  595.284899841 - -train accuracy: 0.509981\n",
      "epoch: 196 - cost: 3.44922 mse:  550.021811773 - -train accuracy: 0.52116\n",
      "epoch: 197 - cost: 3.3889 mse:  592.084765377 - -train accuracy: 0.511312\n",
      "epoch: 198 - cost: 3.41484 mse:  547.250847002 - -train accuracy: 0.522758\n",
      "epoch: 199 - cost: 3.36635 mse:  589.175474741 - -train accuracy: 0.511578\n",
      "epoch: 200 - cost: 3.38064 mse:  544.126844224 - -train accuracy: 0.522758\n",
      "epoch: 201 - cost: 3.34362 mse:  585.805819878 - -train accuracy: 0.513442\n",
      "epoch: 202 - cost: 3.34661 mse:  541.035571447 - -train accuracy: 0.522758\n",
      "epoch: 203 - cost: 3.3202 mse:  582.557994226 - -train accuracy: 0.51424\n",
      "epoch: 204 - cost: 3.31473 mse:  537.957115417 - -train accuracy: 0.52329\n",
      "epoch: 205 - cost: 3.29758 mse:  579.45990892 - -train accuracy: 0.514506\n",
      "epoch: 206 - cost: 3.28121 mse:  535.368822198 - -train accuracy: 0.523822\n",
      "epoch: 207 - cost: 3.27648 mse:  576.714059252 - -train accuracy: 0.515039\n",
      "epoch: 208 - cost: 3.24762 mse:  532.995505857 - -train accuracy: 0.524887\n",
      "epoch: 209 - cost: 3.25172 mse:  574.041301665 - -train accuracy: 0.515571\n",
      "epoch: 210 - cost: 3.21404 mse:  530.922333893 - -train accuracy: 0.525419\n",
      "epoch: 211 - cost: 3.22707 mse:  571.679850015 - -train accuracy: 0.516902\n",
      "epoch: 212 - cost: 3.18228 mse:  528.866392529 - -train accuracy: 0.526484\n",
      "epoch: 213 - cost: 3.20372 mse:  569.13013261 - -train accuracy: 0.518499\n",
      "epoch: 214 - cost: 3.14992 mse:  526.661486536 - -train accuracy: 0.52675\n",
      "epoch: 215 - cost: 3.17778 mse:  566.610612341 - -train accuracy: 0.518765\n",
      "epoch: 216 - cost: 3.11718 mse:  524.425581208 - -train accuracy: 0.527282\n",
      "epoch: 217 - cost: 3.15353 mse:  564.171615032 - -train accuracy: 0.519563\n",
      "epoch: 218 - cost: 3.0856 mse:  522.416418099 - -train accuracy: 0.527815\n",
      "epoch: 219 - cost: 3.12857 mse:  561.893636918 - -train accuracy: 0.520628\n",
      "epoch: 220 - cost: 3.05213 mse:  520.873002078 - -train accuracy: 0.529412\n",
      "epoch: 221 - cost: 3.10557 mse:  560.124959998 - -train accuracy: 0.520894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 222 - cost: 3.02296 mse:  519.177804679 - -train accuracy: 0.529678\n",
      "epoch: 223 - cost: 3.07965 mse:  557.94374387 - -train accuracy: 0.520628\n",
      "epoch: 224 - cost: 2.99153 mse:  517.445026559 - -train accuracy: 0.531009\n",
      "epoch: 225 - cost: 3.05541 mse:  556.14655216 - -train accuracy: 0.521693\n",
      "epoch: 226 - cost: 2.95984 mse:  516.111004964 - -train accuracy: 0.531275\n",
      "epoch: 227 - cost: 3.03213 mse:  554.296249066 - -train accuracy: 0.522758\n",
      "epoch: 228 - cost: 2.93079 mse:  514.668572912 - -train accuracy: 0.53234\n",
      "epoch: 229 - cost: 3.00721 mse:  552.428230448 - -train accuracy: 0.524621\n",
      "epoch: 230 - cost: 2.90075 mse:  513.37494491 - -train accuracy: 0.532872\n",
      "epoch: 231 - cost: 2.98224 mse:  550.652752994 - -train accuracy: 0.525419\n",
      "epoch: 232 - cost: 2.87043 mse:  511.996303111 - -train accuracy: 0.534203\n",
      "epoch: 233 - cost: 2.95789 mse:  548.923066667 - -train accuracy: 0.525685\n",
      "epoch: 234 - cost: 2.83947 mse:  511.057246364 - -train accuracy: 0.534469\n",
      "epoch: 235 - cost: 2.9323 mse:  547.517753459 - -train accuracy: 0.526484\n",
      "epoch: 236 - cost: 2.8105 mse:  510.266683695 - -train accuracy: 0.535001\n",
      "epoch: 237 - cost: 2.90733 mse:  546.109947019 - -train accuracy: 0.527282\n",
      "epoch: 238 - cost: 2.77963 mse:  509.793466521 - -train accuracy: 0.535534\n",
      "epoch: 239 - cost: 2.88237 mse:  545.444244532 - -train accuracy: 0.528613\n",
      "epoch: 240 - cost: 2.74754 mse:  510.368834375 - -train accuracy: 0.5358\n",
      "epoch: 241 - cost: 2.8577 mse:  545.230204596 - -train accuracy: 0.529944\n",
      "epoch: 242 - cost: 2.7176 mse:  511.15091369 - -train accuracy: 0.536332\n",
      "epoch: 243 - cost: 2.83218 mse:  545.212955025 - -train accuracy: 0.531275\n",
      "epoch: 244 - cost: 2.6859 mse:  512.582212954 - -train accuracy: 0.537131\n",
      "epoch: 245 - cost: 2.80562 mse:  545.512195795 - -train accuracy: 0.532872\n",
      "epoch: 246 - cost: 2.65483 mse:  514.406821874 - -train accuracy: 0.537929\n",
      "epoch: 247 - cost: 2.77844 mse:  545.77827514 - -train accuracy: 0.534203\n",
      "epoch: 248 - cost: 2.62396 mse:  516.350620694 - -train accuracy: 0.538195\n",
      "epoch: 249 - cost: 2.74773 mse:  545.273729767 - -train accuracy: 0.536332\n",
      "epoch: 250 - cost: 2.59201 mse:  518.09495965 - -train accuracy: 0.539526\n",
      "epoch: 251 - cost: 2.71786 mse:  544.761725554 - -train accuracy: 0.536332\n",
      "epoch: 252 - cost: 2.56113 mse:  519.760059235 - -train accuracy: 0.540857\n",
      "epoch: 253 - cost: 2.68868 mse:  543.984152975 - -train accuracy: 0.537929\n",
      "epoch: 254 - cost: 2.53489 mse:  520.461107249 - -train accuracy: 0.541922\n",
      "epoch: 255 - cost: 2.65921 mse:  542.402077454 - -train accuracy: 0.539526\n",
      "epoch: 256 - cost: 2.50887 mse:  520.353078755 - -train accuracy: 0.542986\n",
      "epoch: 257 - cost: 2.63082 mse:  540.193364242 - -train accuracy: 0.540325\n",
      "epoch: 258 - cost: 2.48423 mse:  519.363214983 - -train accuracy: 0.543519\n",
      "epoch: 259 - cost: 2.60463 mse:  538.197552522 - -train accuracy: 0.541389\n",
      "epoch: 260 - cost: 2.45994 mse:  518.32108189 - -train accuracy: 0.544583\n",
      "epoch: 261 - cost: 2.58065 mse:  536.124210359 - -train accuracy: 0.54272\n",
      "epoch: 262 - cost: 2.43618 mse:  517.172307582 - -train accuracy: 0.545648\n",
      "epoch: 263 - cost: 2.55556 mse:  533.893306684 - -train accuracy: 0.543253\n",
      "epoch: 264 - cost: 2.41204 mse:  515.975238186 - -train accuracy: 0.546713\n",
      "epoch: 265 - cost: 2.53208 mse:  531.864347954 - -train accuracy: 0.543519\n",
      "epoch: 266 - cost: 2.39084 mse:  514.39018603 - -train accuracy: 0.54831\n",
      "epoch: 267 - cost: 2.50891 mse:  529.843964459 - -train accuracy: 0.544051\n",
      "epoch: 268 - cost: 2.36985 mse:  512.986300468 - -train accuracy: 0.548842\n",
      "epoch: 269 - cost: 2.4852 mse:  527.588209187 - -train accuracy: 0.544583\n",
      "epoch: 270 - cost: 2.34757 mse:  511.18511538 - -train accuracy: 0.550972\n",
      "epoch: 271 - cost: 2.46375 mse:  525.564032204 - -train accuracy: 0.54485\n",
      "epoch: 272 - cost: 2.32892 mse:  509.401236765 - -train accuracy: 0.553633\n",
      "epoch: 273 - cost: 2.44195 mse:  523.240678121 - -train accuracy: 0.545116\n",
      "epoch: 274 - cost: 2.30859 mse:  507.678025753 - -train accuracy: 0.554166\n",
      "epoch: 275 - cost: 2.42119 mse:  521.206882531 - -train accuracy: 0.547245\n",
      "epoch: 276 - cost: 2.28993 mse:  506.317673515 - -train accuracy: 0.555763\n",
      "epoch: 277 - cost: 2.40156 mse:  519.322908327 - -train accuracy: 0.547777\n",
      "epoch: 278 - cost: 2.27302 mse:  504.697525553 - -train accuracy: 0.556827\n",
      "epoch: 279 - cost: 2.38123 mse:  517.221919504 - -train accuracy: 0.548044\n",
      "epoch: 280 - cost: 2.25426 mse:  503.11621101 - -train accuracy: 0.557626\n",
      "epoch: 281 - cost: 2.3619 mse:  515.44011545 - -train accuracy: 0.54831\n",
      "epoch: 282 - cost: 2.23762 mse:  501.723551484 - -train accuracy: 0.558158\n",
      "epoch: 283 - cost: 2.34392 mse:  513.796033046 - -train accuracy: 0.549907\n",
      "epoch: 284 - cost: 2.22227 mse:  500.418880177 - -train accuracy: 0.55869\n",
      "epoch: 285 - cost: 2.32577 mse:  511.920142367 - -train accuracy: 0.550173\n",
      "epoch: 286 - cost: 2.20577 mse:  498.934486419 - -train accuracy: 0.559489\n",
      "epoch: 287 - cost: 2.30816 mse:  510.076604015 - -train accuracy: 0.551504\n",
      "epoch: 288 - cost: 2.19025 mse:  497.667844964 - -train accuracy: 0.561086\n",
      "epoch: 289 - cost: 2.29088 mse:  508.506131271 - -train accuracy: 0.551504\n",
      "epoch: 290 - cost: 2.17458 mse:  496.393392971 - -train accuracy: 0.561884\n",
      "epoch: 291 - cost: 2.27307 mse:  506.836344981 - -train accuracy: 0.55177\n",
      "epoch: 292 - cost: 2.15929 mse:  495.045313169 - -train accuracy: 0.562949\n",
      "epoch: 293 - cost: 2.25516 mse:  505.080192649 - -train accuracy: 0.553101\n",
      "epoch: 294 - cost: 2.14317 mse:  493.654306054 - -train accuracy: 0.564546\n",
      "epoch: 295 - cost: 2.23641 mse:  503.22259814 - -train accuracy: 0.553367\n",
      "epoch: 296 - cost: 2.12753 mse:  492.198352079 - -train accuracy: 0.567208\n",
      "epoch: 297 - cost: 2.22005 mse:  501.460988227 - -train accuracy: 0.554166\n",
      "epoch: 298 - cost: 2.11352 mse:  490.887930377 - -train accuracy: 0.568006\n",
      "epoch: 299 - cost: 2.20444 mse:  499.902880557 - -train accuracy: 0.554964\n",
      "epoch: 300 - cost: 2.09928 mse:  489.810375499 - -train accuracy: 0.569603\n",
      "epoch: 301 - cost: 2.18929 mse:  498.694464648 - -train accuracy: 0.555496\n",
      "epoch: 302 - cost: 2.08682 mse:  488.673552508 - -train accuracy: 0.570136\n",
      "epoch: 303 - cost: 2.17421 mse:  497.38296263 - -train accuracy: 0.556295\n",
      "epoch: 304 - cost: 2.0741 mse:  487.699479384 - -train accuracy: 0.570668\n",
      "epoch: 305 - cost: 2.15864 mse:  496.027348726 - -train accuracy: 0.557093\n",
      "epoch: 306 - cost: 2.0607 mse:  486.488261645 - -train accuracy: 0.571999\n",
      "epoch: 307 - cost: 2.14413 mse:  494.515789605 - -train accuracy: 0.557892\n",
      "epoch: 308 - cost: 2.04744 mse:  485.304387787 - -train accuracy: 0.572531\n",
      "epoch: 309 - cost: 2.12867 mse:  493.00557491 - -train accuracy: 0.558424\n",
      "epoch: 310 - cost: 2.03483 mse:  483.963547191 - -train accuracy: 0.573596\n",
      "epoch: 311 - cost: 2.11363 mse:  491.374486407 - -train accuracy: 0.559489\n",
      "epoch: 312 - cost: 2.0221 mse:  482.619948297 - -train accuracy: 0.574927\n",
      "epoch: 313 - cost: 2.09829 mse:  489.895967332 - -train accuracy: 0.560554\n",
      "epoch: 314 - cost: 2.00953 mse:  481.370881202 - -train accuracy: 0.575193\n",
      "epoch: 315 - cost: 2.08416 mse:  488.473512164 - -train accuracy: 0.56082\n",
      "epoch: 316 - cost: 1.99771 mse:  480.244347159 - -train accuracy: 0.575193\n",
      "epoch: 317 - cost: 2.07015 mse:  487.225835154 - -train accuracy: 0.561086\n",
      "epoch: 318 - cost: 1.98591 mse:  479.250493409 - -train accuracy: 0.575459\n",
      "epoch: 319 - cost: 2.0557 mse:  486.045787175 - -train accuracy: 0.56082\n",
      "epoch: 320 - cost: 1.97412 mse:  478.202878585 - -train accuracy: 0.576524\n",
      "epoch: 321 - cost: 2.04201 mse:  484.745978495 - -train accuracy: 0.56082\n",
      "epoch: 322 - cost: 1.96246 mse:  477.271692011 - -train accuracy: 0.577588\n",
      "epoch: 323 - cost: 2.02904 mse:  483.681170403 - -train accuracy: 0.561884\n",
      "epoch: 324 - cost: 1.952 mse:  476.564121178 - -train accuracy: 0.578387\n",
      "epoch: 325 - cost: 2.01597 mse:  482.593687179 - -train accuracy: 0.562949\n",
      "epoch: 326 - cost: 1.94113 mse:  475.694522803 - -train accuracy: 0.578653\n",
      "epoch: 327 - cost: 2.00323 mse:  481.453762472 - -train accuracy: 0.563215\n",
      "epoch: 328 - cost: 1.92997 mse:  474.745595619 - -train accuracy: 0.579452\n",
      "epoch: 329 - cost: 1.99044 mse:  480.567353697 - -train accuracy: 0.564546\n",
      "epoch: 330 - cost: 1.91939 mse:  474.03289936 - -train accuracy: 0.58025\n",
      "epoch: 331 - cost: 1.9779 mse:  479.620493468 - -train accuracy: 0.565611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 332 - cost: 1.90953 mse:  473.1890525 - -train accuracy: 0.581049\n",
      "epoch: 333 - cost: 1.96608 mse:  478.536314624 - -train accuracy: 0.565345\n",
      "epoch: 334 - cost: 1.90038 mse:  472.280971068 - -train accuracy: 0.581581\n",
      "epoch: 335 - cost: 1.95392 mse:  477.482688668 - -train accuracy: 0.565611\n",
      "epoch: 336 - cost: 1.89 mse:  471.362507756 - -train accuracy: 0.582113\n",
      "epoch: 337 - cost: 1.94145 mse:  476.441808202 - -train accuracy: 0.566409\n",
      "epoch: 338 - cost: 1.88005 mse:  470.651316399 - -train accuracy: 0.582646\n",
      "epoch: 339 - cost: 1.92947 mse:  475.671603907 - -train accuracy: 0.567474\n",
      "epoch: 340 - cost: 1.86955 mse:  470.071720543 - -train accuracy: 0.58371\n",
      "epoch: 341 - cost: 1.91775 mse:  474.81806661 - -train accuracy: 0.567474\n",
      "epoch: 342 - cost: 1.86051 mse:  469.421302591 - -train accuracy: 0.584243\n",
      "epoch: 343 - cost: 1.90564 mse:  474.150013195 - -train accuracy: 0.568006\n",
      "epoch: 344 - cost: 1.85064 mse:  468.80073501 - -train accuracy: 0.584243\n",
      "epoch: 345 - cost: 1.89439 mse:  473.477552374 - -train accuracy: 0.568805\n",
      "epoch: 346 - cost: 1.84188 mse:  468.313468327 - -train accuracy: 0.584243\n",
      "epoch: 347 - cost: 1.88259 mse:  472.898173751 - -train accuracy: 0.569071\n",
      "epoch: 348 - cost: 1.83199 mse:  467.810693648 - -train accuracy: 0.584509\n",
      "epoch: 349 - cost: 1.87057 mse:  472.207239238 - -train accuracy: 0.56987\n",
      "epoch: 350 - cost: 1.82195 mse:  467.349703088 - -train accuracy: 0.585574\n",
      "epoch: 351 - cost: 1.85943 mse:  471.700606819 - -train accuracy: 0.570402\n",
      "epoch: 352 - cost: 1.81247 mse:  467.248168976 - -train accuracy: 0.586638\n",
      "epoch: 353 - cost: 1.84857 mse:  471.42315147 - -train accuracy: 0.570934\n",
      "epoch: 354 - cost: 1.80516 mse:  467.00140962 - -train accuracy: 0.587703\n",
      "epoch: 355 - cost: 1.83729 mse:  470.835438556 - -train accuracy: 0.571733\n",
      "epoch: 356 - cost: 1.79566 mse:  466.54796983 - -train accuracy: 0.588235\n",
      "epoch: 357 - cost: 1.82596 mse:  470.310410983 - -train accuracy: 0.572531\n",
      "epoch: 358 - cost: 1.78673 mse:  466.121978802 - -train accuracy: 0.588501\n",
      "epoch: 359 - cost: 1.81497 mse:  469.892234664 - -train accuracy: 0.572265\n",
      "epoch: 360 - cost: 1.77817 mse:  465.859376518 - -train accuracy: 0.589034\n",
      "epoch: 361 - cost: 1.80498 mse:  469.48254731 - -train accuracy: 0.572797\n",
      "epoch: 362 - cost: 1.77053 mse:  465.519203033 - -train accuracy: 0.5893\n",
      "epoch: 363 - cost: 1.79435 mse:  468.934715354 - -train accuracy: 0.57333\n",
      "epoch: 364 - cost: 1.76199 mse:  464.957597204 - -train accuracy: 0.590099\n",
      "epoch: 365 - cost: 1.78315 mse:  468.305190212 - -train accuracy: 0.575193\n",
      "epoch: 366 - cost: 1.75305 mse:  464.47354475 - -train accuracy: 0.591429\n",
      "epoch: 367 - cost: 1.77185 mse:  467.779755045 - -train accuracy: 0.575725\n",
      "epoch: 368 - cost: 1.74419 mse:  463.877324376 - -train accuracy: 0.592228\n",
      "epoch: 369 - cost: 1.76093 mse:  467.142635215 - -train accuracy: 0.576258\n",
      "epoch: 370 - cost: 1.73588 mse:  463.426898831 - -train accuracy: 0.593026\n",
      "epoch: 371 - cost: 1.74986 mse:  466.530713125 - -train accuracy: 0.57679\n",
      "epoch: 372 - cost: 1.72669 mse:  463.11933308 - -train accuracy: 0.593026\n",
      "epoch: 373 - cost: 1.73962 mse:  466.209605625 - -train accuracy: 0.57679\n",
      "epoch: 374 - cost: 1.71906 mse:  462.830250333 - -train accuracy: 0.593825\n",
      "epoch: 375 - cost: 1.72978 mse:  465.680917865 - -train accuracy: 0.57679\n",
      "epoch: 376 - cost: 1.71161 mse:  462.452305934 - -train accuracy: 0.594091\n",
      "epoch: 377 - cost: 1.71986 mse:  465.116064124 - -train accuracy: 0.57679\n",
      "epoch: 378 - cost: 1.70438 mse:  462.036863867 - -train accuracy: 0.594357\n",
      "epoch: 379 - cost: 1.70968 mse:  464.526674542 - -train accuracy: 0.57679\n",
      "epoch: 380 - cost: 1.69619 mse:  461.54517173 - -train accuracy: 0.594623\n",
      "epoch: 381 - cost: 1.7002 mse:  464.057671009 - -train accuracy: 0.577322\n",
      "epoch: 382 - cost: 1.6885 mse:  461.126687053 - -train accuracy: 0.595156\n",
      "epoch: 383 - cost: 1.6905 mse:  463.44487834 - -train accuracy: 0.577056\n",
      "epoch: 384 - cost: 1.68144 mse:  460.623540567 - -train accuracy: 0.596487\n",
      "epoch: 385 - cost: 1.6806 mse:  462.79728526 - -train accuracy: 0.577588\n",
      "epoch: 386 - cost: 1.67418 mse:  460.09760363 - -train accuracy: 0.597285\n",
      "epoch: 387 - cost: 1.67116 mse:  462.092050979 - -train accuracy: 0.577588\n",
      "epoch: 388 - cost: 1.66728 mse:  459.468949671 - -train accuracy: 0.597551\n",
      "epoch: 389 - cost: 1.66106 mse:  461.407565606 - -train accuracy: 0.577855\n",
      "epoch: 390 - cost: 1.65905 mse:  459.003923239 - -train accuracy: 0.59835\n",
      "epoch: 391 - cost: 1.65136 mse:  460.902133728 - -train accuracy: 0.577855\n",
      "epoch: 392 - cost: 1.65208 mse:  458.593606567 - -train accuracy: 0.599414\n",
      "epoch: 393 - cost: 1.64205 mse:  460.463105935 - -train accuracy: 0.578653\n",
      "epoch: 394 - cost: 1.64502 mse:  458.135003766 - -train accuracy: 0.599414\n",
      "epoch: 395 - cost: 1.63274 mse:  459.964973818 - -train accuracy: 0.579186\n",
      "epoch: 396 - cost: 1.6382 mse:  457.700212571 - -train accuracy: 0.599681\n",
      "epoch: 397 - cost: 1.62336 mse:  459.373998619 - -train accuracy: 0.579452\n",
      "epoch: 398 - cost: 1.63068 mse:  457.245366401 - -train accuracy: 0.600745\n",
      "epoch: 399 - cost: 1.61397 mse:  458.815192833 - -train accuracy: 0.579186\n",
      "epoch: 400 - cost: 1.6235 mse:  456.851321555 - -train accuracy: 0.601278\n",
      "epoch: 401 - cost: 1.60486 mse:  458.389423467 - -train accuracy: 0.579984\n",
      "epoch: 402 - cost: 1.61678 mse:  456.423718511 - -train accuracy: 0.601544\n",
      "epoch: 403 - cost: 1.59588 mse:  457.765588056 - -train accuracy: 0.579718\n",
      "epoch: 404 - cost: 1.60984 mse:  455.819343887 - -train accuracy: 0.60181\n",
      "epoch: 405 - cost: 1.58671 mse:  457.129991385 - -train accuracy: 0.580516\n",
      "epoch: 406 - cost: 1.60252 mse:  455.270458869 - -train accuracy: 0.602342\n",
      "epoch: 407 - cost: 1.57791 mse:  456.384070596 - -train accuracy: 0.581581\n",
      "epoch: 408 - cost: 1.59573 mse:  454.703727352 - -train accuracy: 0.603407\n",
      "epoch: 409 - cost: 1.56897 mse:  455.616100159 - -train accuracy: 0.582113\n",
      "epoch: 410 - cost: 1.58886 mse:  454.054212158 - -train accuracy: 0.603939\n",
      "epoch: 411 - cost: 1.56049 mse:  454.850782611 - -train accuracy: 0.58238\n",
      "epoch: 412 - cost: 1.58263 mse:  453.449233234 - -train accuracy: 0.603939\n",
      "epoch: 413 - cost: 1.55183 mse:  454.134626452 - -train accuracy: 0.582646\n",
      "epoch: 414 - cost: 1.5763 mse:  452.859068106 - -train accuracy: 0.604738\n",
      "epoch: 415 - cost: 1.54378 mse:  453.527650091 - -train accuracy: 0.583178\n",
      "epoch: 416 - cost: 1.57001 mse:  452.391055965 - -train accuracy: 0.605536\n",
      "epoch: 417 - cost: 1.53525 mse:  452.911236544 - -train accuracy: 0.583444\n",
      "epoch: 418 - cost: 1.56315 mse:  451.920865083 - -train accuracy: 0.606335\n",
      "epoch: 419 - cost: 1.52698 mse:  452.341722293 - -train accuracy: 0.584509\n",
      "epoch: 420 - cost: 1.55673 mse:  451.41403345 - -train accuracy: 0.606867\n",
      "epoch: 421 - cost: 1.51877 mse:  451.788117118 - -train accuracy: 0.585041\n",
      "epoch: 422 - cost: 1.5503 mse:  451.009920773 - -train accuracy: 0.607932\n",
      "epoch: 423 - cost: 1.51039 mse:  451.359675491 - -train accuracy: 0.585041\n",
      "epoch: 424 - cost: 1.54407 mse:  450.773224386 - -train accuracy: 0.608198\n",
      "epoch: 425 - cost: 1.50293 mse:  450.907480875 - -train accuracy: 0.585307\n",
      "epoch: 426 - cost: 1.53876 mse:  450.537425348 - -train accuracy: 0.608198\n",
      "epoch: 427 - cost: 1.4963 mse:  450.635853466 - -train accuracy: 0.585574\n",
      "epoch: 428 - cost: 1.53427 mse:  450.301365344 - -train accuracy: 0.608198\n",
      "epoch: 429 - cost: 1.48935 mse:  450.348119761 - -train accuracy: 0.585574\n",
      "epoch: 430 - cost: 1.5288 mse:  450.048087928 - -train accuracy: 0.608198\n",
      "epoch: 431 - cost: 1.48174 mse:  450.026335833 - -train accuracy: 0.58584\n",
      "epoch: 432 - cost: 1.52272 mse:  449.827448334 - -train accuracy: 0.608997\n",
      "epoch: 433 - cost: 1.47464 mse:  449.827148755 - -train accuracy: 0.586372\n",
      "epoch: 434 - cost: 1.51731 mse:  449.678040368 - -train accuracy: 0.608997\n",
      "epoch: 435 - cost: 1.46728 mse:  449.621280484 - -train accuracy: 0.586106\n",
      "epoch: 436 - cost: 1.51169 mse:  449.568473673 - -train accuracy: 0.608997\n",
      "epoch: 437 - cost: 1.46037 mse:  449.300610668 - -train accuracy: 0.586638\n",
      "epoch: 438 - cost: 1.50615 mse:  449.337625103 - -train accuracy: 0.609529\n",
      "epoch: 439 - cost: 1.453 mse:  448.885302902 - -train accuracy: 0.587437\n",
      "epoch: 440 - cost: 1.50051 mse:  448.991818902 - -train accuracy: 0.610061\n",
      "epoch: 441 - cost: 1.44559 mse:  448.340444716 - -train accuracy: 0.587437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 442 - cost: 1.49482 mse:  448.610258445 - -train accuracy: 0.61086\n",
      "epoch: 443 - cost: 1.4381 mse:  447.941249556 - -train accuracy: 0.586904\n",
      "epoch: 444 - cost: 1.48944 mse:  448.19686853 - -train accuracy: 0.611126\n",
      "epoch: 445 - cost: 1.4307 mse:  447.388750692 - -train accuracy: 0.587171\n",
      "epoch: 446 - cost: 1.48323 mse:  447.767429894 - -train accuracy: 0.611658\n",
      "epoch: 447 - cost: 1.42324 mse:  446.946616526 - -train accuracy: 0.586904\n",
      "epoch: 448 - cost: 1.47713 mse:  447.484124108 - -train accuracy: 0.611658\n",
      "epoch: 449 - cost: 1.4161 mse:  446.592838886 - -train accuracy: 0.587437\n",
      "epoch: 450 - cost: 1.47149 mse:  447.16134063 - -train accuracy: 0.612457\n",
      "epoch: 451 - cost: 1.40929 mse:  446.335638648 - -train accuracy: 0.587437\n",
      "epoch: 452 - cost: 1.46534 mse:  446.979193549 - -train accuracy: 0.612723\n",
      "epoch: 453 - cost: 1.40179 mse:  446.033259655 - -train accuracy: 0.587171\n",
      "epoch: 454 - cost: 1.45916 mse:  446.761706202 - -train accuracy: 0.613521\n",
      "epoch: 455 - cost: 1.39481 mse:  445.824352069 - -train accuracy: 0.587171\n",
      "epoch: 456 - cost: 1.45358 mse:  446.605498485 - -train accuracy: 0.614586\n",
      "epoch: 457 - cost: 1.38724 mse:  445.502837093 - -train accuracy: 0.586904\n",
      "epoch: 458 - cost: 1.44763 mse:  446.335256218 - -train accuracy: 0.615385\n",
      "epoch: 459 - cost: 1.3807 mse:  445.217036297 - -train accuracy: 0.586638\n",
      "epoch: 460 - cost: 1.44225 mse:  446.01863436 - -train accuracy: 0.615651\n",
      "epoch: 461 - cost: 1.3742 mse:  444.920741478 - -train accuracy: 0.587171\n",
      "epoch: 462 - cost: 1.43636 mse:  445.76022606 - -train accuracy: 0.616449\n",
      "epoch: 463 - cost: 1.3681 mse:  444.673936119 - -train accuracy: 0.587437\n",
      "epoch: 464 - cost: 1.4309 mse:  445.536999337 - -train accuracy: 0.616449\n",
      "epoch: 465 - cost: 1.36141 mse:  444.458796162 - -train accuracy: 0.586904\n",
      "epoch: 466 - cost: 1.4251 mse:  445.364367416 - -train accuracy: 0.616449\n",
      "epoch: 467 - cost: 1.35405 mse:  444.151080315 - -train accuracy: 0.587171\n",
      "epoch: 468 - cost: 1.41848 mse:  445.096986126 - -train accuracy: 0.616982\n",
      "epoch: 469 - cost: 1.34726 mse:  443.929801601 - -train accuracy: 0.587703\n",
      "epoch: 470 - cost: 1.41276 mse:  444.958743165 - -train accuracy: 0.617248\n",
      "epoch: 471 - cost: 1.3403 mse:  443.592252437 - -train accuracy: 0.587969\n",
      "epoch: 472 - cost: 1.40691 mse:  444.739913855 - -train accuracy: 0.618579\n",
      "epoch: 473 - cost: 1.3342 mse:  443.466238783 - -train accuracy: 0.587969\n",
      "epoch: 474 - cost: 1.40153 mse:  444.486394194 - -train accuracy: 0.619111\n",
      "epoch: 475 - cost: 1.32861 mse:  443.19668289 - -train accuracy: 0.588501\n",
      "epoch: 476 - cost: 1.39714 mse:  444.304325858 - -train accuracy: 0.619111\n",
      "epoch: 477 - cost: 1.32299 mse:  442.991735162 - -train accuracy: 0.588501\n",
      "epoch: 478 - cost: 1.39215 mse:  444.012842703 - -train accuracy: 0.61991\n",
      "epoch: 479 - cost: 1.3165 mse:  442.621239463 - -train accuracy: 0.588235\n",
      "epoch: 480 - cost: 1.38687 mse:  443.807115844 - -train accuracy: 0.620176\n",
      "epoch: 481 - cost: 1.31048 mse:  442.416560566 - -train accuracy: 0.587969\n",
      "epoch: 482 - cost: 1.38165 mse:  443.70337928 - -train accuracy: 0.620442\n",
      "epoch: 483 - cost: 1.30428 mse:  442.173109848 - -train accuracy: 0.588235\n",
      "epoch: 484 - cost: 1.37631 mse:  443.526108087 - -train accuracy: 0.620442\n",
      "epoch: 485 - cost: 1.29787 mse:  442.043160154 - -train accuracy: 0.588768\n",
      "epoch: 486 - cost: 1.37055 mse:  443.411429242 - -train accuracy: 0.620974\n",
      "epoch: 487 - cost: 1.29221 mse:  441.900582265 - -train accuracy: 0.589034\n",
      "epoch: 488 - cost: 1.3659 mse:  443.229945098 - -train accuracy: 0.62124\n",
      "epoch: 489 - cost: 1.28657 mse:  441.758360261 - -train accuracy: 0.589034\n",
      "epoch: 490 - cost: 1.36101 mse:  443.043016869 - -train accuracy: 0.622039\n",
      "epoch: 491 - cost: 1.28111 mse:  441.720662432 - -train accuracy: 0.589034\n",
      "epoch: 492 - cost: 1.35582 mse:  443.001774984 - -train accuracy: 0.622837\n",
      "epoch: 493 - cost: 1.2753 mse:  441.580577967 - -train accuracy: 0.589566\n",
      "epoch: 494 - cost: 1.35102 mse:  442.941535073 - -train accuracy: 0.62337\n",
      "epoch: 495 - cost: 1.26909 mse:  441.378821377 - -train accuracy: 0.589832\n",
      "epoch: 496 - cost: 1.34545 mse:  442.733562344 - -train accuracy: 0.623902\n",
      "epoch: 497 - cost: 1.26255 mse:  441.161004925 - -train accuracy: 0.5893\n",
      "epoch: 498 - cost: 1.34036 mse:  442.533337343 - -train accuracy: 0.624701\n",
      "epoch: 499 - cost: 1.25684 mse:  440.91169116 - -train accuracy: 0.589034\n",
      "epoch: 500 - cost: 1.33435 mse:  442.347097856 - -train accuracy: 0.624967\n",
      "epoch: 501 - cost: 1.25026 mse:  440.68094476 - -train accuracy: 0.588501\n",
      "epoch: 502 - cost: 1.32945 mse:  442.128738866 - -train accuracy: 0.625765\n",
      "epoch: 503 - cost: 1.24459 mse:  440.466046528 - -train accuracy: 0.588768\n",
      "epoch: 504 - cost: 1.32421 mse:  441.979064815 - -train accuracy: 0.626298\n",
      "epoch: 505 - cost: 1.23901 mse:  440.303520466 - -train accuracy: 0.5893\n",
      "epoch: 506 - cost: 1.31889 mse:  441.818569193 - -train accuracy: 0.626564\n",
      "epoch: 507 - cost: 1.23278 mse:  440.042131486 - -train accuracy: 0.589034\n",
      "epoch: 508 - cost: 1.31219 mse:  441.715809998 - -train accuracy: 0.627096\n",
      "epoch: 509 - cost: 1.22666 mse:  439.944820033 - -train accuracy: 0.589566\n",
      "epoch: 510 - cost: 1.30592 mse:  441.597554777 - -train accuracy: 0.627628\n",
      "epoch: 511 - cost: 1.22086 mse:  439.670148452 - -train accuracy: 0.589832\n",
      "epoch: 512 - cost: 1.30076 mse:  441.451980346 - -train accuracy: 0.628161\n",
      "epoch: 513 - cost: 1.21603 mse:  439.616159377 - -train accuracy: 0.5893\n",
      "epoch: 514 - cost: 1.29616 mse:  441.364561763 - -train accuracy: 0.628161\n",
      "epoch: 515 - cost: 1.21013 mse:  439.236298032 - -train accuracy: 0.590099\n",
      "epoch: 516 - cost: 1.29048 mse:  441.061224857 - -train accuracy: 0.628161\n",
      "epoch: 517 - cost: 1.20553 mse:  438.98048771 - -train accuracy: 0.589566\n",
      "epoch: 518 - cost: 1.28657 mse:  440.857046668 - -train accuracy: 0.628693\n",
      "epoch: 519 - cost: 1.20059 mse:  438.577689338 - -train accuracy: 0.589832\n",
      "epoch: 520 - cost: 1.28063 mse:  440.520476559 - -train accuracy: 0.629492\n",
      "epoch: 521 - cost: 1.19374 mse:  437.928937967 - -train accuracy: 0.590099\n",
      "epoch: 522 - cost: 1.27379 mse:  439.985359933 - -train accuracy: 0.63029\n",
      "epoch: 523 - cost: 1.18812 mse:  437.28477113 - -train accuracy: 0.590099\n",
      "epoch: 524 - cost: 1.26904 mse:  439.303110679 - -train accuracy: 0.630556\n",
      "epoch: 525 - cost: 1.1833 mse:  436.362013161 - -train accuracy: 0.590897\n",
      "epoch: 526 - cost: 1.26432 mse:  438.384013128 - -train accuracy: 0.630556\n",
      "epoch: 527 - cost: 1.17826 mse:  435.364001441 - -train accuracy: 0.590365\n",
      "epoch: 528 - cost: 1.25874 mse:  437.571841907 - -train accuracy: 0.631355\n",
      "epoch: 529 - cost: 1.17289 mse:  434.398546455 - -train accuracy: 0.590099\n",
      "epoch: 530 - cost: 1.25162 mse:  436.716414622 - -train accuracy: 0.632153\n",
      "epoch: 531 - cost: 1.16663 mse:  433.659922922 - -train accuracy: 0.591163\n",
      "epoch: 532 - cost: 1.24531 mse:  435.983596702 - -train accuracy: 0.632686\n",
      "epoch: 533 - cost: 1.15981 mse:  432.857219216 - -train accuracy: 0.591962\n",
      "epoch: 534 - cost: 1.23883 mse:  435.251520212 - -train accuracy: 0.633218\n",
      "epoch: 535 - cost: 1.15322 mse:  431.810908211 - -train accuracy: 0.591695\n",
      "epoch: 536 - cost: 1.23135 mse:  434.615756089 - -train accuracy: 0.634283\n",
      "epoch: 537 - cost: 1.14699 mse:  431.019970992 - -train accuracy: 0.591962\n",
      "epoch: 538 - cost: 1.22517 mse:  433.814920902 - -train accuracy: 0.634815\n",
      "epoch: 539 - cost: 1.14239 mse:  430.133637856 - -train accuracy: 0.592228\n",
      "epoch: 540 - cost: 1.21976 mse:  433.157949077 - -train accuracy: 0.634017\n",
      "epoch: 541 - cost: 1.13732 mse:  429.304489485 - -train accuracy: 0.591695\n",
      "epoch: 542 - cost: 1.21369 mse:  432.541921037 - -train accuracy: 0.635347\n",
      "epoch: 543 - cost: 1.13203 mse:  428.503138064 - -train accuracy: 0.591429\n",
      "epoch: 544 - cost: 1.20772 mse:  431.918157687 - -train accuracy: 0.635347\n",
      "epoch: 545 - cost: 1.12586 mse:  427.682637039 - -train accuracy: 0.592228\n",
      "epoch: 546 - cost: 1.20238 mse:  431.217976811 - -train accuracy: 0.63588\n",
      "epoch: 547 - cost: 1.12038 mse:  426.72773132 - -train accuracy: 0.591429\n",
      "epoch: 548 - cost: 1.19609 mse:  430.623461965 - -train accuracy: 0.636412\n",
      "epoch: 549 - cost: 1.11463 mse:  425.93596737 - -train accuracy: 0.591962\n",
      "epoch: 550 - cost: 1.19004 mse:  430.055122344 - -train accuracy: 0.636944\n",
      "epoch: 551 - cost: 1.10933 mse:  425.093402139 - -train accuracy: 0.592494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 552 - cost: 1.18417 mse:  429.341368199 - -train accuracy: 0.637211\n",
      "epoch: 553 - cost: 1.10464 mse:  424.528405121 - -train accuracy: 0.593293\n",
      "epoch: 554 - cost: 1.17944 mse:  428.853160502 - -train accuracy: 0.636944\n",
      "epoch: 555 - cost: 1.10042 mse:  424.103439471 - -train accuracy: 0.592494\n",
      "epoch: 556 - cost: 1.17498 mse:  428.500540322 - -train accuracy: 0.637743\n",
      "epoch: 557 - cost: 1.0951 mse:  423.728050297 - -train accuracy: 0.592494\n",
      "epoch: 558 - cost: 1.16803 mse:  428.26873267 - -train accuracy: 0.638275\n",
      "epoch: 559 - cost: 1.08915 mse:  423.436922382 - -train accuracy: 0.593559\n",
      "epoch: 560 - cost: 1.16187 mse:  428.027750574 - -train accuracy: 0.638009\n",
      "epoch: 561 - cost: 1.08411 mse:  423.254340731 - -train accuracy: 0.594357\n",
      "epoch: 562 - cost: 1.15657 mse:  427.77387508 - -train accuracy: 0.638275\n",
      "epoch: 563 - cost: 1.0793 mse:  422.95134426 - -train accuracy: 0.593825\n",
      "epoch: 564 - cost: 1.15166 mse:  427.472539786 - -train accuracy: 0.638275\n",
      "epoch: 565 - cost: 1.07488 mse:  422.552287991 - -train accuracy: 0.594623\n",
      "epoch: 566 - cost: 1.14729 mse:  427.196632925 - -train accuracy: 0.638275\n",
      "epoch: 567 - cost: 1.0702 mse:  422.175792247 - -train accuracy: 0.59489\n",
      "epoch: 568 - cost: 1.14208 mse:  427.036119881 - -train accuracy: 0.638541\n",
      "epoch: 569 - cost: 1.06597 mse:  422.146234324 - -train accuracy: 0.595422\n",
      "epoch: 570 - cost: 1.13748 mse:  426.880388621 - -train accuracy: 0.639074\n",
      "epoch: 571 - cost: 1.06204 mse:  421.974253227 - -train accuracy: 0.595422\n",
      "epoch: 572 - cost: 1.133 mse:  426.730448828 - -train accuracy: 0.639872\n",
      "epoch: 573 - cost: 1.05746 mse:  421.748953046 - -train accuracy: 0.595422\n",
      "epoch: 574 - cost: 1.12849 mse:  426.453405774 - -train accuracy: 0.640671\n",
      "epoch: 575 - cost: 1.05292 mse:  421.483763528 - -train accuracy: 0.59622\n",
      "epoch: 576 - cost: 1.12361 mse:  426.294521306 - -train accuracy: 0.641469\n",
      "epoch: 577 - cost: 1.04862 mse:  421.293404651 - -train accuracy: 0.596753\n",
      "epoch: 578 - cost: 1.11922 mse:  425.967193249 - -train accuracy: 0.641469\n",
      "epoch: 579 - cost: 1.04488 mse:  421.010632142 - -train accuracy: 0.597019\n",
      "epoch: 580 - cost: 1.11559 mse:  425.582062659 - -train accuracy: 0.642002\n",
      "epoch: 581 - cost: 1.04143 mse:  420.596758207 - -train accuracy: 0.597551\n",
      "epoch: 582 - cost: 1.1116 mse:  425.208561052 - -train accuracy: 0.642268\n",
      "epoch: 583 - cost: 1.03722 mse:  420.155958831 - -train accuracy: 0.597285\n",
      "epoch: 584 - cost: 1.10761 mse:  424.66020924 - -train accuracy: 0.643332\n",
      "epoch: 585 - cost: 1.03337 mse:  419.586640832 - -train accuracy: 0.597285\n",
      "epoch: 586 - cost: 1.10377 mse:  424.056886579 - -train accuracy: 0.643332\n",
      "epoch: 587 - cost: 1.02967 mse:  418.80540357 - -train accuracy: 0.598084\n",
      "epoch: 588 - cost: 1.0994 mse:  423.457045995 - -train accuracy: 0.643332\n",
      "epoch: 589 - cost: 1.02556 mse:  418.263305359 - -train accuracy: 0.59835\n",
      "epoch: 590 - cost: 1.09474 mse:  422.872435507 - -train accuracy: 0.643599\n",
      "epoch: 591 - cost: 1.02115 mse:  417.746959342 - -train accuracy: 0.598616\n",
      "epoch: 592 - cost: 1.09 mse:  422.329104195 - -train accuracy: 0.643865\n",
      "epoch: 593 - cost: 1.01712 mse:  417.27721484 - -train accuracy: 0.599947\n",
      "epoch: 594 - cost: 1.08592 mse:  421.904456945 - -train accuracy: 0.644131\n",
      "epoch: 595 - cost: 1.01375 mse:  416.971325432 - -train accuracy: 0.599681\n",
      "epoch: 596 - cost: 1.08241 mse:  421.518774006 - -train accuracy: 0.644929\n",
      "epoch: 597 - cost: 1.01018 mse:  416.66931298 - -train accuracy: 0.600479\n",
      "epoch: 598 - cost: 1.07852 mse:  421.167381412 - -train accuracy: 0.644929\n",
      "epoch: 599 - cost: 1.00636 mse:  416.453437104 - -train accuracy: 0.600479\n",
      "epoch: 600 - cost: 1.07395 mse:  420.979588932 - -train accuracy: 0.645994\n",
      "epoch: 601 - cost: 1.00214 mse:  416.155096945 - -train accuracy: 0.601011\n",
      "epoch: 602 - cost: 1.06984 mse:  420.570979332 - -train accuracy: 0.645994\n",
      "epoch: 603 - cost: 0.99877 mse:  415.880733285 - -train accuracy: 0.600479\n",
      "epoch: 604 - cost: 1.06629 mse:  420.27608991 - -train accuracy: 0.64626\n",
      "epoch: 605 - cost: 0.995253 mse:  415.523593841 - -train accuracy: 0.600479\n",
      "epoch: 606 - cost: 1.06255 mse:  419.986953093 - -train accuracy: 0.646526\n",
      "epoch: 607 - cost: 0.992048 mse:  415.296132185 - -train accuracy: 0.601278\n",
      "epoch: 608 - cost: 1.0589 mse:  419.694010971 - -train accuracy: 0.647059\n",
      "epoch: 609 - cost: 0.988673 mse:  414.985100489 - -train accuracy: 0.601278\n",
      "epoch: 610 - cost: 1.05508 mse:  419.416906256 - -train accuracy: 0.647059\n",
      "epoch: 611 - cost: 0.985482 mse:  414.871471784 - -train accuracy: 0.601278\n",
      "epoch: 612 - cost: 1.05163 mse:  419.186624756 - -train accuracy: 0.647059\n",
      "epoch: 613 - cost: 0.982492 mse:  414.677002446 - -train accuracy: 0.601278\n",
      "epoch: 614 - cost: 1.04876 mse:  418.854573974 - -train accuracy: 0.647325\n",
      "epoch: 615 - cost: 0.979807 mse:  414.369574606 - -train accuracy: 0.601544\n",
      "epoch: 616 - cost: 1.0455 mse:  418.576202264 - -train accuracy: 0.647857\n",
      "epoch: 617 - cost: 0.976357 mse:  414.161335622 - -train accuracy: 0.601544\n",
      "epoch: 618 - cost: 1.04168 mse:  418.317626133 - -train accuracy: 0.647857\n",
      "epoch: 619 - cost: 0.972889 mse:  413.741780816 - -train accuracy: 0.602342\n",
      "epoch: 620 - cost: 1.0382 mse:  417.977014053 - -train accuracy: 0.64839\n",
      "epoch: 621 - cost: 0.969935 mse:  413.519120461 - -train accuracy: 0.602608\n",
      "epoch: 622 - cost: 1.03525 mse:  417.716326246 - -train accuracy: 0.64839\n",
      "epoch: 623 - cost: 0.967304 mse:  413.201439417 - -train accuracy: 0.602875\n",
      "epoch: 624 - cost: 1.03184 mse:  417.518832666 - -train accuracy: 0.648656\n",
      "epoch: 625 - cost: 0.964361 mse:  413.135119621 - -train accuracy: 0.603141\n",
      "epoch: 626 - cost: 1.0291 mse:  417.242320014 - -train accuracy: 0.648922\n",
      "epoch: 627 - cost: 0.961827 mse:  412.726810947 - -train accuracy: 0.603141\n",
      "epoch: 628 - cost: 1.02597 mse:  416.989290624 - -train accuracy: 0.649188\n",
      "epoch: 629 - cost: 0.958806 mse:  412.502863632 - -train accuracy: 0.603673\n",
      "epoch: 630 - cost: 1.02232 mse:  416.716861411 - -train accuracy: 0.649721\n",
      "epoch: 631 - cost: 0.955661 mse:  412.318759681 - -train accuracy: 0.603939\n",
      "epoch: 632 - cost: 1.01894 mse:  416.401706129 - -train accuracy: 0.649987\n",
      "epoch: 633 - cost: 0.95267 mse:  411.985192256 - -train accuracy: 0.604472\n",
      "epoch: 634 - cost: 1.01544 mse:  416.116713114 - -train accuracy: 0.649987\n",
      "epoch: 635 - cost: 0.949774 mse:  411.810601308 - -train accuracy: 0.60527\n",
      "epoch: 636 - cost: 1.01238 mse:  415.804430085 - -train accuracy: 0.649987\n",
      "epoch: 637 - cost: 0.947097 mse:  411.502214222 - -train accuracy: 0.606069\n",
      "epoch: 638 - cost: 1.00914 mse:  415.539440582 - -train accuracy: 0.650519\n",
      "epoch: 639 - cost: 0.944287 mse:  411.27664945 - -train accuracy: 0.606601\n",
      "epoch: 640 - cost: 1.00621 mse:  415.230776831 - -train accuracy: 0.650519\n",
      "epoch: 641 - cost: 0.941593 mse:  410.959625623 - -train accuracy: 0.606867\n",
      "epoch: 642 - cost: 1.00307 mse:  414.957047869 - -train accuracy: 0.651051\n",
      "epoch: 643 - cost: 0.938726 mse:  410.788241426 - -train accuracy: 0.606867\n",
      "epoch: 644 - cost: 0.999808 mse:  414.761491483 - -train accuracy: 0.651051\n",
      "epoch: 645 - cost: 0.936054 mse:  410.666452752 - -train accuracy: 0.607666\n",
      "epoch: 646 - cost: 0.996867 mse:  414.497181547 - -train accuracy: 0.651584\n",
      "epoch: 647 - cost: 0.933576 mse:  410.440217696 - -train accuracy: 0.6074\n",
      "epoch: 648 - cost: 0.99399 mse:  414.362146349 - -train accuracy: 0.65185\n",
      "epoch: 649 - cost: 0.930838 mse:  410.279546049 - -train accuracy: 0.6074\n",
      "epoch: 650 - cost: 0.991204 mse:  414.159037469 - -train accuracy: 0.652116\n",
      "epoch: 651 - cost: 0.928463 mse:  410.050992953 - -train accuracy: 0.6074\n",
      "epoch: 652 - cost: 0.988696 mse:  413.888855186 - -train accuracy: 0.652116\n",
      "epoch: 653 - cost: 0.926363 mse:  409.79090434 - -train accuracy: 0.607133\n",
      "epoch: 654 - cost: 0.986404 mse:  413.610979657 - -train accuracy: 0.652116\n",
      "epoch: 655 - cost: 0.923959 mse:  409.461946699 - -train accuracy: 0.6074\n",
      "epoch: 656 - cost: 0.983341 mse:  413.327988074 - -train accuracy: 0.652382\n",
      "epoch: 657 - cost: 0.921397 mse:  409.260737786 - -train accuracy: 0.608198\n",
      "epoch: 658 - cost: 0.980433 mse:  413.069509335 - -train accuracy: 0.652382\n",
      "epoch: 659 - cost: 0.918667 mse:  408.968141442 - -train accuracy: 0.60873\n",
      "epoch: 660 - cost: 0.977495 mse:  412.780698586 - -train accuracy: 0.652648\n",
      "epoch: 661 - cost: 0.916086 mse:  408.654623216 - -train accuracy: 0.60873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 662 - cost: 0.974798 mse:  412.508558491 - -train accuracy: 0.653181\n",
      "epoch: 663 - cost: 0.913836 mse:  408.482752549 - -train accuracy: 0.609263\n",
      "epoch: 664 - cost: 0.972036 mse:  412.268977827 - -train accuracy: 0.653447\n",
      "epoch: 665 - cost: 0.911332 mse:  408.172884151 - -train accuracy: 0.609529\n",
      "epoch: 666 - cost: 0.968892 mse:  412.022324859 - -train accuracy: 0.653447\n",
      "epoch: 667 - cost: 0.908802 mse:  407.942769482 - -train accuracy: 0.609529\n",
      "epoch: 668 - cost: 0.966192 mse:  411.800191548 - -train accuracy: 0.653979\n",
      "epoch: 669 - cost: 0.906541 mse:  407.70884855 - -train accuracy: 0.609529\n",
      "epoch: 670 - cost: 0.963684 mse:  411.53664268 - -train accuracy: 0.653979\n",
      "epoch: 671 - cost: 0.904184 mse:  407.388631163 - -train accuracy: 0.609529\n",
      "epoch: 672 - cost: 0.960982 mse:  411.271083221 - -train accuracy: 0.653979\n",
      "epoch: 673 - cost: 0.901923 mse:  407.160445024 - -train accuracy: 0.611126\n",
      "epoch: 674 - cost: 0.958273 mse:  411.017830022 - -train accuracy: 0.653979\n",
      "epoch: 675 - cost: 0.899507 mse:  406.796428244 - -train accuracy: 0.611924\n",
      "epoch: 676 - cost: 0.955672 mse:  410.680151415 - -train accuracy: 0.654245\n",
      "epoch: 677 - cost: 0.897085 mse:  406.460611998 - -train accuracy: 0.612191\n",
      "epoch: 678 - cost: 0.953118 mse:  410.324763132 - -train accuracy: 0.655044\n",
      "epoch: 679 - cost: 0.89482 mse:  406.124907976 - -train accuracy: 0.612723\n",
      "epoch: 680 - cost: 0.950594 mse:  410.03786705 - -train accuracy: 0.655044\n",
      "epoch: 681 - cost: 0.892528 mse:  405.823792053 - -train accuracy: 0.612989\n",
      "epoch: 682 - cost: 0.947883 mse:  409.817963876 - -train accuracy: 0.65531\n",
      "epoch: 683 - cost: 0.890193 mse:  405.61221146 - -train accuracy: 0.613255\n",
      "epoch: 684 - cost: 0.945113 mse:  409.61967535 - -train accuracy: 0.65531\n",
      "epoch: 685 - cost: 0.887877 mse:  405.339334002 - -train accuracy: 0.614054\n",
      "epoch: 686 - cost: 0.942369 mse:  409.37903785 - -train accuracy: 0.656109\n",
      "epoch: 687 - cost: 0.885576 mse:  405.100952243 - -train accuracy: 0.614586\n",
      "epoch: 688 - cost: 0.939739 mse:  409.188398279 - -train accuracy: 0.656375\n",
      "epoch: 689 - cost: 0.883295 mse:  404.86362732 - -train accuracy: 0.614852\n",
      "epoch: 690 - cost: 0.937055 mse:  408.95295707 - -train accuracy: 0.656375\n",
      "epoch: 691 - cost: 0.881074 mse:  404.68712837 - -train accuracy: 0.615385\n",
      "epoch: 692 - cost: 0.934422 mse:  408.769662212 - -train accuracy: 0.656641\n",
      "epoch: 693 - cost: 0.878907 mse:  404.503103255 - -train accuracy: 0.615651\n",
      "epoch: 694 - cost: 0.931711 mse:  408.578601239 - -train accuracy: 0.657706\n",
      "epoch: 695 - cost: 0.87632 mse:  404.218195579 - -train accuracy: 0.615917\n",
      "epoch: 696 - cost: 0.929196 mse:  408.275064233 - -train accuracy: 0.657706\n",
      "epoch: 697 - cost: 0.874102 mse:  403.964622468 - -train accuracy: 0.616183\n",
      "epoch: 698 - cost: 0.926407 mse:  408.08117145 - -train accuracy: 0.658504\n",
      "epoch: 699 - cost: 0.871693 mse:  403.747495359 - -train accuracy: 0.616715\n",
      "epoch: 700 - cost: 0.923613 mse:  407.900892556 - -train accuracy: 0.659569\n",
      "epoch: 701 - cost: 0.868991 mse:  403.51282991 - -train accuracy: 0.616715\n",
      "epoch: 702 - cost: 0.92093 mse:  407.571279452 - -train accuracy: 0.660101\n",
      "epoch: 703 - cost: 0.866737 mse:  403.240377719 - -train accuracy: 0.616982\n",
      "epoch: 704 - cost: 0.918099 mse:  407.397985982 - -train accuracy: 0.6609\n",
      "epoch: 705 - cost: 0.864179 mse:  403.129021905 - -train accuracy: 0.617248\n",
      "epoch: 706 - cost: 0.915053 mse:  407.166318186 - -train accuracy: 0.661166\n",
      "epoch: 707 - cost: 0.86159 mse:  402.949309884 - -train accuracy: 0.617514\n",
      "epoch: 708 - cost: 0.912079 mse:  406.908222864 - -train accuracy: 0.661698\n",
      "epoch: 709 - cost: 0.859251 mse:  402.66453052 - -train accuracy: 0.617514\n",
      "epoch: 710 - cost: 0.909391 mse:  406.60819045 - -train accuracy: 0.661964\n",
      "epoch: 711 - cost: 0.857037 mse:  402.40124414 - -train accuracy: 0.617514\n",
      "epoch: 712 - cost: 0.906913 mse:  406.326720927 - -train accuracy: 0.66223\n",
      "epoch: 713 - cost: 0.855092 mse:  402.227063841 - -train accuracy: 0.61778\n",
      "epoch: 714 - cost: 0.90458 mse:  406.114156369 - -train accuracy: 0.66223\n",
      "epoch: 715 - cost: 0.853297 mse:  402.000566293 - -train accuracy: 0.618312\n",
      "epoch: 716 - cost: 0.902481 mse:  405.837541927 - -train accuracy: 0.663029\n",
      "epoch: 717 - cost: 0.851449 mse:  401.658595842 - -train accuracy: 0.618312\n",
      "epoch: 718 - cost: 0.900393 mse:  405.501995852 - -train accuracy: 0.663029\n",
      "epoch: 719 - cost: 0.849392 mse:  401.387714318 - -train accuracy: 0.619111\n",
      "epoch: 720 - cost: 0.897962 mse:  405.18806788 - -train accuracy: 0.663029\n",
      "epoch: 721 - cost: 0.847074 mse:  400.935022754 - -train accuracy: 0.619643\n",
      "epoch: 722 - cost: 0.895391 mse:  404.81726252 - -train accuracy: 0.663029\n",
      "epoch: 723 - cost: 0.844833 mse:  400.60089012 - -train accuracy: 0.61991\n",
      "epoch: 724 - cost: 0.892966 mse:  404.497764564 - -train accuracy: 0.663561\n",
      "epoch: 725 - cost: 0.842951 mse:  400.38334827 - -train accuracy: 0.61991\n",
      "epoch: 726 - cost: 0.890768 mse:  404.215834827 - -train accuracy: 0.66436\n",
      "epoch: 727 - cost: 0.840996 mse:  400.004898603 - -train accuracy: 0.61991\n",
      "epoch: 728 - cost: 0.888662 mse:  403.857582989 - -train accuracy: 0.66436\n",
      "epoch: 729 - cost: 0.839157 mse:  399.723021547 - -train accuracy: 0.619377\n",
      "epoch: 730 - cost: 0.886526 mse:  403.543858534 - -train accuracy: 0.664626\n",
      "epoch: 731 - cost: 0.837367 mse:  399.456182617 - -train accuracy: 0.619377\n",
      "epoch: 732 - cost: 0.88427 mse:  403.270789455 - -train accuracy: 0.664892\n",
      "epoch: 733 - cost: 0.835482 mse:  399.169268021 - -train accuracy: 0.61991\n",
      "epoch: 734 - cost: 0.882037 mse:  403.011245399 - -train accuracy: 0.665158\n",
      "epoch: 735 - cost: 0.83343 mse:  398.998288721 - -train accuracy: 0.621507\n",
      "epoch: 736 - cost: 0.879379 mse:  402.778917288 - -train accuracy: 0.665425\n",
      "epoch: 737 - cost: 0.831172 mse:  398.707582686 - -train accuracy: 0.622305\n",
      "epoch: 738 - cost: 0.876836 mse:  402.452353752 - -train accuracy: 0.665425\n",
      "epoch: 739 - cost: 0.82907 mse:  398.394950815 - -train accuracy: 0.622571\n",
      "epoch: 740 - cost: 0.874592 mse:  402.092332932 - -train accuracy: 0.665158\n",
      "epoch: 741 - cost: 0.827124 mse:  398.112767502 - -train accuracy: 0.622837\n",
      "epoch: 742 - cost: 0.872206 mse:  401.826416365 - -train accuracy: 0.665425\n",
      "epoch: 743 - cost: 0.824903 mse:  397.799317174 - -train accuracy: 0.623104\n",
      "epoch: 744 - cost: 0.869674 mse:  401.512898282 - -train accuracy: 0.665691\n",
      "epoch: 745 - cost: 0.822861 mse:  397.576859438 - -train accuracy: 0.62337\n",
      "epoch: 746 - cost: 0.867289 mse:  401.229884034 - -train accuracy: 0.665957\n",
      "epoch: 747 - cost: 0.820733 mse:  397.264403178 - -train accuracy: 0.624967\n",
      "epoch: 748 - cost: 0.864783 mse:  400.957185869 - -train accuracy: 0.666223\n",
      "epoch: 749 - cost: 0.818711 mse:  397.079038496 - -train accuracy: 0.625765\n",
      "epoch: 750 - cost: 0.862489 mse:  400.696829395 - -train accuracy: 0.666489\n",
      "epoch: 751 - cost: 0.816732 mse:  396.744138549 - -train accuracy: 0.626298\n",
      "epoch: 752 - cost: 0.86035 mse:  400.447022296 - -train accuracy: 0.666755\n",
      "epoch: 753 - cost: 0.814993 mse:  396.536216046 - -train accuracy: 0.62683\n",
      "epoch: 754 - cost: 0.858323 mse:  400.167699814 - -train accuracy: 0.666755\n",
      "epoch: 755 - cost: 0.813293 mse:  396.220588949 - -train accuracy: 0.627362\n",
      "epoch: 756 - cost: 0.856512 mse:  399.828912351 - -train accuracy: 0.666755\n",
      "epoch: 757 - cost: 0.811692 mse:  395.807635623 - -train accuracy: 0.627895\n",
      "epoch: 758 - cost: 0.854537 mse:  399.471275107 - -train accuracy: 0.666755\n",
      "epoch: 759 - cost: 0.809865 mse:  395.468926807 - -train accuracy: 0.628693\n",
      "epoch: 760 - cost: 0.852327 mse:  399.082154682 - -train accuracy: 0.667554\n",
      "epoch: 761 - cost: 0.80809 mse:  395.082644154 - -train accuracy: 0.628693\n",
      "epoch: 762 - cost: 0.850146 mse:  398.765258848 - -train accuracy: 0.668086\n",
      "epoch: 763 - cost: 0.805892 mse:  394.680327581 - -train accuracy: 0.628693\n",
      "epoch: 764 - cost: 0.847888 mse:  398.365506644 - -train accuracy: 0.668619\n",
      "epoch: 765 - cost: 0.804178 mse:  394.321241003 - -train accuracy: 0.628959\n",
      "epoch: 766 - cost: 0.845825 mse:  398.002490459 - -train accuracy: 0.668885\n",
      "epoch: 767 - cost: 0.802391 mse:  393.941438781 - -train accuracy: 0.628959\n",
      "epoch: 768 - cost: 0.843873 mse:  397.558593155 - -train accuracy: 0.669151\n",
      "epoch: 769 - cost: 0.800532 mse:  393.469105988 - -train accuracy: 0.629492\n",
      "epoch: 770 - cost: 0.841786 mse:  397.168009088 - -train accuracy: 0.669417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 771 - cost: 0.798853 mse:  393.132196151 - -train accuracy: 0.629492\n",
      "epoch: 772 - cost: 0.83981 mse:  396.827592702 - -train accuracy: 0.669949\n",
      "epoch: 773 - cost: 0.797193 mse:  392.770814324 - -train accuracy: 0.629758\n",
      "epoch: 774 - cost: 0.837938 mse:  396.464541937 - -train accuracy: 0.670216\n",
      "epoch: 775 - cost: 0.795592 mse:  392.439127753 - -train accuracy: 0.629492\n",
      "epoch: 776 - cost: 0.836095 mse:  396.090693662 - -train accuracy: 0.670482\n",
      "epoch: 777 - cost: 0.793969 mse:  392.0129404 - -train accuracy: 0.629492\n",
      "epoch: 778 - cost: 0.834318 mse:  395.732166144 - -train accuracy: 0.670482\n",
      "epoch: 779 - cost: 0.792465 mse:  391.743014338 - -train accuracy: 0.630024\n",
      "epoch: 780 - cost: 0.832231 mse:  395.431569234 - -train accuracy: 0.670748\n",
      "epoch: 781 - cost: 0.790495 mse:  391.342941061 - -train accuracy: 0.630556\n",
      "epoch: 782 - cost: 0.829965 mse:  395.075909387 - -train accuracy: 0.67128\n",
      "epoch: 783 - cost: 0.788563 mse:  391.005509876 - -train accuracy: 0.630822\n",
      "epoch: 784 - cost: 0.827924 mse:  394.701057307 - -train accuracy: 0.67128\n",
      "epoch: 785 - cost: 0.787065 mse:  390.731288536 - -train accuracy: 0.631089\n",
      "epoch: 786 - cost: 0.826121 mse:  394.359286976 - -train accuracy: 0.671813\n",
      "epoch: 787 - cost: 0.785589 mse:  390.42374031 - -train accuracy: 0.631089\n",
      "epoch: 788 - cost: 0.824363 mse:  394.014256304 - -train accuracy: 0.672079\n",
      "epoch: 789 - cost: 0.784007 mse:  390.066977053 - -train accuracy: 0.631355\n",
      "epoch: 790 - cost: 0.822633 mse:  393.641381311 - -train accuracy: 0.672079\n",
      "epoch: 791 - cost: 0.782419 mse:  389.707823904 - -train accuracy: 0.631089\n",
      "epoch: 792 - cost: 0.820698 mse:  393.297616226 - -train accuracy: 0.672611\n",
      "epoch: 793 - cost: 0.780651 mse:  389.404039995 - -train accuracy: 0.631355\n",
      "epoch: 794 - cost: 0.818884 mse:  392.94655087 - -train accuracy: 0.673143\n",
      "epoch: 795 - cost: 0.779191 mse:  389.033625783 - -train accuracy: 0.631355\n",
      "epoch: 796 - cost: 0.817038 mse:  392.627372851 - -train accuracy: 0.67341\n",
      "epoch: 797 - cost: 0.777555 mse:  388.766671035 - -train accuracy: 0.631355\n",
      "epoch: 798 - cost: 0.815143 mse:  392.325334839 - -train accuracy: 0.673942\n",
      "epoch: 799 - cost: 0.776043 mse:  388.50557598 - -train accuracy: 0.631089\n",
      "epoch: 800 - cost: 0.813234 mse:  391.995440163 - -train accuracy: 0.674474\n",
      "epoch: 801 - cost: 0.774382 mse:  388.186953446 - -train accuracy: 0.631089\n",
      "epoch: 802 - cost: 0.811353 mse:  391.670325501 - -train accuracy: 0.675007\n",
      "epoch: 803 - cost: 0.772772 mse:  387.812721821 - -train accuracy: 0.631089\n",
      "epoch: 804 - cost: 0.809542 mse:  391.323309221 - -train accuracy: 0.675273\n",
      "epoch: 805 - cost: 0.771226 mse:  387.39365088 - -train accuracy: 0.631621\n",
      "epoch: 806 - cost: 0.807942 mse:  390.793111264 - -train accuracy: 0.675539\n",
      "epoch: 807 - cost: 0.769985 mse:  386.917714365 - -train accuracy: 0.631621\n",
      "epoch: 808 - cost: 0.806526 mse:  390.27672183 - -train accuracy: 0.675539\n",
      "epoch: 809 - cost: 0.768558 mse:  386.432788043 - -train accuracy: 0.631621\n",
      "epoch: 810 - cost: 0.804763 mse:  389.831898165 - -train accuracy: 0.675805\n",
      "epoch: 811 - cost: 0.767092 mse:  385.972772597 - -train accuracy: 0.631355\n",
      "epoch: 812 - cost: 0.803019 mse:  389.473343322 - -train accuracy: 0.676337\n",
      "epoch: 813 - cost: 0.765431 mse:  385.624956953 - -train accuracy: 0.631887\n",
      "epoch: 814 - cost: 0.801186 mse:  389.060101257 - -train accuracy: 0.676604\n",
      "epoch: 815 - cost: 0.763986 mse:  385.208554545 - -train accuracy: 0.632153\n",
      "epoch: 816 - cost: 0.799458 mse:  388.722627113 - -train accuracy: 0.67687\n",
      "epoch: 817 - cost: 0.762258 mse:  384.75982295 - -train accuracy: 0.633218\n",
      "epoch: 818 - cost: 0.797655 mse:  388.30339997 - -train accuracy: 0.676604\n",
      "epoch: 819 - cost: 0.760896 mse:  384.418494057 - -train accuracy: 0.633218\n",
      "epoch: 820 - cost: 0.795989 mse:  387.882535145 - -train accuracy: 0.677136\n",
      "epoch: 821 - cost: 0.759331 mse:  383.941716062 - -train accuracy: 0.63375\n",
      "epoch: 822 - cost: 0.79428 mse:  387.442549054 - -train accuracy: 0.677402\n",
      "epoch: 823 - cost: 0.757962 mse:  383.54239785 - -train accuracy: 0.634017\n",
      "epoch: 824 - cost: 0.792667 mse:  387.015178646 - -train accuracy: 0.677136\n",
      "epoch: 825 - cost: 0.756452 mse:  382.993776022 - -train accuracy: 0.634017\n",
      "epoch: 826 - cost: 0.791163 mse:  386.50700397 - -train accuracy: 0.677668\n",
      "epoch: 827 - cost: 0.755172 mse:  382.542328117 - -train accuracy: 0.634017\n",
      "epoch: 828 - cost: 0.789646 mse:  386.030989308 - -train accuracy: 0.677402\n",
      "epoch: 829 - cost: 0.753866 mse:  382.119767774 - -train accuracy: 0.634017\n",
      "epoch: 830 - cost: 0.78806 mse:  385.622867486 - -train accuracy: 0.677402\n",
      "epoch: 831 - cost: 0.752386 mse:  381.683312212 - -train accuracy: 0.634283\n",
      "epoch: 832 - cost: 0.786431 mse:  385.183524132 - -train accuracy: 0.678201\n",
      "epoch: 833 - cost: 0.751 mse:  381.196001823 - -train accuracy: 0.634815\n",
      "epoch: 834 - cost: 0.784737 mse:  384.695805747 - -train accuracy: 0.678201\n",
      "epoch: 835 - cost: 0.749543 mse:  380.74150787 - -train accuracy: 0.634549\n",
      "epoch: 836 - cost: 0.783168 mse:  384.215477202 - -train accuracy: 0.678733\n",
      "epoch: 837 - cost: 0.748278 mse:  380.34019763 - -train accuracy: 0.634815\n",
      "epoch: 838 - cost: 0.78172 mse:  383.823138975 - -train accuracy: 0.678733\n",
      "epoch: 839 - cost: 0.746934 mse:  379.938899049 - -train accuracy: 0.634815\n",
      "epoch: 840 - cost: 0.780111 mse:  383.381068405 - -train accuracy: 0.678999\n",
      "epoch: 841 - cost: 0.745497 mse:  379.484426146 - -train accuracy: 0.635347\n",
      "epoch: 842 - cost: 0.778489 mse:  382.909915034 - -train accuracy: 0.678999\n",
      "epoch: 843 - cost: 0.744082 mse:  379.045432004 - -train accuracy: 0.635347\n",
      "epoch: 844 - cost: 0.776756 mse:  382.508310435 - -train accuracy: 0.679532\n",
      "epoch: 845 - cost: 0.742543 mse:  378.680070543 - -train accuracy: 0.635347\n",
      "epoch: 846 - cost: 0.774893 mse:  382.108568078 - -train accuracy: 0.679532\n",
      "epoch: 847 - cost: 0.741042 mse:  378.324504608 - -train accuracy: 0.635614\n",
      "epoch: 848 - cost: 0.773187 mse:  381.714026406 - -train accuracy: 0.679798\n",
      "epoch: 849 - cost: 0.739655 mse:  377.927117837 - -train accuracy: 0.635614\n",
      "epoch: 850 - cost: 0.77171 mse:  381.297205397 - -train accuracy: 0.680064\n",
      "epoch: 851 - cost: 0.738372 mse:  377.500695696 - -train accuracy: 0.636412\n",
      "epoch: 852 - cost: 0.770298 mse:  380.888285724 - -train accuracy: 0.68033\n",
      "epoch: 853 - cost: 0.737332 mse:  377.097703549 - -train accuracy: 0.636412\n",
      "epoch: 854 - cost: 0.769094 mse:  380.445681409 - -train accuracy: 0.680064\n",
      "epoch: 855 - cost: 0.736136 mse:  376.633769848 - -train accuracy: 0.636944\n",
      "epoch: 856 - cost: 0.767663 mse:  379.998816587 - -train accuracy: 0.68033\n",
      "epoch: 857 - cost: 0.734854 mse:  376.218219 - -train accuracy: 0.637211\n",
      "epoch: 858 - cost: 0.766224 mse:  379.553165682 - -train accuracy: 0.680596\n",
      "epoch: 859 - cost: 0.733767 mse:  375.773014554 - -train accuracy: 0.637743\n",
      "epoch: 860 - cost: 0.76496 mse:  379.11362118 - -train accuracy: 0.680596\n",
      "epoch: 861 - cost: 0.732721 mse:  375.360779863 - -train accuracy: 0.638009\n",
      "epoch: 862 - cost: 0.763633 mse:  378.704046738 - -train accuracy: 0.681129\n",
      "epoch: 863 - cost: 0.731443 mse:  374.966981632 - -train accuracy: 0.638275\n",
      "epoch: 864 - cost: 0.762044 mse:  378.316248578 - -train accuracy: 0.681129\n",
      "epoch: 865 - cost: 0.72996 mse:  374.577374314 - -train accuracy: 0.638541\n",
      "epoch: 866 - cost: 0.760291 mse:  377.909452506 - -train accuracy: 0.681927\n",
      "epoch: 867 - cost: 0.728538 mse:  374.163106652 - -train accuracy: 0.638541\n",
      "epoch: 868 - cost: 0.758577 mse:  377.506967954 - -train accuracy: 0.682459\n",
      "epoch: 869 - cost: 0.727053 mse:  373.755612157 - -train accuracy: 0.638808\n",
      "epoch: 870 - cost: 0.756834 mse:  377.047210849 - -train accuracy: 0.682992\n",
      "epoch: 871 - cost: 0.725534 mse:  373.279400081 - -train accuracy: 0.639074\n",
      "epoch: 872 - cost: 0.755107 mse:  376.575672923 - -train accuracy: 0.682992\n",
      "epoch: 873 - cost: 0.724089 mse:  372.842019298 - -train accuracy: 0.639074\n",
      "epoch: 874 - cost: 0.753437 mse:  376.134393545 - -train accuracy: 0.68379\n",
      "epoch: 875 - cost: 0.722754 mse:  372.415693297 - -train accuracy: 0.639606\n",
      "epoch: 876 - cost: 0.751843 mse:  375.685731917 - -train accuracy: 0.684056\n",
      "epoch: 877 - cost: 0.721319 mse:  371.968423612 - -train accuracy: 0.639872\n",
      "epoch: 878 - cost: 0.7502 mse:  375.292603554 - -train accuracy: 0.684323\n",
      "epoch: 879 - cost: 0.719855 mse:  371.622997436 - -train accuracy: 0.639872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 880 - cost: 0.748552 mse:  374.894662769 - -train accuracy: 0.684589\n",
      "epoch: 881 - cost: 0.718618 mse:  371.276657957 - -train accuracy: 0.640405\n",
      "epoch: 882 - cost: 0.747176 mse:  374.53575121 - -train accuracy: 0.684855\n",
      "epoch: 883 - cost: 0.717355 mse:  370.934177995 - -train accuracy: 0.641203\n",
      "epoch: 884 - cost: 0.745676 mse:  374.214808744 - -train accuracy: 0.684855\n",
      "epoch: 885 - cost: 0.715921 mse:  370.632411206 - -train accuracy: 0.642002\n",
      "epoch: 886 - cost: 0.744144 mse:  373.810446802 - -train accuracy: 0.685387\n",
      "epoch: 887 - cost: 0.714749 mse:  370.243483915 - -train accuracy: 0.641735\n",
      "epoch: 888 - cost: 0.74284 mse:  373.467637916 - -train accuracy: 0.685387\n",
      "epoch: 889 - cost: 0.713567 mse:  369.917677976 - -train accuracy: 0.641735\n",
      "epoch: 890 - cost: 0.741499 mse:  373.097517392 - -train accuracy: 0.68592\n",
      "epoch: 891 - cost: 0.712398 mse:  369.613905004 - -train accuracy: 0.642002\n",
      "epoch: 892 - cost: 0.74031 mse:  372.713554553 - -train accuracy: 0.68592\n",
      "epoch: 893 - cost: 0.711395 mse:  369.223582946 - -train accuracy: 0.642002\n",
      "epoch: 894 - cost: 0.739246 mse:  372.307284209 - -train accuracy: 0.685653\n",
      "epoch: 895 - cost: 0.710428 mse:  368.893872696 - -train accuracy: 0.642002\n",
      "epoch: 896 - cost: 0.737957 mse:  372.016486292 - -train accuracy: 0.685653\n",
      "epoch: 897 - cost: 0.709102 mse:  368.527995791 - -train accuracy: 0.642534\n",
      "epoch: 898 - cost: 0.73655 mse:  371.624427971 - -train accuracy: 0.686186\n",
      "epoch: 899 - cost: 0.707893 mse:  368.176986534 - -train accuracy: 0.642534\n",
      "epoch: 900 - cost: 0.7351 mse:  371.295280527 - -train accuracy: 0.686452\n",
      "epoch: 901 - cost: 0.70669 mse:  367.851809878 - -train accuracy: 0.642534\n",
      "epoch: 902 - cost: 0.733736 mse:  370.952212302 - -train accuracy: 0.686452\n",
      "epoch: 903 - cost: 0.705566 mse:  367.558376322 - -train accuracy: 0.6428\n",
      "epoch: 904 - cost: 0.732438 mse:  370.651409832 - -train accuracy: 0.686452\n",
      "epoch: 905 - cost: 0.704379 mse:  367.289102184 - -train accuracy: 0.643066\n",
      "epoch: 906 - cost: 0.731056 mse:  370.40466953 - -train accuracy: 0.686452\n",
      "epoch: 907 - cost: 0.7032 mse:  367.043909522 - -train accuracy: 0.643332\n",
      "epoch: 908 - cost: 0.729693 mse:  370.198061725 - -train accuracy: 0.686718\n",
      "epoch: 909 - cost: 0.701942 mse:  366.8449305 - -train accuracy: 0.644663\n",
      "epoch: 910 - cost: 0.728264 mse:  369.975804615 - -train accuracy: 0.686718\n",
      "epoch: 911 - cost: 0.700879 mse:  366.63826934 - -train accuracy: 0.644929\n",
      "epoch: 912 - cost: 0.726959 mse:  369.744612249 - -train accuracy: 0.68725\n",
      "epoch: 913 - cost: 0.699633 mse:  366.335793235 - -train accuracy: 0.644929\n",
      "epoch: 914 - cost: 0.725674 mse:  369.43416978 - -train accuracy: 0.68725\n",
      "epoch: 915 - cost: 0.698492 mse:  366.054950242 - -train accuracy: 0.645462\n",
      "epoch: 916 - cost: 0.724411 mse:  369.111535639 - -train accuracy: 0.68725\n",
      "epoch: 917 - cost: 0.697474 mse:  365.760661054 - -train accuracy: 0.645462\n",
      "epoch: 918 - cost: 0.723299 mse:  368.832237423 - -train accuracy: 0.687517\n",
      "epoch: 919 - cost: 0.696325 mse:  365.471187315 - -train accuracy: 0.645728\n",
      "epoch: 920 - cost: 0.721944 mse:  368.478066307 - -train accuracy: 0.687783\n",
      "epoch: 921 - cost: 0.695047 mse:  365.112313565 - -train accuracy: 0.645994\n",
      "epoch: 922 - cost: 0.720511 mse:  368.181808662 - -train accuracy: 0.687783\n",
      "epoch: 923 - cost: 0.693849 mse:  364.835087782 - -train accuracy: 0.645994\n",
      "epoch: 924 - cost: 0.719137 mse:  367.903040932 - -train accuracy: 0.688581\n",
      "epoch: 925 - cost: 0.692669 mse:  364.614391006 - -train accuracy: 0.64626\n",
      "epoch: 926 - cost: 0.717769 mse:  367.637395642 - -train accuracy: 0.688315\n",
      "epoch: 927 - cost: 0.691406 mse:  364.319269733 - -train accuracy: 0.647059\n",
      "epoch: 928 - cost: 0.716343 mse:  367.359944637 - -train accuracy: 0.688315\n",
      "epoch: 929 - cost: 0.690114 mse:  364.034611839 - -train accuracy: 0.647591\n",
      "epoch: 930 - cost: 0.714818 mse:  367.053294859 - -train accuracy: 0.688049\n",
      "epoch: 931 - cost: 0.688912 mse:  363.7350654 - -train accuracy: 0.647591\n",
      "epoch: 932 - cost: 0.713396 mse:  366.880090537 - -train accuracy: 0.688847\n",
      "epoch: 933 - cost: 0.687664 mse:  363.582056855 - -train accuracy: 0.647857\n",
      "epoch: 934 - cost: 0.712037 mse:  366.556368168 - -train accuracy: 0.688847\n",
      "epoch: 935 - cost: 0.686475 mse:  363.260594736 - -train accuracy: 0.647857\n",
      "epoch: 936 - cost: 0.710662 mse:  366.211766281 - -train accuracy: 0.689114\n",
      "epoch: 937 - cost: 0.685269 mse:  362.956804232 - -train accuracy: 0.647325\n",
      "epoch: 938 - cost: 0.709401 mse:  365.855353518 - -train accuracy: 0.68938\n",
      "epoch: 939 - cost: 0.684184 mse:  362.615676776 - -train accuracy: 0.647325\n",
      "epoch: 940 - cost: 0.708173 mse:  365.502065969 - -train accuracy: 0.68938\n",
      "epoch: 941 - cost: 0.683087 mse:  362.282751025 - -train accuracy: 0.646793\n",
      "epoch: 942 - cost: 0.706877 mse:  365.161132397 - -train accuracy: 0.689646\n",
      "epoch: 943 - cost: 0.681929 mse:  361.952806605 - -train accuracy: 0.647325\n",
      "epoch: 944 - cost: 0.705536 mse:  364.800597153 - -train accuracy: 0.689646\n",
      "epoch: 945 - cost: 0.680812 mse:  361.638894477 - -train accuracy: 0.647591\n",
      "epoch: 946 - cost: 0.704334 mse:  364.470304371 - -train accuracy: 0.689912\n",
      "epoch: 947 - cost: 0.679746 mse:  361.295486096 - -train accuracy: 0.64839\n",
      "epoch: 948 - cost: 0.703003 mse:  364.16482619 - -train accuracy: 0.690178\n",
      "epoch: 949 - cost: 0.678542 mse:  360.990392336 - -train accuracy: 0.648922\n",
      "epoch: 950 - cost: 0.70161 mse:  363.779911623 - -train accuracy: 0.690178\n",
      "epoch: 951 - cost: 0.677435 mse:  360.678605045 - -train accuracy: 0.649721\n",
      "epoch: 952 - cost: 0.700405 mse:  363.484240692 - -train accuracy: 0.690445\n",
      "epoch: 953 - cost: 0.676366 mse:  360.362488836 - -train accuracy: 0.650253\n",
      "epoch: 954 - cost: 0.699291 mse:  363.098168345 - -train accuracy: 0.690445\n",
      "epoch: 955 - cost: 0.675388 mse:  360.021537667 - -train accuracy: 0.650253\n",
      "epoch: 956 - cost: 0.69806 mse:  362.759010039 - -train accuracy: 0.689912\n",
      "epoch: 957 - cost: 0.674266 mse:  359.669338667 - -train accuracy: 0.650253\n",
      "epoch: 958 - cost: 0.696829 mse:  362.440456136 - -train accuracy: 0.690445\n",
      "epoch: 959 - cost: 0.673289 mse:  359.370800644 - -train accuracy: 0.650519\n",
      "epoch: 960 - cost: 0.695737 mse:  362.12201484 - -train accuracy: 0.690711\n",
      "epoch: 961 - cost: 0.672327 mse:  359.067310353 - -train accuracy: 0.651318\n",
      "epoch: 962 - cost: 0.694604 mse:  361.841970391 - -train accuracy: 0.690977\n",
      "epoch: 963 - cost: 0.671319 mse:  358.799499621 - -train accuracy: 0.650785\n",
      "epoch: 964 - cost: 0.693499 mse:  361.562184996 - -train accuracy: 0.691243\n",
      "epoch: 965 - cost: 0.670331 mse:  358.500008531 - -train accuracy: 0.651051\n",
      "epoch: 966 - cost: 0.692381 mse:  361.286107486 - -train accuracy: 0.692042\n",
      "epoch: 967 - cost: 0.669438 mse:  358.221520533 - -train accuracy: 0.651584\n",
      "epoch: 968 - cost: 0.691353 mse:  360.968001098 - -train accuracy: 0.692042\n",
      "epoch: 969 - cost: 0.668532 mse:  357.875974873 - -train accuracy: 0.651584\n",
      "epoch: 970 - cost: 0.690205 mse:  360.664247687 - -train accuracy: 0.69284\n",
      "epoch: 971 - cost: 0.667412 mse:  357.552143246 - -train accuracy: 0.65185\n",
      "epoch: 972 - cost: 0.688872 mse:  360.322019317 - -train accuracy: 0.693639\n",
      "epoch: 973 - cost: 0.666283 mse:  357.208654696 - -train accuracy: 0.65185\n",
      "epoch: 974 - cost: 0.687615 mse:  359.955826836 - -train accuracy: 0.693905\n",
      "epoch: 975 - cost: 0.665224 mse:  356.854715082 - -train accuracy: 0.652382\n",
      "epoch: 976 - cost: 0.686405 mse:  359.616304787 - -train accuracy: 0.694703\n",
      "epoch: 977 - cost: 0.664147 mse:  356.510036228 - -train accuracy: 0.652648\n",
      "epoch: 978 - cost: 0.685192 mse:  359.274407889 - -train accuracy: 0.694969\n",
      "epoch: 979 - cost: 0.66311 mse:  356.216065205 - -train accuracy: 0.652915\n",
      "epoch: 980 - cost: 0.684005 mse:  358.955667664 - -train accuracy: 0.695768\n",
      "epoch: 981 - cost: 0.662054 mse:  355.918192419 - -train accuracy: 0.653979\n",
      "epoch: 982 - cost: 0.682789 mse:  358.634667025 - -train accuracy: 0.695768\n",
      "epoch: 983 - cost: 0.661038 mse:  355.615761922 - -train accuracy: 0.654512\n",
      "epoch: 984 - cost: 0.681667 mse:  358.298447206 - -train accuracy: 0.695768\n",
      "epoch: 985 - cost: 0.660014 mse:  355.285914547 - -train accuracy: 0.654512\n",
      "epoch: 986 - cost: 0.680321 mse:  357.988926309 - -train accuracy: 0.697099\n",
      "epoch: 987 - cost: 0.65887 mse:  354.980015752 - -train accuracy: 0.655842\n",
      "epoch: 988 - cost: 0.679178 mse:  357.596407239 - -train accuracy: 0.697099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 989 - cost: 0.657917 mse:  354.588170655 - -train accuracy: 0.655842\n",
      "epoch: 990 - cost: 0.678005 mse:  357.309783598 - -train accuracy: 0.697365\n",
      "epoch: 991 - cost: 0.656894 mse:  354.322547424 - -train accuracy: 0.655842\n",
      "epoch: 992 - cost: 0.676847 mse:  356.994718465 - -train accuracy: 0.697365\n",
      "epoch: 993 - cost: 0.655946 mse:  353.991007143 - -train accuracy: 0.655842\n",
      "epoch: 994 - cost: 0.675717 mse:  356.642467113 - -train accuracy: 0.697897\n",
      "epoch: 995 - cost: 0.654966 mse:  353.650558182 - -train accuracy: 0.655842\n",
      "epoch: 996 - cost: 0.674562 mse:  356.308185507 - -train accuracy: 0.69843\n",
      "epoch: 997 - cost: 0.653911 mse:  353.309549823 - -train accuracy: 0.656109\n",
      "epoch: 998 - cost: 0.673457 mse:  355.951009822 - -train accuracy: 0.698696\n",
      "epoch: 999 - cost: 0.653076 mse:  352.990163145 - -train accuracy: 0.656109\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    sess.run(train_step,feed_dict={x:x_train,y_:y_train})\n",
    "    cost=sess.run(cross_entropy,feed_dict={x:x_train,y_:y_train})\n",
    "    cost_history.append(np.append(cost_history,cost))\n",
    "    correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    \n",
    "    pred_y=sess.run(y,feed_dict={x:x_test})\n",
    "    mse=tf.reduce_mean(tf.square(pred_y-y_test))\n",
    "    mse_=sess.run(mse)\n",
    "    mse_history.append(mse_)\n",
    "    accuracy=sess.run(accuracy,feed_dict={x:x_train,y_:y_train})\n",
    "    accuracy_history.append(accuracy)\n",
    "    \n",
    "    print('epoch:',epoch,'-','cost:',cost,'mse: ',mse_,'-','-train accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.660724\n"
     ]
    }
   ],
   "source": [
    "correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "print('test accuracy:',sess.run(accuracy,feed_dict={x:x_test,y_:y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:352.9902\n"
     ]
    }
   ],
   "source": [
    "pred_y=sess.run(y,feed_dict={x:x_test})\n",
    "mse=tf.reduce_mean(tf.square(pred_y-y_test))\n",
    "print('mse:%.4f'%sess.run(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
