{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('/home/saloni/Documents/ML/Mortality/train.csv')\n",
    "labels=pd.read_csv('/home/saloni/Documents/ML/Mortality/labels_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dailydata=df.copy()\n",
    "result=pd.concat([dailydata,labels],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>...</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Temp</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Weight</th>\n",
       "      <th>pH</th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>54</td>\n",
       "      <td>2.973333</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>97.25</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>37.357143</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>171.052632</td>\n",
       "      <td>10.3</td>\n",
       "      <td>80.060976</td>\n",
       "      <td>7.387273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ALP   ALT   AST  Age   Albumin   BUN  Bilirubin  Cholesterol  Creatinine  \\\n",
       "0  77.0  31.0  46.0   54  2.973333  10.5        0.7        154.0        0.75   \n",
       "\n",
       "     DiasABP        ...           SaO2      SysABP       Temp  TroponinI  \\\n",
       "0  58.795833        ...          97.25  116.891892  37.357143        2.1   \n",
       "\n",
       "   TroponinT       Urine   WBC     Weight        pH  In-hospital_death  \n",
       "0       0.14  171.052632  10.3  80.060976  7.387273                  0  \n",
       "\n",
       "[1 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_variables = ['Age', 'Albumin', 'ALP', 'ALT', 'AST', 'Bilirubin', 'BUN', 'Cholesterol', 'Creatinine',\n",
    "                             'DiasABP', 'FiO2', 'GCS', 'Gender', 'Glucose', 'HCO3', 'HCT', 'Height', 'HR', 'ICUType', 'K',\n",
    "                             'Lactate', 'Mg', 'MAP', 'MechVent', 'Na', 'NIDiasABP', 'NIMAP', 'NISysABP', 'PaCO2', 'PaO2',\n",
    "                             'pH', 'Platelets', 'RecordID', 'RespRate', 'SaO2', 'SysABP', 'Temp', 'TroponinI','TroponinT','Urine',\n",
    "                             'WBC', 'Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datawithoutoutliers=result.copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3169, 43)\n"
     ]
    }
   ],
   "source": [
    "for i in list_of_variables:\n",
    "    datawithoutoutliers=datawithoutoutliers[np.abs(datawithoutoutliers[i]-datawithoutoutliers[i].mean())<=(4*datawithoutoutliers[i].std())]\n",
    "    outliers=datawithoutoutliers[np.abs(datawithoutoutliers[i]-datawithoutoutliers[i].mean())>=(4*datawithoutoutliers[i].std())]\n",
    "    \n",
    "print(datawithoutoutliers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels=datawithoutoutliers.pop(\"In-hospital_death\")\n",
    "df=datawithoutoutliers.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3169,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3169, 42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#normalization\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df = scaler.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "df_res,labels_res=SMOTE(random_state=9).fit_sample(df,labels) #balancing the data\n",
    "df_res=pd.DataFrame(df_res)\n",
    "labels_res=pd.DataFrame(labels_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc=OneHotEncoder(sparse=False)\n",
    "onehot_encoded = enc.fit_transform(labels_res)\n",
    "\n",
    "labels_res=onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(df_res,labels_res,test_size=0.33,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden_1=80\n",
    "n_hidden_2=80\n",
    "n_hidden_3=80\n",
    "n_hidden_4=80\n",
    "n_hidden_5=80\n",
    "\n",
    "\n",
    "x=tf.placeholder(tf.float32,shape=[None,42])\n",
    "y_=tf.placeholder(tf.float32,shape=[None,2])\n",
    "w =tf.Variable(tf.zeros([42,2]))\n",
    "b=tf.Variable(tf.zeros([2]))\n",
    "\n",
    "def multilayer_perceptron(x,weights,biases):\n",
    "    layer_1=tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    layer_1=tf.nn.sigmoid(layer_1)\n",
    "    \n",
    "    layer_2=tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
    "    layer_2=tf.nn.sigmoid(layer_2)\n",
    "    \n",
    "    layer_3=tf.add(tf.matmul(layer_2,weights['h3']),biases['b3'])\n",
    "    layer_3=tf.nn.sigmoid(layer_3)\n",
    "    \n",
    "    layer_4=tf.add(tf.matmul(layer_3,weights['h4']),biases['b4'])\n",
    "    layer_4=tf.nn.sigmoid(layer_4)\n",
    "    \n",
    "    layer_5=tf.add(tf.matmul(layer_4,weights['h5']),biases['b5'])\n",
    "    layer_5=tf.nn.relu(layer_5)\n",
    "    \n",
    "    \n",
    "    out_layer=tf.add(tf.matmul(layer_5,weights['out']),biases['out'])\n",
    "    return out_layer\n",
    "\n",
    "weights={\n",
    "       \n",
    "    'h1':tf.Variable(tf.truncated_normal([42,n_hidden_1])),\n",
    "    'h2':tf.Variable(tf.truncated_normal([n_hidden_1,n_hidden_2])),\n",
    "    'h3':tf.Variable(tf.truncated_normal([n_hidden_2,n_hidden_3])),\n",
    "    'h4':tf.Variable(tf.truncated_normal([n_hidden_3,n_hidden_4])),\n",
    "    'h5':tf.Variable(tf.truncated_normal([n_hidden_4,n_hidden_5])),\n",
    "    'out':tf.Variable(tf.truncated_normal([n_hidden_5,2]))\n",
    "}\n",
    "\n",
    "biases={\n",
    "    'b1':tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3':tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'b4':tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    'b5':tf.Variable(tf.truncated_normal([n_hidden_5])),\n",
    "    'out':tf.Variable(tf.truncated_normal([2]))\n",
    "}\n",
    "    \n",
    "y=multilayer_perceptron(x,weights,biases)\n",
    "cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_,logits=y))  \n",
    "train_step=tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "sess.run(tf.global_variables_initializer())                     \n",
    "                     \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_history=[]\n",
    "cost_history=[]\n",
    "accuracy_history=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_epochs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - cost: 14.423 mse:  870.948671723 - -train accuracy: 0.492148\n",
      "epoch: 1 - cost: 9.81883 mse:  648.277495597 - -train accuracy: 0.510514\n",
      "epoch: 2 - cost: 13.0674 mse:  824.742540291 - -train accuracy: 0.492148\n",
      "epoch: 3 - cost: 9.51903 mse:  639.498736882 - -train accuracy: 0.510248\n",
      "epoch: 4 - cost: 11.7187 mse:  783.136033461 - -train accuracy: 0.492148\n",
      "epoch: 5 - cost: 9.50597 mse:  643.436584133 - -train accuracy: 0.509449\n",
      "epoch: 6 - cost: 10.35 mse:  744.171025237 - -train accuracy: 0.492148\n",
      "epoch: 7 - cost: 9.75387 mse:  653.91212373 - -train accuracy: 0.509183\n",
      "epoch: 8 - cost: 9.00779 mse:  709.703248609 - -train accuracy: 0.492148\n",
      "epoch: 9 - cost: 10.167 mse:  667.10179829 - -train accuracy: 0.508917\n",
      "epoch: 10 - cost: 7.72671 mse:  683.174758693 - -train accuracy: 0.492148\n",
      "epoch: 11 - cost: 10.6809 mse:  680.102553605 - -train accuracy: 0.508651\n",
      "epoch: 12 - cost: 6.48907 mse:  659.400348456 - -train accuracy: 0.492148\n",
      "epoch: 13 - cost: 11.2283 mse:  692.29222034 - -train accuracy: 0.508384\n",
      "epoch: 14 - cost: 5.30635 mse:  638.407428813 - -train accuracy: 0.492148\n",
      "epoch: 15 - cost: 11.7392 mse:  702.678783082 - -train accuracy: 0.508384\n",
      "epoch: 16 - cost: 4.22718 mse:  620.180476079 - -train accuracy: 0.494011\n",
      "epoch: 17 - cost: 12.0272 mse:  707.713918447 - -train accuracy: 0.508384\n",
      "epoch: 18 - cost: 3.44802 mse:  606.524172338 - -train accuracy: 0.495076\n",
      "epoch: 19 - cost: 11.7958 mse:  700.404999757 - -train accuracy: 0.508384\n",
      "epoch: 20 - cost: 3.25097 mse:  598.947166706 - -train accuracy: 0.496141\n",
      "epoch: 21 - cost: 11.3844 mse:  689.171550706 - -train accuracy: 0.508384\n",
      "epoch: 22 - cost: 3.28452 mse:  594.812973805 - -train accuracy: 0.495342\n",
      "epoch: 23 - cost: 11.0642 mse:  679.761304359 - -train accuracy: 0.508384\n",
      "epoch: 24 - cost: 3.26253 mse:  589.178367245 - -train accuracy: 0.495874\n",
      "epoch: 25 - cost: 10.7358 mse:  670.50199828 - -train accuracy: 0.508384\n",
      "epoch: 26 - cost: 3.27894 mse:  584.985169835 - -train accuracy: 0.495874\n",
      "epoch: 27 - cost: 10.4397 mse:  662.344894952 - -train accuracy: 0.508384\n",
      "epoch: 28 - cost: 3.28758 mse:  581.097514875 - -train accuracy: 0.495874\n",
      "epoch: 29 - cost: 10.1537 mse:  654.911044976 - -train accuracy: 0.508384\n",
      "epoch: 30 - cost: 3.31051 mse:  578.123284694 - -train accuracy: 0.495874\n",
      "epoch: 31 - cost: 9.88998 mse:  648.313071379 - -train accuracy: 0.508384\n",
      "epoch: 32 - cost: 3.32678 mse:  575.363096398 - -train accuracy: 0.495608\n",
      "epoch: 33 - cost: 9.63979 mse:  642.338755805 - -train accuracy: 0.508384\n",
      "epoch: 34 - cost: 3.3339 mse:  573.064876687 - -train accuracy: 0.495342\n",
      "epoch: 35 - cost: 9.3905 mse:  636.68768689 - -train accuracy: 0.508384\n",
      "epoch: 36 - cost: 3.34914 mse:  571.289737141 - -train accuracy: 0.495342\n",
      "epoch: 37 - cost: 9.14773 mse:  631.517304767 - -train accuracy: 0.508384\n",
      "epoch: 38 - cost: 3.36746 mse:  569.917360395 - -train accuracy: 0.495342\n",
      "epoch: 39 - cost: 8.91442 mse:  626.910809984 - -train accuracy: 0.508384\n",
      "epoch: 40 - cost: 3.38074 mse:  569.187704338 - -train accuracy: 0.495342\n",
      "epoch: 41 - cost: 8.67572 mse:  622.263053872 - -train accuracy: 0.508384\n",
      "epoch: 42 - cost: 3.40772 mse:  568.414228041 - -train accuracy: 0.495342\n",
      "epoch: 43 - cost: 8.44613 mse:  617.925532288 - -train accuracy: 0.508384\n",
      "epoch: 44 - cost: 3.43703 mse:  567.680088948 - -train accuracy: 0.495076\n",
      "epoch: 45 - cost: 8.22761 mse:  613.879310852 - -train accuracy: 0.508384\n",
      "epoch: 46 - cost: 3.46391 mse:  567.135604474 - -train accuracy: 0.496673\n",
      "epoch: 47 - cost: 8.01823 mse:  609.940257796 - -train accuracy: 0.508384\n",
      "epoch: 48 - cost: 3.49016 mse:  566.519780486 - -train accuracy: 0.497471\n",
      "epoch: 49 - cost: 7.82108 mse:  606.384012581 - -train accuracy: 0.508651\n",
      "epoch: 50 - cost: 3.51848 mse:  565.912788078 - -train accuracy: 0.497471\n",
      "epoch: 51 - cost: 7.64861 mse:  603.201987756 - -train accuracy: 0.508917\n",
      "epoch: 52 - cost: 3.52799 mse:  565.091127606 - -train accuracy: 0.497471\n",
      "epoch: 53 - cost: 7.48927 mse:  600.344860811 - -train accuracy: 0.509183\n",
      "epoch: 54 - cost: 3.52937 mse:  564.503623532 - -train accuracy: 0.497471\n",
      "epoch: 55 - cost: 7.33033 mse:  597.509221823 - -train accuracy: 0.509449\n",
      "epoch: 56 - cost: 3.53818 mse:  563.853191585 - -train accuracy: 0.497471\n",
      "epoch: 57 - cost: 7.18438 mse:  594.832178691 - -train accuracy: 0.509449\n",
      "epoch: 58 - cost: 3.53548 mse:  563.159209225 - -train accuracy: 0.497471\n",
      "epoch: 59 - cost: 7.0455 mse:  592.352214826 - -train accuracy: 0.509449\n",
      "epoch: 60 - cost: 3.52933 mse:  562.55783691 - -train accuracy: 0.497471\n",
      "epoch: 61 - cost: 6.90682 mse:  589.825790444 - -train accuracy: 0.510248\n",
      "epoch: 62 - cost: 3.52483 mse:  562.004750362 - -train accuracy: 0.497471\n",
      "epoch: 63 - cost: 6.7746 mse:  587.265198093 - -train accuracy: 0.510514\n",
      "epoch: 64 - cost: 3.51893 mse:  561.244441804 - -train accuracy: 0.497471\n",
      "epoch: 65 - cost: 6.64559 mse:  584.640672958 - -train accuracy: 0.511046\n",
      "epoch: 66 - cost: 3.51617 mse:  560.220148706 - -train accuracy: 0.497738\n",
      "epoch: 67 - cost: 6.5266 mse:  581.969874781 - -train accuracy: 0.512111\n",
      "epoch: 68 - cost: 3.50296 mse:  559.043699327 - -train accuracy: 0.497471\n",
      "epoch: 69 - cost: 6.41023 mse:  579.248324175 - -train accuracy: 0.512111\n",
      "epoch: 70 - cost: 3.4932 mse:  557.60337498 - -train accuracy: 0.497738\n",
      "epoch: 71 - cost: 6.30155 mse:  576.50645276 - -train accuracy: 0.512377\n",
      "epoch: 72 - cost: 3.47909 mse:  556.089479711 - -train accuracy: 0.49827\n",
      "epoch: 73 - cost: 6.19563 mse:  573.709560543 - -train accuracy: 0.513708\n",
      "epoch: 74 - cost: 3.46508 mse:  554.452136978 - -train accuracy: 0.49827\n",
      "epoch: 75 - cost: 6.09429 mse:  570.84081798 - -train accuracy: 0.513175\n",
      "epoch: 76 - cost: 3.45046 mse:  552.557091852 - -train accuracy: 0.498536\n",
      "epoch: 77 - cost: 5.99514 mse:  567.935946444 - -train accuracy: 0.513442\n",
      "epoch: 78 - cost: 3.43525 mse:  550.650080822 - -train accuracy: 0.498536\n",
      "epoch: 79 - cost: 5.90023 mse:  565.100069408 - -train accuracy: 0.513708\n",
      "epoch: 80 - cost: 3.41917 mse:  548.755968702 - -train accuracy: 0.498802\n",
      "epoch: 81 - cost: 5.81316 mse:  562.305456498 - -train accuracy: 0.51424\n",
      "epoch: 82 - cost: 3.3982 mse:  546.69427042 - -train accuracy: 0.499601\n",
      "epoch: 83 - cost: 5.72521 mse:  559.457102185 - -train accuracy: 0.514506\n",
      "epoch: 84 - cost: 3.38088 mse:  544.713844262 - -train accuracy: 0.500932\n",
      "epoch: 85 - cost: 5.64111 mse:  556.573310137 - -train accuracy: 0.515837\n",
      "epoch: 86 - cost: 3.35821 mse:  542.566006134 - -train accuracy: 0.501464\n",
      "epoch: 87 - cost: 5.5601 mse:  553.734325935 - -train accuracy: 0.517434\n",
      "epoch: 88 - cost: 3.33633 mse:  540.498404849 - -train accuracy: 0.501464\n",
      "epoch: 89 - cost: 5.48021 mse:  550.964956441 - -train accuracy: 0.517434\n",
      "epoch: 90 - cost: 3.3156 mse:  538.425538696 - -train accuracy: 0.502529\n",
      "epoch: 91 - cost: 5.4018 mse:  548.131426373 - -train accuracy: 0.518233\n",
      "epoch: 92 - cost: 3.29627 mse:  536.263294127 - -train accuracy: 0.503061\n",
      "epoch: 93 - cost: 5.32275 mse:  545.131849301 - -train accuracy: 0.519563\n",
      "epoch: 94 - cost: 3.27882 mse:  533.8907914 - -train accuracy: 0.503859\n",
      "epoch: 95 - cost: 5.24715 mse:  542.096123101 - -train accuracy: 0.520096\n",
      "epoch: 96 - cost: 3.25903 mse:  531.456059322 - -train accuracy: 0.504126\n",
      "epoch: 97 - cost: 5.17353 mse:  539.084546052 - -train accuracy: 0.520628\n",
      "epoch: 98 - cost: 3.23971 mse:  528.919572159 - -train accuracy: 0.504392\n",
      "epoch: 99 - cost: 5.10337 mse:  536.051890538 - -train accuracy: 0.521427\n",
      "epoch: 100 - cost: 3.21892 mse:  526.418434725 - -train accuracy: 0.505989\n",
      "epoch: 101 - cost: 5.03489 mse:  532.980340148 - -train accuracy: 0.521693\n",
      "epoch: 102 - cost: 3.19888 mse:  523.905655407 - -train accuracy: 0.505989\n",
      "epoch: 103 - cost: 4.96931 mse:  529.922691702 - -train accuracy: 0.522491\n",
      "epoch: 104 - cost: 3.17751 mse:  521.401695742 - -train accuracy: 0.507586\n",
      "epoch: 105 - cost: 4.90654 mse:  526.955183742 - -train accuracy: 0.523024\n",
      "epoch: 106 - cost: 3.15597 mse:  519.034164768 - -train accuracy: 0.507852\n",
      "epoch: 107 - cost: 4.84363 mse:  523.983246548 - -train accuracy: 0.523822\n",
      "epoch: 108 - cost: 3.1351 mse:  516.655720011 - -train accuracy: 0.508917\n",
      "epoch: 109 - cost: 4.78056 mse:  520.940551498 - -train accuracy: 0.525153\n",
      "epoch: 110 - cost: 3.11576 mse:  514.15688235 - -train accuracy: 0.510248\n",
      "epoch: 111 - cost: 4.72196 mse:  517.981444507 - -train accuracy: 0.524887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 112 - cost: 3.09396 mse:  511.698962078 - -train accuracy: 0.511578\n",
      "epoch: 113 - cost: 4.66259 mse:  515.031147598 - -train accuracy: 0.525685\n",
      "epoch: 114 - cost: 3.07316 mse:  509.240626045 - -train accuracy: 0.512377\n",
      "epoch: 115 - cost: 4.60447 mse:  512.125779443 - -train accuracy: 0.527016\n",
      "epoch: 116 - cost: 3.05276 mse:  506.816665729 - -train accuracy: 0.513442\n",
      "epoch: 117 - cost: 4.54742 mse:  509.26107043 - -train accuracy: 0.528081\n",
      "epoch: 118 - cost: 3.03221 mse:  504.429628646 - -train accuracy: 0.514506\n",
      "epoch: 119 - cost: 4.49278 mse:  506.408469394 - -train accuracy: 0.528347\n",
      "epoch: 120 - cost: 3.0119 mse:  502.018631216 - -train accuracy: 0.516369\n",
      "epoch: 121 - cost: 4.43906 mse:  503.572505205 - -train accuracy: 0.529146\n",
      "epoch: 122 - cost: 2.99193 mse:  499.693408135 - -train accuracy: 0.516636\n",
      "epoch: 123 - cost: 4.38865 mse:  500.902868713 - -train accuracy: 0.529678\n",
      "epoch: 124 - cost: 2.9714 mse:  497.47223281 - -train accuracy: 0.516369\n",
      "epoch: 125 - cost: 4.33839 mse:  498.248122184 - -train accuracy: 0.529678\n",
      "epoch: 126 - cost: 2.95018 mse:  495.331953513 - -train accuracy: 0.516902\n",
      "epoch: 127 - cost: 4.28894 mse:  495.684120202 - -train accuracy: 0.53021\n",
      "epoch: 128 - cost: 2.9295 mse:  493.261959976 - -train accuracy: 0.517434\n",
      "epoch: 129 - cost: 4.2402 mse:  493.137140529 - -train accuracy: 0.532073\n",
      "epoch: 130 - cost: 2.90896 mse:  491.162472119 - -train accuracy: 0.518499\n",
      "epoch: 131 - cost: 4.19353 mse:  490.683230391 - -train accuracy: 0.533404\n",
      "epoch: 132 - cost: 2.88905 mse:  489.098805776 - -train accuracy: 0.519031\n",
      "epoch: 133 - cost: 4.14657 mse:  488.210262831 - -train accuracy: 0.533937\n",
      "epoch: 134 - cost: 2.86908 mse:  487.046771621 - -train accuracy: 0.519031\n",
      "epoch: 135 - cost: 4.10174 mse:  485.822191841 - -train accuracy: 0.533937\n",
      "epoch: 136 - cost: 2.84904 mse:  485.075296795 - -train accuracy: 0.519297\n",
      "epoch: 137 - cost: 4.05675 mse:  483.410842637 - -train accuracy: 0.535267\n",
      "epoch: 138 - cost: 2.82991 mse:  483.024264822 - -train accuracy: 0.51983\n",
      "epoch: 139 - cost: 4.01325 mse:  480.981752143 - -train accuracy: 0.5358\n",
      "epoch: 140 - cost: 2.81083 mse:  480.947496544 - -train accuracy: 0.520096\n",
      "epoch: 141 - cost: 3.97048 mse:  478.566733351 - -train accuracy: 0.537131\n",
      "epoch: 142 - cost: 2.79084 mse:  478.85767638 - -train accuracy: 0.520362\n",
      "epoch: 143 - cost: 3.92825 mse:  476.158048024 - -train accuracy: 0.538994\n",
      "epoch: 144 - cost: 2.77036 mse:  476.85639432 - -train accuracy: 0.520096\n",
      "epoch: 145 - cost: 3.8858 mse:  473.709469879 - -train accuracy: 0.539792\n",
      "epoch: 146 - cost: 2.75175 mse:  474.731807666 - -train accuracy: 0.520628\n",
      "epoch: 147 - cost: 3.84605 mse:  471.329948115 - -train accuracy: 0.539792\n",
      "epoch: 148 - cost: 2.73267 mse:  472.656690459 - -train accuracy: 0.521693\n",
      "epoch: 149 - cost: 3.80662 mse:  468.926054031 - -train accuracy: 0.540591\n",
      "epoch: 150 - cost: 2.71374 mse:  470.563246599 - -train accuracy: 0.521959\n",
      "epoch: 151 - cost: 3.76789 mse:  466.586144854 - -train accuracy: 0.541123\n",
      "epoch: 152 - cost: 2.6953 mse:  468.551482715 - -train accuracy: 0.523024\n",
      "epoch: 153 - cost: 3.72928 mse:  464.216579636 - -train accuracy: 0.541656\n",
      "epoch: 154 - cost: 2.67667 mse:  466.52338046 - -train accuracy: 0.523556\n",
      "epoch: 155 - cost: 3.69117 mse:  461.92297112 - -train accuracy: 0.54272\n",
      "epoch: 156 - cost: 2.65854 mse:  464.575299931 - -train accuracy: 0.525419\n",
      "epoch: 157 - cost: 3.65458 mse:  459.66335716 - -train accuracy: 0.542986\n",
      "epoch: 158 - cost: 2.6402 mse:  462.668408475 - -train accuracy: 0.525952\n",
      "epoch: 159 - cost: 3.61781 mse:  457.360771534 - -train accuracy: 0.543519\n",
      "epoch: 160 - cost: 2.62245 mse:  460.674661977 - -train accuracy: 0.526218\n",
      "epoch: 161 - cost: 3.58368 mse:  455.118627037 - -train accuracy: 0.54485\n",
      "epoch: 162 - cost: 2.60553 mse:  458.762050157 - -train accuracy: 0.526484\n",
      "epoch: 163 - cost: 3.55013 mse:  452.906226713 - -train accuracy: 0.54485\n",
      "epoch: 164 - cost: 2.58757 mse:  456.860593292 - -train accuracy: 0.527016\n",
      "epoch: 165 - cost: 3.51796 mse:  450.681785996 - -train accuracy: 0.545116\n",
      "epoch: 166 - cost: 2.56998 mse:  454.978837638 - -train accuracy: 0.527549\n",
      "epoch: 167 - cost: 3.4865 mse:  448.47972113 - -train accuracy: 0.546447\n",
      "epoch: 168 - cost: 2.55242 mse:  453.126119202 - -train accuracy: 0.527815\n",
      "epoch: 169 - cost: 3.45438 mse:  446.331667123 - -train accuracy: 0.547511\n",
      "epoch: 170 - cost: 2.53526 mse:  451.328583639 - -train accuracy: 0.527815\n",
      "epoch: 171 - cost: 3.42443 mse:  444.257486807 - -train accuracy: 0.54831\n",
      "epoch: 172 - cost: 2.51794 mse:  449.6166561 - -train accuracy: 0.528879\n",
      "epoch: 173 - cost: 3.39499 mse:  442.267561899 - -train accuracy: 0.54831\n",
      "epoch: 174 - cost: 2.5013 mse:  447.993600034 - -train accuracy: 0.529678\n",
      "epoch: 175 - cost: 3.36542 mse:  440.222773846 - -train accuracy: 0.549108\n",
      "epoch: 176 - cost: 2.48495 mse:  446.286663869 - -train accuracy: 0.529944\n",
      "epoch: 177 - cost: 3.33558 mse:  438.226411257 - -train accuracy: 0.549907\n",
      "epoch: 178 - cost: 2.46927 mse:  444.640445384 - -train accuracy: 0.530743\n",
      "epoch: 179 - cost: 3.30735 mse:  436.308229831 - -train accuracy: 0.550972\n",
      "epoch: 180 - cost: 2.45279 mse:  443.040311795 - -train accuracy: 0.531009\n",
      "epoch: 181 - cost: 3.27892 mse:  434.361801498 - -train accuracy: 0.551504\n",
      "epoch: 182 - cost: 2.43726 mse:  441.410536589 - -train accuracy: 0.531807\n",
      "epoch: 183 - cost: 3.25134 mse:  432.399996054 - -train accuracy: 0.55177\n",
      "epoch: 184 - cost: 2.42141 mse:  439.780419967 - -train accuracy: 0.533138\n",
      "epoch: 185 - cost: 3.22423 mse:  430.441825866 - -train accuracy: 0.552569\n",
      "epoch: 186 - cost: 2.40477 mse:  438.161097533 - -train accuracy: 0.534469\n",
      "epoch: 187 - cost: 3.19587 mse:  428.399277036 - -train accuracy: 0.553101\n",
      "epoch: 188 - cost: 2.38856 mse:  436.408633527 - -train accuracy: 0.534469\n",
      "epoch: 189 - cost: 3.1684 mse:  426.417013578 - -train accuracy: 0.553899\n",
      "epoch: 190 - cost: 2.37188 mse:  434.81051323 - -train accuracy: 0.535001\n",
      "epoch: 191 - cost: 3.14305 mse:  424.547139761 - -train accuracy: 0.553899\n",
      "epoch: 192 - cost: 2.35733 mse:  433.274925934 - -train accuracy: 0.534735\n",
      "epoch: 193 - cost: 3.11873 mse:  422.674174351 - -train accuracy: 0.554166\n",
      "epoch: 194 - cost: 2.34209 mse:  431.702835805 - -train accuracy: 0.535534\n",
      "epoch: 195 - cost: 3.09354 mse:  420.779633167 - -train accuracy: 0.554698\n",
      "epoch: 196 - cost: 2.32677 mse:  430.151193211 - -train accuracy: 0.535534\n",
      "epoch: 197 - cost: 3.06921 mse:  418.892403022 - -train accuracy: 0.554964\n",
      "epoch: 198 - cost: 2.3118 mse:  428.578414264 - -train accuracy: 0.536332\n",
      "epoch: 199 - cost: 3.04446 mse:  416.971446108 - -train accuracy: 0.555496\n",
      "epoch: 200 - cost: 2.29683 mse:  426.92470205 - -train accuracy: 0.536598\n",
      "epoch: 201 - cost: 3.0202 mse:  415.071749268 - -train accuracy: 0.556029\n",
      "epoch: 202 - cost: 2.28277 mse:  425.302737793 - -train accuracy: 0.536332\n",
      "epoch: 203 - cost: 2.99631 mse:  413.14456585 - -train accuracy: 0.556561\n",
      "epoch: 204 - cost: 2.26805 mse:  423.649501129 - -train accuracy: 0.536332\n",
      "epoch: 205 - cost: 2.9717 mse:  411.242491023 - -train accuracy: 0.556827\n",
      "epoch: 206 - cost: 2.25299 mse:  422.026321585 - -train accuracy: 0.536598\n",
      "epoch: 207 - cost: 2.9474 mse:  409.33516273 - -train accuracy: 0.557626\n",
      "epoch: 208 - cost: 2.23783 mse:  420.380089372 - -train accuracy: 0.537929\n",
      "epoch: 209 - cost: 2.92366 mse:  407.432592813 - -train accuracy: 0.557626\n",
      "epoch: 210 - cost: 2.22296 mse:  418.749589777 - -train accuracy: 0.538195\n",
      "epoch: 211 - cost: 2.89985 mse:  405.546153569 - -train accuracy: 0.558158\n",
      "epoch: 212 - cost: 2.20811 mse:  417.079569162 - -train accuracy: 0.538462\n",
      "epoch: 213 - cost: 2.87613 mse:  403.704263339 - -train accuracy: 0.558424\n",
      "epoch: 214 - cost: 2.1939 mse:  415.485775626 - -train accuracy: 0.538994\n",
      "epoch: 215 - cost: 2.85592 mse:  401.948954778 - -train accuracy: 0.558957\n",
      "epoch: 216 - cost: 2.18111 mse:  413.928587452 - -train accuracy: 0.53926\n",
      "epoch: 217 - cost: 2.83532 mse:  400.117124486 - -train accuracy: 0.559755\n",
      "epoch: 218 - cost: 2.16717 mse:  412.288146792 - -train accuracy: 0.540059\n",
      "epoch: 219 - cost: 2.81398 mse:  398.27637978 - -train accuracy: 0.560554\n",
      "epoch: 220 - cost: 2.15329 mse:  410.666922955 - -train accuracy: 0.540325\n",
      "epoch: 221 - cost: 2.79351 mse:  396.476899599 - -train accuracy: 0.56082\n",
      "epoch: 222 - cost: 2.13912 mse:  409.052836267 - -train accuracy: 0.541389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 223 - cost: 2.77294 mse:  394.704090693 - -train accuracy: 0.56082\n",
      "epoch: 224 - cost: 2.12603 mse:  407.483507145 - -train accuracy: 0.541656\n",
      "epoch: 225 - cost: 2.75161 mse:  392.931639201 - -train accuracy: 0.561884\n",
      "epoch: 226 - cost: 2.11236 mse:  405.832090543 - -train accuracy: 0.542188\n",
      "epoch: 227 - cost: 2.72892 mse:  391.11446505 - -train accuracy: 0.562683\n",
      "epoch: 228 - cost: 2.09826 mse:  404.158614116 - -train accuracy: 0.542986\n",
      "epoch: 229 - cost: 2.70712 mse:  389.296976623 - -train accuracy: 0.563215\n",
      "epoch: 230 - cost: 2.08467 mse:  402.487639145 - -train accuracy: 0.542986\n",
      "epoch: 231 - cost: 2.68591 mse:  387.59331088 - -train accuracy: 0.564546\n",
      "epoch: 232 - cost: 2.07149 mse:  400.932792016 - -train accuracy: 0.543253\n",
      "epoch: 233 - cost: 2.66437 mse:  385.892005746 - -train accuracy: 0.565345\n",
      "epoch: 234 - cost: 2.05782 mse:  399.353121055 - -train accuracy: 0.543253\n",
      "epoch: 235 - cost: 2.64412 mse:  384.281362618 - -train accuracy: 0.566409\n",
      "epoch: 236 - cost: 2.04575 mse:  397.861380934 - -train accuracy: 0.544051\n",
      "epoch: 237 - cost: 2.62491 mse:  382.698327072 - -train accuracy: 0.566676\n",
      "epoch: 238 - cost: 2.03344 mse:  396.333668374 - -train accuracy: 0.544051\n",
      "epoch: 239 - cost: 2.60531 mse:  381.031685097 - -train accuracy: 0.56774\n",
      "epoch: 240 - cost: 2.02037 mse:  394.760604867 - -train accuracy: 0.544317\n",
      "epoch: 241 - cost: 2.58507 mse:  379.362467409 - -train accuracy: 0.569071\n",
      "epoch: 242 - cost: 2.00876 mse:  393.233841866 - -train accuracy: 0.545382\n",
      "epoch: 243 - cost: 2.56632 mse:  377.720183782 - -train accuracy: 0.56987\n",
      "epoch: 244 - cost: 1.99758 mse:  391.712009884 - -train accuracy: 0.545914\n",
      "epoch: 245 - cost: 2.54814 mse:  376.106963155 - -train accuracy: 0.570668\n",
      "epoch: 246 - cost: 1.98544 mse:  390.227595036 - -train accuracy: 0.547245\n",
      "epoch: 247 - cost: 2.53028 mse:  374.531076499 - -train accuracy: 0.5712\n",
      "epoch: 248 - cost: 1.97431 mse:  388.761670388 - -train accuracy: 0.547245\n",
      "epoch: 249 - cost: 2.51248 mse:  372.968620778 - -train accuracy: 0.571733\n",
      "epoch: 250 - cost: 1.96282 mse:  387.294622721 - -train accuracy: 0.548044\n",
      "epoch: 251 - cost: 2.49408 mse:  371.40813172 - -train accuracy: 0.572531\n",
      "epoch: 252 - cost: 1.95098 mse:  385.815359061 - -train accuracy: 0.549108\n",
      "epoch: 253 - cost: 2.47599 mse:  369.824609565 - -train accuracy: 0.57333\n",
      "epoch: 254 - cost: 1.93945 mse:  384.294582611 - -train accuracy: 0.549108\n",
      "epoch: 255 - cost: 2.45727 mse:  368.181141326 - -train accuracy: 0.573596\n",
      "epoch: 256 - cost: 1.92791 mse:  382.653886554 - -train accuracy: 0.549375\n",
      "epoch: 257 - cost: 2.43823 mse:  366.526433828 - -train accuracy: 0.574128\n",
      "epoch: 258 - cost: 1.91683 mse:  381.090614713 - -train accuracy: 0.549907\n",
      "epoch: 259 - cost: 2.42008 mse:  364.864378644 - -train accuracy: 0.575193\n",
      "epoch: 260 - cost: 1.90557 mse:  379.439763026 - -train accuracy: 0.550173\n",
      "epoch: 261 - cost: 2.40194 mse:  363.177062905 - -train accuracy: 0.575725\n",
      "epoch: 262 - cost: 1.89429 mse:  377.799062801 - -train accuracy: 0.550972\n",
      "epoch: 263 - cost: 2.3847 mse:  361.508566231 - -train accuracy: 0.576258\n",
      "epoch: 264 - cost: 1.88319 mse:  376.192953394 - -train accuracy: 0.552036\n",
      "epoch: 265 - cost: 2.36747 mse:  359.867685168 - -train accuracy: 0.576258\n",
      "epoch: 266 - cost: 1.87223 mse:  374.606914801 - -train accuracy: 0.552302\n",
      "epoch: 267 - cost: 2.35052 mse:  358.225227509 - -train accuracy: 0.577056\n",
      "epoch: 268 - cost: 1.86162 mse:  373.039399486 - -train accuracy: 0.553101\n",
      "epoch: 269 - cost: 2.33369 mse:  356.696336916 - -train accuracy: 0.577588\n",
      "epoch: 270 - cost: 1.85127 mse:  371.520312901 - -train accuracy: 0.552835\n",
      "epoch: 271 - cost: 2.31717 mse:  355.10397024 - -train accuracy: 0.577855\n",
      "epoch: 272 - cost: 1.84088 mse:  369.928032831 - -train accuracy: 0.553633\n",
      "epoch: 273 - cost: 2.30027 mse:  353.637996236 - -train accuracy: 0.578121\n",
      "epoch: 274 - cost: 1.83039 mse:  368.526151357 - -train accuracy: 0.554432\n",
      "epoch: 275 - cost: 2.28463 mse:  352.151191534 - -train accuracy: 0.578387\n",
      "epoch: 276 - cost: 1.81976 mse:  367.070217299 - -train accuracy: 0.55523\n",
      "epoch: 277 - cost: 2.26887 mse:  350.657969744 - -train accuracy: 0.579452\n",
      "epoch: 278 - cost: 1.80986 mse:  365.614274205 - -train accuracy: 0.555496\n",
      "epoch: 279 - cost: 2.25452 mse:  349.229181934 - -train accuracy: 0.58025\n",
      "epoch: 280 - cost: 1.79985 mse:  364.231742567 - -train accuracy: 0.556029\n",
      "epoch: 281 - cost: 2.24002 mse:  347.878090226 - -train accuracy: 0.580516\n",
      "epoch: 282 - cost: 1.79029 mse:  362.964751846 - -train accuracy: 0.556029\n",
      "epoch: 283 - cost: 2.22626 mse:  346.60442273 - -train accuracy: 0.580516\n",
      "epoch: 284 - cost: 1.78135 mse:  361.747616305 - -train accuracy: 0.556561\n",
      "epoch: 285 - cost: 2.21281 mse:  345.34170473 - -train accuracy: 0.580783\n",
      "epoch: 286 - cost: 1.77155 mse:  360.529708285 - -train accuracy: 0.556561\n",
      "epoch: 287 - cost: 2.19842 mse:  344.084369755 - -train accuracy: 0.581049\n",
      "epoch: 288 - cost: 1.76163 mse:  359.356982869 - -train accuracy: 0.556827\n",
      "epoch: 289 - cost: 2.1841 mse:  342.886678576 - -train accuracy: 0.581049\n",
      "epoch: 290 - cost: 1.75245 mse:  358.187671217 - -train accuracy: 0.557626\n",
      "epoch: 291 - cost: 2.17051 mse:  341.742272087 - -train accuracy: 0.581581\n",
      "epoch: 292 - cost: 1.74259 mse:  357.143387927 - -train accuracy: 0.557892\n",
      "epoch: 293 - cost: 2.15703 mse:  340.663044652 - -train accuracy: 0.582113\n",
      "epoch: 294 - cost: 1.734 mse:  356.10526108 - -train accuracy: 0.557626\n",
      "epoch: 295 - cost: 2.14404 mse:  339.558268094 - -train accuracy: 0.582912\n",
      "epoch: 296 - cost: 1.72448 mse:  355.014240096 - -train accuracy: 0.55736\n",
      "epoch: 297 - cost: 2.12948 mse:  338.445532317 - -train accuracy: 0.58371\n",
      "epoch: 298 - cost: 1.71481 mse:  353.966872355 - -train accuracy: 0.557626\n",
      "epoch: 299 - cost: 2.11545 mse:  337.337860052 - -train accuracy: 0.583977\n",
      "epoch: 300 - cost: 1.70535 mse:  352.901246768 - -train accuracy: 0.55869\n",
      "epoch: 301 - cost: 2.1016 mse:  336.223690421 - -train accuracy: 0.585041\n",
      "epoch: 302 - cost: 1.69616 mse:  351.830359516 - -train accuracy: 0.558957\n",
      "epoch: 303 - cost: 2.08857 mse:  335.08707867 - -train accuracy: 0.585041\n",
      "epoch: 304 - cost: 1.6872 mse:  350.704465501 - -train accuracy: 0.559755\n",
      "epoch: 305 - cost: 2.07599 mse:  334.002422933 - -train accuracy: 0.585574\n",
      "epoch: 306 - cost: 1.67856 mse:  349.646545188 - -train accuracy: 0.559755\n",
      "epoch: 307 - cost: 2.06351 mse:  332.936533156 - -train accuracy: 0.585041\n",
      "epoch: 308 - cost: 1.66971 mse:  348.614974924 - -train accuracy: 0.560021\n",
      "epoch: 309 - cost: 2.05036 mse:  331.88671463 - -train accuracy: 0.585574\n",
      "epoch: 310 - cost: 1.66062 mse:  347.58096843 - -train accuracy: 0.560554\n",
      "epoch: 311 - cost: 2.0372 mse:  330.864038266 - -train accuracy: 0.586372\n",
      "epoch: 312 - cost: 1.65192 mse:  346.571830444 - -train accuracy: 0.56082\n",
      "epoch: 313 - cost: 2.02439 mse:  329.812013671 - -train accuracy: 0.586638\n",
      "epoch: 314 - cost: 1.64312 mse:  345.558877991 - -train accuracy: 0.561884\n",
      "epoch: 315 - cost: 2.01118 mse:  328.786906819 - -train accuracy: 0.587171\n",
      "epoch: 316 - cost: 1.63446 mse:  344.548250615 - -train accuracy: 0.563215\n",
      "epoch: 317 - cost: 1.99867 mse:  327.786263429 - -train accuracy: 0.587437\n",
      "epoch: 318 - cost: 1.62515 mse:  343.566880592 - -train accuracy: 0.564546\n",
      "epoch: 319 - cost: 1.98539 mse:  326.801098836 - -train accuracy: 0.588235\n",
      "epoch: 320 - cost: 1.61661 mse:  342.59226091 - -train accuracy: 0.56428\n",
      "epoch: 321 - cost: 1.97256 mse:  325.829732651 - -train accuracy: 0.589034\n",
      "epoch: 322 - cost: 1.60762 mse:  341.620879788 - -train accuracy: 0.565078\n",
      "epoch: 323 - cost: 1.9596 mse:  324.857520594 - -train accuracy: 0.590099\n",
      "epoch: 324 - cost: 1.59839 mse:  340.650638853 - -train accuracy: 0.566409\n",
      "epoch: 325 - cost: 1.94654 mse:  323.882939502 - -train accuracy: 0.590099\n",
      "epoch: 326 - cost: 1.59029 mse:  339.641861741 - -train accuracy: 0.566409\n",
      "epoch: 327 - cost: 1.93511 mse:  322.89081466 - -train accuracy: 0.591163\n",
      "epoch: 328 - cost: 1.58187 mse:  338.664572791 - -train accuracy: 0.566942\n",
      "epoch: 329 - cost: 1.92309 mse:  321.933940793 - -train accuracy: 0.591429\n",
      "epoch: 330 - cost: 1.57391 mse:  337.694428012 - -train accuracy: 0.567208\n",
      "epoch: 331 - cost: 1.91196 mse:  320.976239494 - -train accuracy: 0.591962\n",
      "epoch: 332 - cost: 1.56589 mse:  336.731448745 - -train accuracy: 0.566942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 333 - cost: 1.90094 mse:  320.013844103 - -train accuracy: 0.593026\n",
      "epoch: 334 - cost: 1.55848 mse:  335.774889091 - -train accuracy: 0.566942\n",
      "epoch: 335 - cost: 1.8904 mse:  319.078348716 - -train accuracy: 0.593293\n",
      "epoch: 336 - cost: 1.5508 mse:  334.844211459 - -train accuracy: 0.567208\n",
      "epoch: 337 - cost: 1.8797 mse:  318.169478417 - -train accuracy: 0.593559\n",
      "epoch: 338 - cost: 1.54315 mse:  333.930960534 - -train accuracy: 0.567208\n",
      "epoch: 339 - cost: 1.86808 mse:  317.243095694 - -train accuracy: 0.593293\n",
      "epoch: 340 - cost: 1.53535 mse:  332.996322781 - -train accuracy: 0.567474\n",
      "epoch: 341 - cost: 1.85735 mse:  316.365093206 - -train accuracy: 0.593559\n",
      "epoch: 342 - cost: 1.5281 mse:  332.128395343 - -train accuracy: 0.568006\n",
      "epoch: 343 - cost: 1.84673 mse:  315.459573813 - -train accuracy: 0.593559\n",
      "epoch: 344 - cost: 1.52024 mse:  331.251371095 - -train accuracy: 0.568273\n",
      "epoch: 345 - cost: 1.83611 mse:  314.568777619 - -train accuracy: 0.594357\n",
      "epoch: 346 - cost: 1.51269 mse:  330.397400449 - -train accuracy: 0.568006\n",
      "epoch: 347 - cost: 1.82511 mse:  313.655568937 - -train accuracy: 0.59489\n",
      "epoch: 348 - cost: 1.50551 mse:  329.454335988 - -train accuracy: 0.568539\n",
      "epoch: 349 - cost: 1.81544 mse:  312.776716229 - -train accuracy: 0.595688\n",
      "epoch: 350 - cost: 1.49871 mse:  328.58566268 - -train accuracy: 0.568539\n",
      "epoch: 351 - cost: 1.80481 mse:  311.85258149 - -train accuracy: 0.596487\n",
      "epoch: 352 - cost: 1.49125 mse:  327.641982654 - -train accuracy: 0.570668\n",
      "epoch: 353 - cost: 1.79394 mse:  310.984094022 - -train accuracy: 0.597817\n",
      "epoch: 354 - cost: 1.48445 mse:  326.757841646 - -train accuracy: 0.570934\n",
      "epoch: 355 - cost: 1.78402 mse:  310.053523117 - -train accuracy: 0.597817\n",
      "epoch: 356 - cost: 1.47711 mse:  325.811521186 - -train accuracy: 0.5712\n",
      "epoch: 357 - cost: 1.7734 mse:  309.184930999 - -train accuracy: 0.598084\n",
      "epoch: 358 - cost: 1.46992 mse:  324.930496309 - -train accuracy: 0.5712\n",
      "epoch: 359 - cost: 1.76303 mse:  308.30668331 - -train accuracy: 0.598084\n",
      "epoch: 360 - cost: 1.46269 mse:  324.035315478 - -train accuracy: 0.5712\n",
      "epoch: 361 - cost: 1.75242 mse:  307.439619413 - -train accuracy: 0.59835\n",
      "epoch: 362 - cost: 1.45509 mse:  323.144629592 - -train accuracy: 0.572265\n",
      "epoch: 363 - cost: 1.74178 mse:  306.577932438 - -train accuracy: 0.59835\n",
      "epoch: 364 - cost: 1.44795 mse:  322.256954807 - -train accuracy: 0.572265\n",
      "epoch: 365 - cost: 1.73188 mse:  305.709889279 - -train accuracy: 0.598882\n",
      "epoch: 366 - cost: 1.44126 mse:  321.363765471 - -train accuracy: 0.572531\n",
      "epoch: 367 - cost: 1.72227 mse:  304.851734115 - -train accuracy: 0.599414\n",
      "epoch: 368 - cost: 1.43475 mse:  320.474005045 - -train accuracy: 0.573064\n",
      "epoch: 369 - cost: 1.71252 mse:  303.978528043 - -train accuracy: 0.600213\n",
      "epoch: 370 - cost: 1.42783 mse:  319.576295847 - -train accuracy: 0.57333\n",
      "epoch: 371 - cost: 1.70278 mse:  303.102215047 - -train accuracy: 0.600479\n",
      "epoch: 372 - cost: 1.42084 mse:  318.656090795 - -train accuracy: 0.574128\n",
      "epoch: 373 - cost: 1.69343 mse:  302.26088268 - -train accuracy: 0.600745\n",
      "epoch: 374 - cost: 1.41438 mse:  317.810530837 - -train accuracy: 0.574128\n",
      "epoch: 375 - cost: 1.6838 mse:  301.414726464 - -train accuracy: 0.601278\n",
      "epoch: 376 - cost: 1.40785 mse:  316.940432689 - -train accuracy: 0.574394\n",
      "epoch: 377 - cost: 1.67452 mse:  300.582782039 - -train accuracy: 0.601278\n",
      "epoch: 378 - cost: 1.40104 mse:  316.099172987 - -train accuracy: 0.574927\n",
      "epoch: 379 - cost: 1.665 mse:  299.792031757 - -train accuracy: 0.60181\n",
      "epoch: 380 - cost: 1.3943 mse:  315.276342956 - -train accuracy: 0.575193\n",
      "epoch: 381 - cost: 1.65591 mse:  298.984745533 - -train accuracy: 0.602608\n",
      "epoch: 382 - cost: 1.3878 mse:  314.436086371 - -train accuracy: 0.574927\n",
      "epoch: 383 - cost: 1.64719 mse:  298.181134728 - -train accuracy: 0.603673\n",
      "epoch: 384 - cost: 1.38195 mse:  313.606399398 - -train accuracy: 0.575193\n",
      "epoch: 385 - cost: 1.63904 mse:  297.404428447 - -train accuracy: 0.603673\n",
      "epoch: 386 - cost: 1.37596 mse:  312.813223489 - -train accuracy: 0.574927\n",
      "epoch: 387 - cost: 1.63067 mse:  296.643751959 - -train accuracy: 0.603939\n",
      "epoch: 388 - cost: 1.36984 mse:  312.044925329 - -train accuracy: 0.574927\n",
      "epoch: 389 - cost: 1.62204 mse:  295.91679864 - -train accuracy: 0.604205\n",
      "epoch: 390 - cost: 1.36389 mse:  311.289404014 - -train accuracy: 0.575459\n",
      "epoch: 391 - cost: 1.61345 mse:  295.214844916 - -train accuracy: 0.604472\n",
      "epoch: 392 - cost: 1.35792 mse:  310.549082927 - -train accuracy: 0.575992\n",
      "epoch: 393 - cost: 1.6046 mse:  294.493213609 - -train accuracy: 0.604738\n",
      "epoch: 394 - cost: 1.3514 mse:  309.838951401 - -train accuracy: 0.577056\n",
      "epoch: 395 - cost: 1.59579 mse:  293.817459346 - -train accuracy: 0.60527\n",
      "epoch: 396 - cost: 1.34554 mse:  309.121723488 - -train accuracy: 0.577056\n",
      "epoch: 397 - cost: 1.58792 mse:  293.112220311 - -train accuracy: 0.60527\n",
      "epoch: 398 - cost: 1.3398 mse:  308.40770299 - -train accuracy: 0.578387\n",
      "epoch: 399 - cost: 1.57999 mse:  292.416610676 - -train accuracy: 0.605802\n",
      "epoch: 400 - cost: 1.33392 mse:  307.682417621 - -train accuracy: 0.578653\n",
      "epoch: 401 - cost: 1.57176 mse:  291.709085402 - -train accuracy: 0.606335\n",
      "epoch: 402 - cost: 1.32794 mse:  306.943800967 - -train accuracy: 0.579186\n",
      "epoch: 403 - cost: 1.56382 mse:  290.99549687 - -train accuracy: 0.606335\n",
      "epoch: 404 - cost: 1.32257 mse:  306.1989954 - -train accuracy: 0.579452\n",
      "epoch: 405 - cost: 1.55622 mse:  290.250128931 - -train accuracy: 0.606601\n",
      "epoch: 406 - cost: 1.31686 mse:  305.418191067 - -train accuracy: 0.579718\n",
      "epoch: 407 - cost: 1.54805 mse:  289.519646847 - -train accuracy: 0.606867\n",
      "epoch: 408 - cost: 1.31115 mse:  304.648662975 - -train accuracy: 0.579718\n",
      "epoch: 409 - cost: 1.54026 mse:  288.802158209 - -train accuracy: 0.6074\n",
      "epoch: 410 - cost: 1.30543 mse:  303.907096627 - -train accuracy: 0.579718\n",
      "epoch: 411 - cost: 1.53236 mse:  288.092128094 - -train accuracy: 0.608198\n",
      "epoch: 412 - cost: 1.29999 mse:  303.156617078 - -train accuracy: 0.579718\n",
      "epoch: 413 - cost: 1.52529 mse:  287.382243794 - -train accuracy: 0.60873\n",
      "epoch: 414 - cost: 1.29452 mse:  302.409483943 - -train accuracy: 0.579452\n",
      "epoch: 415 - cost: 1.51752 mse:  286.642908397 - -train accuracy: 0.609795\n",
      "epoch: 416 - cost: 1.2889 mse:  301.620191687 - -train accuracy: 0.579984\n",
      "epoch: 417 - cost: 1.51027 mse:  285.945804037 - -train accuracy: 0.610061\n",
      "epoch: 418 - cost: 1.28365 mse:  300.886318524 - -train accuracy: 0.579984\n",
      "epoch: 419 - cost: 1.50357 mse:  285.210320076 - -train accuracy: 0.610327\n",
      "epoch: 420 - cost: 1.27851 mse:  300.074634032 - -train accuracy: 0.58025\n",
      "epoch: 421 - cost: 1.4958 mse:  284.445185941 - -train accuracy: 0.611126\n",
      "epoch: 422 - cost: 1.27333 mse:  299.245626808 - -train accuracy: 0.580783\n",
      "epoch: 423 - cost: 1.48908 mse:  283.646571073 - -train accuracy: 0.611658\n",
      "epoch: 424 - cost: 1.26782 mse:  298.41702181 - -train accuracy: 0.580783\n",
      "epoch: 425 - cost: 1.48141 mse:  282.885493998 - -train accuracy: 0.611924\n",
      "epoch: 426 - cost: 1.26274 mse:  297.624388275 - -train accuracy: 0.581581\n",
      "epoch: 427 - cost: 1.47473 mse:  282.130824715 - -train accuracy: 0.611924\n",
      "epoch: 428 - cost: 1.25734 mse:  296.827510709 - -train accuracy: 0.581581\n",
      "epoch: 429 - cost: 1.4672 mse:  281.384895112 - -train accuracy: 0.612457\n",
      "epoch: 430 - cost: 1.25247 mse:  296.058819562 - -train accuracy: 0.581581\n",
      "epoch: 431 - cost: 1.46139 mse:  280.644236828 - -train accuracy: 0.612723\n",
      "epoch: 432 - cost: 1.24773 mse:  295.253691549 - -train accuracy: 0.582113\n",
      "epoch: 433 - cost: 1.45418 mse:  279.907480396 - -train accuracy: 0.612723\n",
      "epoch: 434 - cost: 1.24251 mse:  294.472551405 - -train accuracy: 0.582113\n",
      "epoch: 435 - cost: 1.44717 mse:  279.176736018 - -train accuracy: 0.613255\n",
      "epoch: 436 - cost: 1.23734 mse:  293.68231296 - -train accuracy: 0.582912\n",
      "epoch: 437 - cost: 1.44011 mse:  278.444878926 - -train accuracy: 0.613788\n",
      "epoch: 438 - cost: 1.23238 mse:  292.910704923 - -train accuracy: 0.583178\n",
      "epoch: 439 - cost: 1.43356 mse:  277.71595919 - -train accuracy: 0.614586\n",
      "epoch: 440 - cost: 1.22731 mse:  292.144721644 - -train accuracy: 0.584243\n",
      "epoch: 441 - cost: 1.42654 mse:  277.024882792 - -train accuracy: 0.615651\n",
      "epoch: 442 - cost: 1.22222 mse:  291.415640615 - -train accuracy: 0.583977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 443 - cost: 1.41996 mse:  276.354225104 - -train accuracy: 0.615651\n",
      "epoch: 444 - cost: 1.21726 mse:  290.699914628 - -train accuracy: 0.583977\n",
      "epoch: 445 - cost: 1.41347 mse:  275.693647864 - -train accuracy: 0.615917\n",
      "epoch: 446 - cost: 1.21228 mse:  289.995111817 - -train accuracy: 0.584775\n",
      "epoch: 447 - cost: 1.40675 mse:  275.029183124 - -train accuracy: 0.616715\n",
      "epoch: 448 - cost: 1.20728 mse:  289.279976872 - -train accuracy: 0.585041\n",
      "epoch: 449 - cost: 1.40031 mse:  274.363160446 - -train accuracy: 0.616982\n",
      "epoch: 450 - cost: 1.20272 mse:  288.557297132 - -train accuracy: 0.585574\n",
      "epoch: 451 - cost: 1.39397 mse:  273.694656637 - -train accuracy: 0.617248\n",
      "epoch: 452 - cost: 1.19813 mse:  287.830213651 - -train accuracy: 0.586372\n",
      "epoch: 453 - cost: 1.38806 mse:  273.025795642 - -train accuracy: 0.617248\n",
      "epoch: 454 - cost: 1.1936 mse:  287.120423508 - -train accuracy: 0.58584\n",
      "epoch: 455 - cost: 1.38167 mse:  272.369529636 - -train accuracy: 0.618312\n",
      "epoch: 456 - cost: 1.18894 mse:  286.383369643 - -train accuracy: 0.585574\n",
      "epoch: 457 - cost: 1.37529 mse:  271.708042484 - -train accuracy: 0.618845\n",
      "epoch: 458 - cost: 1.18453 mse:  285.686235988 - -train accuracy: 0.586106\n",
      "epoch: 459 - cost: 1.36919 mse:  271.038258854 - -train accuracy: 0.619377\n",
      "epoch: 460 - cost: 1.17979 mse:  284.965344316 - -train accuracy: 0.586904\n",
      "epoch: 461 - cost: 1.36268 mse:  270.394095218 - -train accuracy: 0.620442\n",
      "epoch: 462 - cost: 1.1753 mse:  284.287885314 - -train accuracy: 0.586372\n",
      "epoch: 463 - cost: 1.357 mse:  269.752714591 - -train accuracy: 0.62124\n",
      "epoch: 464 - cost: 1.17081 mse:  283.617198943 - -train accuracy: 0.586638\n",
      "epoch: 465 - cost: 1.35072 mse:  269.118558548 - -train accuracy: 0.622039\n",
      "epoch: 466 - cost: 1.16615 mse:  282.947993652 - -train accuracy: 0.586372\n",
      "epoch: 467 - cost: 1.34467 mse:  268.50730326 - -train accuracy: 0.623104\n",
      "epoch: 468 - cost: 1.16179 mse:  282.299094915 - -train accuracy: 0.586372\n",
      "epoch: 469 - cost: 1.33873 mse:  267.877738896 - -train accuracy: 0.62337\n",
      "epoch: 470 - cost: 1.1573 mse:  281.604813048 - -train accuracy: 0.586372\n",
      "epoch: 471 - cost: 1.33265 mse:  267.274395817 - -train accuracy: 0.623636\n",
      "epoch: 472 - cost: 1.15285 mse:  280.932148322 - -train accuracy: 0.586904\n",
      "epoch: 473 - cost: 1.32657 mse:  266.660453821 - -train accuracy: 0.624434\n",
      "epoch: 474 - cost: 1.14847 mse:  280.280426731 - -train accuracy: 0.587969\n",
      "epoch: 475 - cost: 1.32083 mse:  266.021455279 - -train accuracy: 0.624701\n",
      "epoch: 476 - cost: 1.14356 mse:  279.607182359 - -train accuracy: 0.588501\n",
      "epoch: 477 - cost: 1.31428 mse:  265.402714341 - -train accuracy: 0.625233\n",
      "epoch: 478 - cost: 1.13937 mse:  278.937229538 - -train accuracy: 0.588501\n",
      "epoch: 479 - cost: 1.30873 mse:  264.8039797 - -train accuracy: 0.624967\n",
      "epoch: 480 - cost: 1.13501 mse:  278.294395098 - -train accuracy: 0.588501\n",
      "epoch: 481 - cost: 1.30314 mse:  264.198363614 - -train accuracy: 0.625499\n",
      "epoch: 482 - cost: 1.13094 mse:  277.654286434 - -train accuracy: 0.588501\n",
      "epoch: 483 - cost: 1.29778 mse:  263.593691572 - -train accuracy: 0.626031\n",
      "epoch: 484 - cost: 1.12703 mse:  277.012401153 - -train accuracy: 0.588768\n",
      "epoch: 485 - cost: 1.2928 mse:  262.990351606 - -train accuracy: 0.626031\n",
      "epoch: 486 - cost: 1.123 mse:  276.379111219 - -train accuracy: 0.5893\n",
      "epoch: 487 - cost: 1.28717 mse:  262.386888312 - -train accuracy: 0.62683\n",
      "epoch: 488 - cost: 1.11857 mse:  275.741630661 - -train accuracy: 0.589566\n",
      "epoch: 489 - cost: 1.28148 mse:  261.798531679 - -train accuracy: 0.627362\n",
      "epoch: 490 - cost: 1.11434 mse:  275.114240171 - -train accuracy: 0.589832\n",
      "epoch: 491 - cost: 1.27598 mse:  261.221532369 - -train accuracy: 0.627362\n",
      "epoch: 492 - cost: 1.11034 mse:  274.506796151 - -train accuracy: 0.589832\n",
      "epoch: 493 - cost: 1.27073 mse:  260.650428892 - -train accuracy: 0.627895\n",
      "epoch: 494 - cost: 1.10633 mse:  273.905678331 - -train accuracy: 0.589832\n",
      "epoch: 495 - cost: 1.26603 mse:  260.098703209 - -train accuracy: 0.628161\n",
      "epoch: 496 - cost: 1.10259 mse:  273.327433783 - -train accuracy: 0.589566\n",
      "epoch: 497 - cost: 1.26077 mse:  259.553273947 - -train accuracy: 0.628427\n",
      "epoch: 498 - cost: 1.09875 mse:  272.750282325 - -train accuracy: 0.590099\n",
      "epoch: 499 - cost: 1.25565 mse:  259.001210367 - -train accuracy: 0.628427\n",
      "epoch: 500 - cost: 1.095 mse:  272.15652365 - -train accuracy: 0.590099\n",
      "epoch: 501 - cost: 1.2507 mse:  258.455816829 - -train accuracy: 0.628427\n",
      "epoch: 502 - cost: 1.09133 mse:  271.565674674 - -train accuracy: 0.590365\n",
      "epoch: 503 - cost: 1.24545 mse:  257.885489583 - -train accuracy: 0.628693\n",
      "epoch: 504 - cost: 1.08729 mse:  270.955821698 - -train accuracy: 0.591695\n",
      "epoch: 505 - cost: 1.24008 mse:  257.336261761 - -train accuracy: 0.629492\n",
      "epoch: 506 - cost: 1.08354 mse:  270.388347506 - -train accuracy: 0.591962\n",
      "epoch: 507 - cost: 1.23509 mse:  256.783640814 - -train accuracy: 0.629758\n",
      "epoch: 508 - cost: 1.07968 mse:  269.801857656 - -train accuracy: 0.592228\n",
      "epoch: 509 - cost: 1.23 mse:  256.246902686 - -train accuracy: 0.629758\n",
      "epoch: 510 - cost: 1.07601 mse:  269.227225385 - -train accuracy: 0.59276\n",
      "epoch: 511 - cost: 1.22504 mse:  255.717752335 - -train accuracy: 0.63029\n",
      "epoch: 512 - cost: 1.07216 mse:  268.66163447 - -train accuracy: 0.59276\n",
      "epoch: 513 - cost: 1.21993 mse:  255.205031931 - -train accuracy: 0.631089\n",
      "epoch: 514 - cost: 1.06847 mse:  268.114079977 - -train accuracy: 0.59276\n",
      "epoch: 515 - cost: 1.21521 mse:  254.710594563 - -train accuracy: 0.631355\n",
      "epoch: 516 - cost: 1.0649 mse:  267.58507992 - -train accuracy: 0.593293\n",
      "epoch: 517 - cost: 1.21066 mse:  254.216816763 - -train accuracy: 0.631621\n",
      "epoch: 518 - cost: 1.06148 mse:  267.061701831 - -train accuracy: 0.593559\n",
      "epoch: 519 - cost: 1.20602 mse:  253.724960731 - -train accuracy: 0.631621\n",
      "epoch: 520 - cost: 1.05784 mse:  266.525660395 - -train accuracy: 0.594091\n",
      "epoch: 521 - cost: 1.20097 mse:  253.231185654 - -train accuracy: 0.631887\n",
      "epoch: 522 - cost: 1.05397 mse:  265.98261585 - -train accuracy: 0.593559\n",
      "epoch: 523 - cost: 1.19569 mse:  252.743467128 - -train accuracy: 0.632153\n",
      "epoch: 524 - cost: 1.05046 mse:  265.441093805 - -train accuracy: 0.593559\n",
      "epoch: 525 - cost: 1.19077 mse:  252.251570597 - -train accuracy: 0.632153\n",
      "epoch: 526 - cost: 1.04693 mse:  264.895501841 - -train accuracy: 0.593293\n",
      "epoch: 527 - cost: 1.18631 mse:  251.772739201 - -train accuracy: 0.632419\n",
      "epoch: 528 - cost: 1.04348 mse:  264.382906543 - -train accuracy: 0.594357\n",
      "epoch: 529 - cost: 1.18144 mse:  251.284994894 - -train accuracy: 0.632153\n",
      "epoch: 530 - cost: 1.03973 mse:  263.85625663 - -train accuracy: 0.594623\n",
      "epoch: 531 - cost: 1.17672 mse:  250.814753882 - -train accuracy: 0.632153\n",
      "epoch: 532 - cost: 1.03626 mse:  263.356682393 - -train accuracy: 0.594623\n",
      "epoch: 533 - cost: 1.17212 mse:  250.351480468 - -train accuracy: 0.633218\n",
      "epoch: 534 - cost: 1.03312 mse:  262.858970675 - -train accuracy: 0.59489\n",
      "epoch: 535 - cost: 1.16808 mse:  249.88832833 - -train accuracy: 0.634017\n",
      "epoch: 536 - cost: 1.03 mse:  262.365218939 - -train accuracy: 0.59489\n",
      "epoch: 537 - cost: 1.16403 mse:  249.436926103 - -train accuracy: 0.63375\n",
      "epoch: 538 - cost: 1.02681 mse:  261.876664908 - -train accuracy: 0.595156\n",
      "epoch: 539 - cost: 1.16006 mse:  248.982356002 - -train accuracy: 0.63375\n",
      "epoch: 540 - cost: 1.02363 mse:  261.377681785 - -train accuracy: 0.595688\n",
      "epoch: 541 - cost: 1.1555 mse:  248.532811394 - -train accuracy: 0.634017\n",
      "epoch: 542 - cost: 1.02061 mse:  260.894255642 - -train accuracy: 0.596487\n",
      "epoch: 543 - cost: 1.15165 mse:  248.077209801 - -train accuracy: 0.634017\n",
      "epoch: 544 - cost: 1.01749 mse:  260.394373262 - -train accuracy: 0.596487\n",
      "epoch: 545 - cost: 1.14724 mse:  247.610423415 - -train accuracy: 0.634283\n",
      "epoch: 546 - cost: 1.01406 mse:  259.889746369 - -train accuracy: 0.596487\n",
      "epoch: 547 - cost: 1.14258 mse:  247.147595739 - -train accuracy: 0.635081\n",
      "epoch: 548 - cost: 1.01086 mse:  259.405761051 - -train accuracy: 0.59622\n",
      "epoch: 549 - cost: 1.13873 mse:  246.704111988 - -train accuracy: 0.635081\n",
      "epoch: 550 - cost: 1.00788 mse:  258.933754221 - -train accuracy: 0.59622\n",
      "epoch: 551 - cost: 1.13481 mse:  246.254262966 - -train accuracy: 0.635081\n",
      "epoch: 552 - cost: 1.00507 mse:  258.452715758 - -train accuracy: 0.596487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 553 - cost: 1.13105 mse:  245.812260255 - -train accuracy: 0.635614\n",
      "epoch: 554 - cost: 1.00196 mse:  257.977955458 - -train accuracy: 0.597019\n",
      "epoch: 555 - cost: 1.12687 mse:  245.37745368 - -train accuracy: 0.635614\n",
      "epoch: 556 - cost: 0.998901 mse:  257.509698348 - -train accuracy: 0.597285\n",
      "epoch: 557 - cost: 1.12299 mse:  244.957110119 - -train accuracy: 0.636146\n",
      "epoch: 558 - cost: 0.995792 mse:  257.069593091 - -train accuracy: 0.597019\n",
      "epoch: 559 - cost: 1.11913 mse:  244.566596937 - -train accuracy: 0.636678\n",
      "epoch: 560 - cost: 0.99289 mse:  256.659132705 - -train accuracy: 0.597019\n",
      "epoch: 561 - cost: 1.11552 mse:  244.171240789 - -train accuracy: 0.636944\n",
      "epoch: 562 - cost: 0.990202 mse:  256.244870361 - -train accuracy: 0.597285\n",
      "epoch: 563 - cost: 1.11171 mse:  243.768296523 - -train accuracy: 0.637211\n",
      "epoch: 564 - cost: 0.987184 mse:  255.818831062 - -train accuracy: 0.597551\n",
      "epoch: 565 - cost: 1.10739 mse:  243.368977106 - -train accuracy: 0.637477\n",
      "epoch: 566 - cost: 0.983948 mse:  255.382854511 - -train accuracy: 0.598616\n",
      "epoch: 567 - cost: 1.10294 mse:  242.987388325 - -train accuracy: 0.638275\n",
      "epoch: 568 - cost: 0.980749 mse:  254.960564903 - -train accuracy: 0.598616\n",
      "epoch: 569 - cost: 1.09892 mse:  242.60190933 - -train accuracy: 0.638808\n",
      "epoch: 570 - cost: 0.977946 mse:  254.537578171 - -train accuracy: 0.599148\n",
      "epoch: 571 - cost: 1.09533 mse:  242.235260544 - -train accuracy: 0.638808\n",
      "epoch: 572 - cost: 0.975093 mse:  254.164015032 - -train accuracy: 0.599414\n",
      "epoch: 573 - cost: 1.09156 mse:  241.86754574 - -train accuracy: 0.639074\n",
      "epoch: 574 - cost: 0.972154 mse:  253.756174572 - -train accuracy: 0.599947\n",
      "epoch: 575 - cost: 1.08771 mse:  241.488914478 - -train accuracy: 0.63934\n",
      "epoch: 576 - cost: 0.969344 mse:  253.348336682 - -train accuracy: 0.600479\n",
      "epoch: 577 - cost: 1.08417 mse:  241.107153046 - -train accuracy: 0.639872\n",
      "epoch: 578 - cost: 0.966525 mse:  252.934514924 - -train accuracy: 0.600479\n",
      "epoch: 579 - cost: 1.08026 mse:  240.712056686 - -train accuracy: 0.640671\n",
      "epoch: 580 - cost: 0.963583 mse:  252.501728762 - -train accuracy: 0.600745\n",
      "epoch: 581 - cost: 1.07624 mse:  240.32640587 - -train accuracy: 0.641203\n",
      "epoch: 582 - cost: 0.960583 mse:  252.077921025 - -train accuracy: 0.60181\n",
      "epoch: 583 - cost: 1.07203 mse:  239.934315768 - -train accuracy: 0.641735\n",
      "epoch: 584 - cost: 0.957777 mse:  251.643152518 - -train accuracy: 0.602342\n",
      "epoch: 585 - cost: 1.0685 mse:  239.55000423 - -train accuracy: 0.641735\n",
      "epoch: 586 - cost: 0.955132 mse:  251.216023363 - -train accuracy: 0.603141\n",
      "epoch: 587 - cost: 1.0649 mse:  239.169259321 - -train accuracy: 0.642002\n",
      "epoch: 588 - cost: 0.952575 mse:  250.802873961 - -train accuracy: 0.603407\n",
      "epoch: 589 - cost: 1.06146 mse:  238.797163736 - -train accuracy: 0.642002\n",
      "epoch: 590 - cost: 0.949949 mse:  250.394218126 - -train accuracy: 0.603407\n",
      "epoch: 591 - cost: 1.05801 mse:  238.44037308 - -train accuracy: 0.642002\n",
      "epoch: 592 - cost: 0.947153 mse:  250.017467383 - -train accuracy: 0.603407\n",
      "epoch: 593 - cost: 1.05418 mse:  238.104010384 - -train accuracy: 0.643066\n",
      "epoch: 594 - cost: 0.944295 mse:  249.640100504 - -train accuracy: 0.603141\n",
      "epoch: 595 - cost: 1.05061 mse:  237.759036141 - -train accuracy: 0.643066\n",
      "epoch: 596 - cost: 0.941566 mse:  249.267987142 - -train accuracy: 0.603939\n",
      "epoch: 597 - cost: 1.04712 mse:  237.428605074 - -train accuracy: 0.644131\n",
      "epoch: 598 - cost: 0.93891 mse:  248.911664685 - -train accuracy: 0.604205\n",
      "epoch: 599 - cost: 1.04372 mse:  237.10798805 - -train accuracy: 0.644397\n",
      "epoch: 600 - cost: 0.936349 mse:  248.556060049 - -train accuracy: 0.604205\n",
      "epoch: 601 - cost: 1.04042 mse:  236.786271118 - -train accuracy: 0.644929\n",
      "epoch: 602 - cost: 0.93393 mse:  248.202490214 - -train accuracy: 0.604205\n",
      "epoch: 603 - cost: 1.03714 mse:  236.451205523 - -train accuracy: 0.644929\n",
      "epoch: 604 - cost: 0.931438 mse:  247.831816024 - -train accuracy: 0.604205\n",
      "epoch: 605 - cost: 1.03387 mse:  236.139183749 - -train accuracy: 0.645196\n",
      "epoch: 606 - cost: 0.928759 mse:  247.486934101 - -train accuracy: 0.604205\n",
      "epoch: 607 - cost: 1.03036 mse:  235.836518304 - -train accuracy: 0.645196\n",
      "epoch: 608 - cost: 0.926161 mse:  247.14632585 - -train accuracy: 0.604205\n",
      "epoch: 609 - cost: 1.02691 mse:  235.52757491 - -train accuracy: 0.645196\n",
      "epoch: 610 - cost: 0.923654 mse:  246.800660001 - -train accuracy: 0.604472\n",
      "epoch: 611 - cost: 1.02377 mse:  235.22083097 - -train accuracy: 0.645728\n",
      "epoch: 612 - cost: 0.921322 mse:  246.464776631 - -train accuracy: 0.604472\n",
      "epoch: 613 - cost: 1.02057 mse:  234.922490586 - -train accuracy: 0.64626\n",
      "epoch: 614 - cost: 0.918766 mse:  246.136638454 - -train accuracy: 0.60527\n",
      "epoch: 615 - cost: 1.01723 mse:  234.632200899 - -train accuracy: 0.646526\n",
      "epoch: 616 - cost: 0.916173 mse:  245.816718634 - -train accuracy: 0.606069\n",
      "epoch: 617 - cost: 1.01403 mse:  234.334197072 - -train accuracy: 0.646526\n",
      "epoch: 618 - cost: 0.913707 mse:  245.503025053 - -train accuracy: 0.606335\n",
      "epoch: 619 - cost: 1.01113 mse:  234.055393183 - -train accuracy: 0.647059\n",
      "epoch: 620 - cost: 0.911397 mse:  245.216234581 - -train accuracy: 0.606335\n",
      "epoch: 621 - cost: 1.00838 mse:  233.792469055 - -train accuracy: 0.647591\n",
      "epoch: 622 - cost: 0.909231 mse:  244.935090582 - -train accuracy: 0.605802\n",
      "epoch: 623 - cost: 1.00556 mse:  233.527596992 - -train accuracy: 0.647591\n",
      "epoch: 624 - cost: 0.906805 mse:  244.67607398 - -train accuracy: 0.605802\n",
      "epoch: 625 - cost: 1.00256 mse:  233.274021504 - -train accuracy: 0.647591\n",
      "epoch: 626 - cost: 0.904395 mse:  244.399999916 - -train accuracy: 0.606601\n",
      "epoch: 627 - cost: 0.999433 mse:  233.020887728 - -train accuracy: 0.647857\n",
      "epoch: 628 - cost: 0.902114 mse:  244.11927774 - -train accuracy: 0.606601\n",
      "epoch: 629 - cost: 0.99638 mse:  232.746701837 - -train accuracy: 0.648656\n",
      "epoch: 630 - cost: 0.899917 mse:  243.815790759 - -train accuracy: 0.606601\n",
      "epoch: 631 - cost: 0.993275 mse:  232.45812045 - -train accuracy: 0.648656\n",
      "epoch: 632 - cost: 0.897532 mse:  243.498321298 - -train accuracy: 0.607666\n",
      "epoch: 633 - cost: 0.99026 mse:  232.185821522 - -train accuracy: 0.648656\n",
      "epoch: 634 - cost: 0.89542 mse:  243.197565872 - -train accuracy: 0.607932\n",
      "epoch: 635 - cost: 0.987316 mse:  231.902687347 - -train accuracy: 0.648656\n",
      "epoch: 636 - cost: 0.892974 mse:  242.886034108 - -train accuracy: 0.607932\n",
      "epoch: 637 - cost: 0.983907 mse:  231.621214802 - -train accuracy: 0.648656\n",
      "epoch: 638 - cost: 0.890492 mse:  242.560335051 - -train accuracy: 0.608997\n",
      "epoch: 639 - cost: 0.980432 mse:  231.316633851 - -train accuracy: 0.648656\n",
      "epoch: 640 - cost: 0.887802 mse:  242.214936342 - -train accuracy: 0.608997\n",
      "epoch: 641 - cost: 0.976752 mse:  231.012137359 - -train accuracy: 0.64839\n",
      "epoch: 642 - cost: 0.88492 mse:  241.872760659 - -train accuracy: 0.608997\n",
      "epoch: 643 - cost: 0.973087 mse:  230.715039889 - -train accuracy: 0.64839\n",
      "epoch: 644 - cost: 0.882277 mse:  241.551773151 - -train accuracy: 0.609529\n",
      "epoch: 645 - cost: 0.969666 mse:  230.439612137 - -train accuracy: 0.649188\n",
      "epoch: 646 - cost: 0.879815 mse:  241.245385838 - -train accuracy: 0.610061\n",
      "epoch: 647 - cost: 0.966374 mse:  230.159420599 - -train accuracy: 0.648922\n",
      "epoch: 648 - cost: 0.877418 mse:  240.927680489 - -train accuracy: 0.611126\n",
      "epoch: 649 - cost: 0.963167 mse:  229.887739576 - -train accuracy: 0.648922\n",
      "epoch: 650 - cost: 0.875127 mse:  240.626399991 - -train accuracy: 0.611658\n",
      "epoch: 651 - cost: 0.960232 mse:  229.617075444 - -train accuracy: 0.649454\n",
      "epoch: 652 - cost: 0.872863 mse:  240.327814628 - -train accuracy: 0.611658\n",
      "epoch: 653 - cost: 0.957304 mse:  229.357237747 - -train accuracy: 0.649721\n",
      "epoch: 654 - cost: 0.870566 mse:  240.037226293 - -train accuracy: 0.612457\n",
      "epoch: 655 - cost: 0.954132 mse:  229.105766276 - -train accuracy: 0.650253\n",
      "epoch: 656 - cost: 0.868355 mse:  239.747375213 - -train accuracy: 0.613521\n",
      "epoch: 657 - cost: 0.951288 mse:  228.850288088 - -train accuracy: 0.650519\n",
      "epoch: 658 - cost: 0.866085 mse:  239.460016115 - -train accuracy: 0.613255\n",
      "epoch: 659 - cost: 0.948328 mse:  228.584091941 - -train accuracy: 0.652116\n",
      "epoch: 660 - cost: 0.863605 mse:  239.161253253 - -train accuracy: 0.615118\n",
      "epoch: 661 - cost: 0.945122 mse:  228.331181158 - -train accuracy: 0.652382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 662 - cost: 0.861398 mse:  238.88049043 - -train accuracy: 0.616449\n",
      "epoch: 663 - cost: 0.942289 mse:  228.073355026 - -train accuracy: 0.653447\n",
      "epoch: 664 - cost: 0.858962 mse:  238.597820943 - -train accuracy: 0.617248\n",
      "epoch: 665 - cost: 0.939003 mse:  227.831424102 - -train accuracy: 0.653713\n",
      "epoch: 666 - cost: 0.856562 mse:  238.319514527 - -train accuracy: 0.61778\n",
      "epoch: 667 - cost: 0.935932 mse:  227.58529361 - -train accuracy: 0.654512\n",
      "epoch: 668 - cost: 0.854126 mse:  238.036523192 - -train accuracy: 0.618046\n",
      "epoch: 669 - cost: 0.932695 mse:  227.342039177 - -train accuracy: 0.655044\n",
      "epoch: 670 - cost: 0.851706 mse:  237.751644058 - -train accuracy: 0.618312\n",
      "epoch: 671 - cost: 0.929486 mse:  227.09717664 - -train accuracy: 0.655044\n",
      "epoch: 672 - cost: 0.849471 mse:  237.476634639 - -train accuracy: 0.618579\n",
      "epoch: 673 - cost: 0.926537 mse:  226.859045265 - -train accuracy: 0.65531\n",
      "epoch: 674 - cost: 0.847415 mse:  237.219354979 - -train accuracy: 0.619111\n",
      "epoch: 675 - cost: 0.923796 mse:  226.633752124 - -train accuracy: 0.655576\n",
      "epoch: 676 - cost: 0.845178 mse:  236.957940033 - -train accuracy: 0.619111\n",
      "epoch: 677 - cost: 0.920782 mse:  226.394650635 - -train accuracy: 0.656375\n",
      "epoch: 678 - cost: 0.842884 mse:  236.683507191 - -train accuracy: 0.618845\n",
      "epoch: 679 - cost: 0.917737 mse:  226.161706464 - -train accuracy: 0.656641\n",
      "epoch: 680 - cost: 0.840544 mse:  236.401877047 - -train accuracy: 0.619643\n",
      "epoch: 681 - cost: 0.914675 mse:  225.929986785 - -train accuracy: 0.656641\n",
      "epoch: 682 - cost: 0.838133 mse:  236.127932903 - -train accuracy: 0.620176\n",
      "epoch: 683 - cost: 0.911547 mse:  225.700622884 - -train accuracy: 0.657173\n",
      "epoch: 684 - cost: 0.835726 mse:  235.863196578 - -train accuracy: 0.61991\n",
      "epoch: 685 - cost: 0.908521 mse:  225.461759168 - -train accuracy: 0.657706\n",
      "epoch: 686 - cost: 0.83341 mse:  235.574125699 - -train accuracy: 0.61991\n",
      "epoch: 687 - cost: 0.905438 mse:  225.208926613 - -train accuracy: 0.658504\n",
      "epoch: 688 - cost: 0.830971 mse:  235.280087104 - -train accuracy: 0.620176\n",
      "epoch: 689 - cost: 0.902163 mse:  224.957921262 - -train accuracy: 0.659303\n",
      "epoch: 690 - cost: 0.828665 mse:  234.993980887 - -train accuracy: 0.61991\n",
      "epoch: 691 - cost: 0.899206 mse:  224.705295917 - -train accuracy: 0.659303\n",
      "epoch: 692 - cost: 0.826535 mse:  234.701585294 - -train accuracy: 0.620708\n",
      "epoch: 693 - cost: 0.896565 mse:  224.46838996 - -train accuracy: 0.659835\n",
      "epoch: 694 - cost: 0.824446 mse:  234.424220249 - -train accuracy: 0.620708\n",
      "epoch: 695 - cost: 0.893669 mse:  224.223635172 - -train accuracy: 0.660367\n",
      "epoch: 696 - cost: 0.822146 mse:  234.126519759 - -train accuracy: 0.620708\n",
      "epoch: 697 - cost: 0.890505 mse:  223.976170209 - -train accuracy: 0.661432\n",
      "epoch: 698 - cost: 0.819798 mse:  233.843465875 - -train accuracy: 0.621773\n",
      "epoch: 699 - cost: 0.887425 mse:  223.7552802 - -train accuracy: 0.662497\n",
      "epoch: 700 - cost: 0.817791 mse:  233.598984969 - -train accuracy: 0.62124\n",
      "epoch: 701 - cost: 0.884785 mse:  223.535078094 - -train accuracy: 0.663029\n",
      "epoch: 702 - cost: 0.815702 mse:  233.341786914 - -train accuracy: 0.62124\n",
      "epoch: 703 - cost: 0.882168 mse:  223.313408965 - -train accuracy: 0.663029\n",
      "epoch: 704 - cost: 0.813797 mse:  233.087321323 - -train accuracy: 0.622039\n",
      "epoch: 705 - cost: 0.87965 mse:  223.085249302 - -train accuracy: 0.663828\n",
      "epoch: 706 - cost: 0.811872 mse:  232.829424973 - -train accuracy: 0.622571\n",
      "epoch: 707 - cost: 0.877174 mse:  222.856180469 - -train accuracy: 0.664094\n",
      "epoch: 708 - cost: 0.809985 mse:  232.55721062 - -train accuracy: 0.622571\n",
      "epoch: 709 - cost: 0.874333 mse:  222.650595613 - -train accuracy: 0.664626\n",
      "epoch: 710 - cost: 0.807904 mse:  232.318696995 - -train accuracy: 0.622837\n",
      "epoch: 711 - cost: 0.871725 mse:  222.434347056 - -train accuracy: 0.665158\n",
      "epoch: 712 - cost: 0.806069 mse:  232.070397068 - -train accuracy: 0.622837\n",
      "epoch: 713 - cost: 0.869346 mse:  222.243873451 - -train accuracy: 0.665158\n",
      "epoch: 714 - cost: 0.804166 mse:  231.852613931 - -train accuracy: 0.62337\n",
      "epoch: 715 - cost: 0.866762 mse:  222.054495396 - -train accuracy: 0.666223\n",
      "epoch: 716 - cost: 0.802366 mse:  231.632206989 - -train accuracy: 0.623902\n",
      "epoch: 717 - cost: 0.864404 mse:  221.874282696 - -train accuracy: 0.666489\n",
      "epoch: 718 - cost: 0.800495 mse:  231.427624076 - -train accuracy: 0.624434\n",
      "epoch: 719 - cost: 0.862053 mse:  221.706190905 - -train accuracy: 0.666489\n",
      "epoch: 720 - cost: 0.798756 mse:  231.226547435 - -train accuracy: 0.624701\n",
      "epoch: 721 - cost: 0.859977 mse:  221.532044542 - -train accuracy: 0.666755\n",
      "epoch: 722 - cost: 0.797061 mse:  231.025151191 - -train accuracy: 0.624701\n",
      "epoch: 723 - cost: 0.857971 mse:  221.369279258 - -train accuracy: 0.667022\n",
      "epoch: 724 - cost: 0.795531 mse:  230.825343639 - -train accuracy: 0.624967\n",
      "epoch: 725 - cost: 0.855978 mse:  221.187539765 - -train accuracy: 0.667288\n",
      "epoch: 726 - cost: 0.793846 mse:  230.611276703 - -train accuracy: 0.624967\n",
      "epoch: 727 - cost: 0.853872 mse:  221.000027925 - -train accuracy: 0.66782\n",
      "epoch: 728 - cost: 0.79213 mse:  230.391426066 - -train accuracy: 0.624967\n",
      "epoch: 729 - cost: 0.851526 mse:  220.822198563 - -train accuracy: 0.668086\n",
      "epoch: 730 - cost: 0.790293 mse:  230.173505653 - -train accuracy: 0.625499\n",
      "epoch: 731 - cost: 0.849185 mse:  220.642701833 - -train accuracy: 0.668352\n",
      "epoch: 732 - cost: 0.788588 mse:  229.965534899 - -train accuracy: 0.625499\n",
      "epoch: 733 - cost: 0.847004 mse:  220.459874583 - -train accuracy: 0.668352\n",
      "epoch: 734 - cost: 0.786754 mse:  229.764696374 - -train accuracy: 0.625233\n",
      "epoch: 735 - cost: 0.844779 mse:  220.297387248 - -train accuracy: 0.668885\n",
      "epoch: 736 - cost: 0.785177 mse:  229.561971806 - -train accuracy: 0.624967\n",
      "epoch: 737 - cost: 0.842708 mse:  220.137954792 - -train accuracy: 0.668619\n",
      "epoch: 738 - cost: 0.783398 mse:  229.400637831 - -train accuracy: 0.625233\n",
      "epoch: 739 - cost: 0.840554 mse:  219.993158582 - -train accuracy: 0.669151\n",
      "epoch: 740 - cost: 0.781657 mse:  229.209905514 - -train accuracy: 0.625765\n",
      "epoch: 741 - cost: 0.838354 mse:  219.824155273 - -train accuracy: 0.669417\n",
      "epoch: 742 - cost: 0.779769 mse:  228.993612296 - -train accuracy: 0.626031\n",
      "epoch: 743 - cost: 0.836008 mse:  219.631525671 - -train accuracy: 0.669417\n",
      "epoch: 744 - cost: 0.778035 mse:  228.767367678 - -train accuracy: 0.626564\n",
      "epoch: 745 - cost: 0.83371 mse:  219.445317348 - -train accuracy: 0.669417\n",
      "epoch: 746 - cost: 0.776361 mse:  228.544757138 - -train accuracy: 0.626298\n",
      "epoch: 747 - cost: 0.831635 mse:  219.247223344 - -train accuracy: 0.670482\n",
      "epoch: 748 - cost: 0.774753 mse:  228.31809831 - -train accuracy: 0.62683\n",
      "epoch: 749 - cost: 0.829559 mse:  219.059109547 - -train accuracy: 0.670748\n",
      "epoch: 750 - cost: 0.773143 mse:  228.10521447 - -train accuracy: 0.627096\n",
      "epoch: 751 - cost: 0.827606 mse:  218.866262987 - -train accuracy: 0.67128\n",
      "epoch: 752 - cost: 0.77154 mse:  227.880707186 - -train accuracy: 0.627895\n",
      "epoch: 753 - cost: 0.825526 mse:  218.672342589 - -train accuracy: 0.671546\n",
      "epoch: 754 - cost: 0.769883 mse:  227.661631964 - -train accuracy: 0.628161\n",
      "epoch: 755 - cost: 0.823505 mse:  218.482423802 - -train accuracy: 0.671813\n",
      "epoch: 756 - cost: 0.768325 mse:  227.442326964 - -train accuracy: 0.628427\n",
      "epoch: 757 - cost: 0.821497 mse:  218.293197956 - -train accuracy: 0.672079\n",
      "epoch: 758 - cost: 0.766767 mse:  227.231437349 - -train accuracy: 0.628959\n",
      "epoch: 759 - cost: 0.819386 mse:  218.113371063 - -train accuracy: 0.672345\n",
      "epoch: 760 - cost: 0.765051 mse:  227.017865309 - -train accuracy: 0.629492\n",
      "epoch: 761 - cost: 0.817164 mse:  217.928543399 - -train accuracy: 0.672611\n",
      "epoch: 762 - cost: 0.763257 mse:  226.795723833 - -train accuracy: 0.629758\n",
      "epoch: 763 - cost: 0.814856 mse:  217.745542078 - -train accuracy: 0.673676\n",
      "epoch: 764 - cost: 0.761438 mse:  226.563680506 - -train accuracy: 0.631355\n",
      "epoch: 765 - cost: 0.81255 mse:  217.555379512 - -train accuracy: 0.67341\n",
      "epoch: 766 - cost: 0.759635 mse:  226.330786205 - -train accuracy: 0.631621\n",
      "epoch: 767 - cost: 0.810325 mse:  217.361786922 - -train accuracy: 0.673942\n",
      "epoch: 768 - cost: 0.757949 mse:  226.111736172 - -train accuracy: 0.632153\n",
      "epoch: 769 - cost: 0.808177 mse:  217.181896548 - -train accuracy: 0.67474\n",
      "epoch: 770 - cost: 0.756281 mse:  225.896403886 - -train accuracy: 0.632686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 771 - cost: 0.806098 mse:  217.007792683 - -train accuracy: 0.675273\n",
      "epoch: 772 - cost: 0.75469 mse:  225.685285639 - -train accuracy: 0.632952\n",
      "epoch: 773 - cost: 0.804075 mse:  216.826594229 - -train accuracy: 0.675539\n",
      "epoch: 774 - cost: 0.753064 mse:  225.475126926 - -train accuracy: 0.634017\n",
      "epoch: 775 - cost: 0.802019 mse:  216.636335314 - -train accuracy: 0.675539\n",
      "epoch: 776 - cost: 0.751473 mse:  225.265191751 - -train accuracy: 0.634815\n",
      "epoch: 777 - cost: 0.800061 mse:  216.460394044 - -train accuracy: 0.675805\n",
      "epoch: 778 - cost: 0.749924 mse:  225.057605581 - -train accuracy: 0.635081\n",
      "epoch: 779 - cost: 0.79808 mse:  216.292951387 - -train accuracy: 0.676337\n",
      "epoch: 780 - cost: 0.748405 mse:  224.858627059 - -train accuracy: 0.636944\n",
      "epoch: 781 - cost: 0.796198 mse:  216.12975482 - -train accuracy: 0.676604\n",
      "epoch: 782 - cost: 0.747028 mse:  224.665116502 - -train accuracy: 0.638009\n",
      "epoch: 783 - cost: 0.794413 mse:  215.965377298 - -train accuracy: 0.67687\n",
      "epoch: 784 - cost: 0.745528 mse:  224.463751936 - -train accuracy: 0.638541\n",
      "epoch: 785 - cost: 0.792432 mse:  215.792519688 - -train accuracy: 0.677668\n",
      "epoch: 786 - cost: 0.743909 mse:  224.258237499 - -train accuracy: 0.638541\n",
      "epoch: 787 - cost: 0.790456 mse:  215.617147544 - -train accuracy: 0.678201\n",
      "epoch: 788 - cost: 0.742355 mse:  224.053934052 - -train accuracy: 0.639074\n",
      "epoch: 789 - cost: 0.788587 mse:  215.441786374 - -train accuracy: 0.678467\n",
      "epoch: 790 - cost: 0.740862 mse:  223.862977924 - -train accuracy: 0.63934\n",
      "epoch: 791 - cost: 0.786815 mse:  215.289977503 - -train accuracy: 0.678467\n",
      "epoch: 792 - cost: 0.739431 mse:  223.696477917 - -train accuracy: 0.63934\n",
      "epoch: 793 - cost: 0.785036 mse:  215.123394947 - -train accuracy: 0.678733\n",
      "epoch: 794 - cost: 0.738003 mse:  223.494416129 - -train accuracy: 0.639872\n",
      "epoch: 795 - cost: 0.783374 mse:  214.960454244 - -train accuracy: 0.679265\n",
      "epoch: 796 - cost: 0.736646 mse:  223.297153295 - -train accuracy: 0.640671\n",
      "epoch: 797 - cost: 0.781717 mse:  214.778008236 - -train accuracy: 0.679265\n",
      "epoch: 798 - cost: 0.73533 mse:  223.095253765 - -train accuracy: 0.641203\n",
      "epoch: 799 - cost: 0.779956 mse:  214.604017116 - -train accuracy: 0.679798\n",
      "epoch: 800 - cost: 0.733889 mse:  222.891388573 - -train accuracy: 0.642002\n",
      "epoch: 801 - cost: 0.778187 mse:  214.421035595 - -train accuracy: 0.679798\n",
      "epoch: 802 - cost: 0.732534 mse:  222.688514492 - -train accuracy: 0.642534\n",
      "epoch: 803 - cost: 0.776527 mse:  214.245161003 - -train accuracy: 0.680596\n",
      "epoch: 804 - cost: 0.731208 mse:  222.489361102 - -train accuracy: 0.643066\n",
      "epoch: 805 - cost: 0.774821 mse:  214.072824116 - -train accuracy: 0.680862\n",
      "epoch: 806 - cost: 0.729862 mse:  222.28935831 - -train accuracy: 0.643599\n",
      "epoch: 807 - cost: 0.773111 mse:  213.9014397 - -train accuracy: 0.680862\n",
      "epoch: 808 - cost: 0.728528 mse:  222.086645559 - -train accuracy: 0.644663\n",
      "epoch: 809 - cost: 0.771402 mse:  213.726321099 - -train accuracy: 0.681129\n",
      "epoch: 810 - cost: 0.727144 mse:  221.88633097 - -train accuracy: 0.645462\n",
      "epoch: 811 - cost: 0.769661 mse:  213.559839241 - -train accuracy: 0.681395\n",
      "epoch: 812 - cost: 0.725767 mse:  221.690100648 - -train accuracy: 0.645462\n",
      "epoch: 813 - cost: 0.767888 mse:  213.40483934 - -train accuracy: 0.681395\n",
      "epoch: 814 - cost: 0.724334 mse:  221.50881941 - -train accuracy: 0.645994\n",
      "epoch: 815 - cost: 0.766058 mse:  213.253808156 - -train accuracy: 0.681395\n",
      "epoch: 816 - cost: 0.722817 mse:  221.316743679 - -train accuracy: 0.646793\n",
      "epoch: 817 - cost: 0.764076 mse:  213.094744582 - -train accuracy: 0.682193\n",
      "epoch: 818 - cost: 0.721416 mse:  221.135732878 - -train accuracy: 0.647325\n",
      "epoch: 819 - cost: 0.762379 mse:  212.948394182 - -train accuracy: 0.682193\n",
      "epoch: 820 - cost: 0.720076 mse:  220.958130038 - -train accuracy: 0.647325\n",
      "epoch: 821 - cost: 0.760723 mse:  212.796902485 - -train accuracy: 0.682193\n",
      "epoch: 822 - cost: 0.718725 mse:  220.778260951 - -train accuracy: 0.647857\n",
      "epoch: 823 - cost: 0.759062 mse:  212.6430915 - -train accuracy: 0.683524\n",
      "epoch: 824 - cost: 0.717366 mse:  220.602919026 - -train accuracy: 0.647857\n",
      "epoch: 825 - cost: 0.757348 mse:  212.503941554 - -train accuracy: 0.684323\n",
      "epoch: 826 - cost: 0.715872 mse:  220.437204155 - -train accuracy: 0.649454\n",
      "epoch: 827 - cost: 0.755613 mse:  212.378283876 - -train accuracy: 0.684589\n",
      "epoch: 828 - cost: 0.714563 mse:  220.297125622 - -train accuracy: 0.649721\n",
      "epoch: 829 - cost: 0.754092 mse:  212.261713047 - -train accuracy: 0.684589\n",
      "epoch: 830 - cost: 0.713263 mse:  220.161119773 - -train accuracy: 0.650785\n",
      "epoch: 831 - cost: 0.752494 mse:  212.141034109 - -train accuracy: 0.684855\n",
      "epoch: 832 - cost: 0.711926 mse:  220.019443816 - -train accuracy: 0.651584\n",
      "epoch: 833 - cost: 0.750854 mse:  212.008721886 - -train accuracy: 0.685121\n",
      "epoch: 834 - cost: 0.710707 mse:  219.86357423 - -train accuracy: 0.65185\n",
      "epoch: 835 - cost: 0.749338 mse:  211.87934537 - -train accuracy: 0.685121\n",
      "epoch: 836 - cost: 0.709441 mse:  219.701727942 - -train accuracy: 0.652382\n",
      "epoch: 837 - cost: 0.74776 mse:  211.744638998 - -train accuracy: 0.685387\n",
      "epoch: 838 - cost: 0.708097 mse:  219.532827648 - -train accuracy: 0.652648\n",
      "epoch: 839 - cost: 0.74611 mse:  211.604845547 - -train accuracy: 0.685387\n",
      "epoch: 840 - cost: 0.706757 mse:  219.366120869 - -train accuracy: 0.653181\n",
      "epoch: 841 - cost: 0.744524 mse:  211.464107407 - -train accuracy: 0.685387\n",
      "epoch: 842 - cost: 0.705546 mse:  219.202333725 - -train accuracy: 0.653713\n",
      "epoch: 843 - cost: 0.742947 mse:  211.331744211 - -train accuracy: 0.685121\n",
      "epoch: 844 - cost: 0.704254 mse:  219.049551013 - -train accuracy: 0.653713\n",
      "epoch: 845 - cost: 0.741349 mse:  211.20384391 - -train accuracy: 0.685387\n",
      "epoch: 846 - cost: 0.702994 mse:  218.885573751 - -train accuracy: 0.653447\n",
      "epoch: 847 - cost: 0.739761 mse:  211.061190367 - -train accuracy: 0.687517\n",
      "epoch: 848 - cost: 0.701631 mse:  218.707591419 - -train accuracy: 0.653713\n",
      "epoch: 849 - cost: 0.738167 mse:  210.909066878 - -train accuracy: 0.687783\n",
      "epoch: 850 - cost: 0.700426 mse:  218.532290913 - -train accuracy: 0.653447\n",
      "epoch: 851 - cost: 0.73666 mse:  210.756312246 - -train accuracy: 0.688315\n",
      "epoch: 852 - cost: 0.699131 mse:  218.344036149 - -train accuracy: 0.654245\n",
      "epoch: 853 - cost: 0.735077 mse:  210.595322959 - -train accuracy: 0.688581\n",
      "epoch: 854 - cost: 0.697811 mse:  218.146206523 - -train accuracy: 0.654512\n",
      "epoch: 855 - cost: 0.733373 mse:  210.425907943 - -train accuracy: 0.688581\n",
      "epoch: 856 - cost: 0.696479 mse:  217.948645207 - -train accuracy: 0.654778\n",
      "epoch: 857 - cost: 0.731742 mse:  210.263014737 - -train accuracy: 0.689114\n",
      "epoch: 858 - cost: 0.695172 mse:  217.7548604 - -train accuracy: 0.655842\n",
      "epoch: 859 - cost: 0.730084 mse:  210.091721243 - -train accuracy: 0.689114\n",
      "epoch: 860 - cost: 0.693814 mse:  217.557765626 - -train accuracy: 0.656109\n",
      "epoch: 861 - cost: 0.728437 mse:  209.923261583 - -train accuracy: 0.689114\n",
      "epoch: 862 - cost: 0.69255 mse:  217.360829111 - -train accuracy: 0.656641\n",
      "epoch: 863 - cost: 0.726847 mse:  209.756042597 - -train accuracy: 0.689646\n",
      "epoch: 864 - cost: 0.691253 mse:  217.172111992 - -train accuracy: 0.657439\n",
      "epoch: 865 - cost: 0.725221 mse:  209.604369405 - -train accuracy: 0.690445\n",
      "epoch: 866 - cost: 0.689983 mse:  216.9865062 - -train accuracy: 0.657972\n",
      "epoch: 867 - cost: 0.723711 mse:  209.447622376 - -train accuracy: 0.690711\n",
      "epoch: 868 - cost: 0.688748 mse:  216.801254094 - -train accuracy: 0.657972\n",
      "epoch: 869 - cost: 0.722169 mse:  209.292855008 - -train accuracy: 0.691243\n",
      "epoch: 870 - cost: 0.68754 mse:  216.615488595 - -train accuracy: 0.657972\n",
      "epoch: 871 - cost: 0.720649 mse:  209.13487538 - -train accuracy: 0.691509\n",
      "epoch: 872 - cost: 0.686314 mse:  216.431562018 - -train accuracy: 0.658238\n",
      "epoch: 873 - cost: 0.719142 mse:  208.980234686 - -train accuracy: 0.692042\n",
      "epoch: 874 - cost: 0.685152 mse:  216.2571783 - -train accuracy: 0.65877\n",
      "epoch: 875 - cost: 0.717685 mse:  208.823443673 - -train accuracy: 0.692308\n",
      "epoch: 876 - cost: 0.683949 mse:  216.079592957 - -train accuracy: 0.659036\n",
      "epoch: 877 - cost: 0.716186 mse:  208.673946546 - -train accuracy: 0.692308\n",
      "epoch: 878 - cost: 0.682757 mse:  215.907340671 - -train accuracy: 0.659835\n",
      "epoch: 879 - cost: 0.71476 mse:  208.52549015 - -train accuracy: 0.692308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 880 - cost: 0.681609 mse:  215.730363813 - -train accuracy: 0.659835\n",
      "epoch: 881 - cost: 0.713427 mse:  208.37604907 - -train accuracy: 0.692308\n",
      "epoch: 882 - cost: 0.680465 mse:  215.553894871 - -train accuracy: 0.660634\n",
      "epoch: 883 - cost: 0.711949 mse:  208.23386201 - -train accuracy: 0.692574\n",
      "epoch: 884 - cost: 0.679223 mse:  215.389327223 - -train accuracy: 0.661166\n",
      "epoch: 885 - cost: 0.710416 mse:  208.103812565 - -train accuracy: 0.692574\n",
      "epoch: 886 - cost: 0.677976 mse:  215.231268242 - -train accuracy: 0.661698\n",
      "epoch: 887 - cost: 0.708946 mse:  207.967763806 - -train accuracy: 0.693639\n",
      "epoch: 888 - cost: 0.676768 mse:  215.071954324 - -train accuracy: 0.66223\n",
      "epoch: 889 - cost: 0.707462 mse:  207.824406832 - -train accuracy: 0.694171\n",
      "epoch: 890 - cost: 0.675537 mse:  214.901402425 - -train accuracy: 0.662497\n",
      "epoch: 891 - cost: 0.705922 mse:  207.691917904 - -train accuracy: 0.694703\n",
      "epoch: 892 - cost: 0.67433 mse:  214.744482854 - -train accuracy: 0.663029\n",
      "epoch: 893 - cost: 0.704503 mse:  207.557017324 - -train accuracy: 0.694703\n",
      "epoch: 894 - cost: 0.673188 mse:  214.58695613 - -train accuracy: 0.663561\n",
      "epoch: 895 - cost: 0.703111 mse:  207.422479692 - -train accuracy: 0.694969\n",
      "epoch: 896 - cost: 0.672065 mse:  214.426614231 - -train accuracy: 0.663828\n",
      "epoch: 897 - cost: 0.701775 mse:  207.28847137 - -train accuracy: 0.695236\n",
      "epoch: 898 - cost: 0.670985 mse:  214.270828825 - -train accuracy: 0.664094\n",
      "epoch: 899 - cost: 0.700449 mse:  207.160406794 - -train accuracy: 0.695236\n",
      "epoch: 900 - cost: 0.669819 mse:  214.132273956 - -train accuracy: 0.66436\n",
      "epoch: 901 - cost: 0.699052 mse:  207.037477266 - -train accuracy: 0.695502\n",
      "epoch: 902 - cost: 0.668656 mse:  213.991985356 - -train accuracy: 0.665158\n",
      "epoch: 903 - cost: 0.697635 mse:  206.921061087 - -train accuracy: 0.696566\n",
      "epoch: 904 - cost: 0.667539 mse:  213.850687045 - -train accuracy: 0.665957\n",
      "epoch: 905 - cost: 0.696335 mse:  206.795795061 - -train accuracy: 0.696833\n",
      "epoch: 906 - cost: 0.666462 mse:  213.704469328 - -train accuracy: 0.666755\n",
      "epoch: 907 - cost: 0.695077 mse:  206.672318661 - -train accuracy: 0.697099\n",
      "epoch: 908 - cost: 0.665412 mse:  213.558446903 - -train accuracy: 0.66782\n",
      "epoch: 909 - cost: 0.693791 mse:  206.544657545 - -train accuracy: 0.697365\n",
      "epoch: 910 - cost: 0.664298 mse:  213.409615311 - -train accuracy: 0.668885\n",
      "epoch: 911 - cost: 0.692452 mse:  206.417771311 - -train accuracy: 0.697631\n",
      "epoch: 912 - cost: 0.663215 mse:  213.261357042 - -train accuracy: 0.669151\n",
      "epoch: 913 - cost: 0.691156 mse:  206.298917935 - -train accuracy: 0.697897\n",
      "epoch: 914 - cost: 0.662169 mse:  213.120688431 - -train accuracy: 0.669151\n",
      "epoch: 915 - cost: 0.689914 mse:  206.181557557 - -train accuracy: 0.698163\n",
      "epoch: 916 - cost: 0.661151 mse:  212.979765631 - -train accuracy: 0.669683\n",
      "epoch: 917 - cost: 0.688615 mse:  206.06161342 - -train accuracy: 0.698696\n",
      "epoch: 918 - cost: 0.66008 mse:  212.832036648 - -train accuracy: 0.670216\n",
      "epoch: 919 - cost: 0.687292 mse:  205.945626364 - -train accuracy: 0.699228\n",
      "epoch: 920 - cost: 0.658928 mse:  212.684389845 - -train accuracy: 0.669949\n",
      "epoch: 921 - cost: 0.685875 mse:  205.823269782 - -train accuracy: 0.69976\n",
      "epoch: 922 - cost: 0.657785 mse:  212.536842968 - -train accuracy: 0.670482\n",
      "epoch: 923 - cost: 0.6845 mse:  205.716857173 - -train accuracy: 0.700559\n",
      "epoch: 924 - cost: 0.656653 mse:  212.394856909 - -train accuracy: 0.670482\n",
      "epoch: 925 - cost: 0.683165 mse:  205.599009719 - -train accuracy: 0.701624\n",
      "epoch: 926 - cost: 0.655537 mse:  212.243239775 - -train accuracy: 0.670748\n",
      "epoch: 927 - cost: 0.68179 mse:  205.482819515 - -train accuracy: 0.701624\n",
      "epoch: 928 - cost: 0.654472 mse:  212.108955602 - -train accuracy: 0.671014\n",
      "epoch: 929 - cost: 0.680495 mse:  205.377771895 - -train accuracy: 0.70189\n",
      "epoch: 930 - cost: 0.65338 mse:  211.983778493 - -train accuracy: 0.670748\n",
      "epoch: 931 - cost: 0.679165 mse:  205.273799305 - -train accuracy: 0.702156\n",
      "epoch: 932 - cost: 0.652268 mse:  211.843936309 - -train accuracy: 0.671813\n",
      "epoch: 933 - cost: 0.677787 mse:  205.169990744 - -train accuracy: 0.702688\n",
      "epoch: 934 - cost: 0.651141 mse:  211.71278116 - -train accuracy: 0.672611\n",
      "epoch: 935 - cost: 0.676423 mse:  205.056997634 - -train accuracy: 0.702954\n",
      "epoch: 936 - cost: 0.650054 mse:  211.578964375 - -train accuracy: 0.673143\n",
      "epoch: 937 - cost: 0.675137 mse:  204.945994987 - -train accuracy: 0.702954\n",
      "epoch: 938 - cost: 0.649018 mse:  211.444362797 - -train accuracy: 0.673143\n",
      "epoch: 939 - cost: 0.673849 mse:  204.846163989 - -train accuracy: 0.702954\n",
      "epoch: 940 - cost: 0.647979 mse:  211.322465893 - -train accuracy: 0.672611\n",
      "epoch: 941 - cost: 0.672634 mse:  204.745311967 - -train accuracy: 0.702954\n",
      "epoch: 942 - cost: 0.646969 mse:  211.194957629 - -train accuracy: 0.672611\n",
      "epoch: 943 - cost: 0.671379 mse:  204.646656749 - -train accuracy: 0.703221\n",
      "epoch: 944 - cost: 0.645827 mse:  211.073269309 - -train accuracy: 0.67341\n",
      "epoch: 945 - cost: 0.669888 mse:  204.557802281 - -train accuracy: 0.703753\n",
      "epoch: 946 - cost: 0.644707 mse:  210.955668137 - -train accuracy: 0.67341\n",
      "epoch: 947 - cost: 0.668601 mse:  204.471125271 - -train accuracy: 0.704285\n",
      "epoch: 948 - cost: 0.643652 mse:  210.849504094 - -train accuracy: 0.673676\n",
      "epoch: 949 - cost: 0.667281 mse:  204.392748216 - -train accuracy: 0.704552\n",
      "epoch: 950 - cost: 0.642538 mse:  210.736035828 - -train accuracy: 0.672877\n",
      "epoch: 951 - cost: 0.665809 mse:  204.299419279 - -train accuracy: 0.704818\n",
      "epoch: 952 - cost: 0.641357 mse:  210.603928701 - -train accuracy: 0.672877\n",
      "epoch: 953 - cost: 0.66443 mse:  204.205445421 - -train accuracy: 0.704818\n",
      "epoch: 954 - cost: 0.640169 mse:  210.475727334 - -train accuracy: 0.67341\n",
      "epoch: 955 - cost: 0.663023 mse:  204.110468376 - -train accuracy: 0.705084\n",
      "epoch: 956 - cost: 0.639086 mse:  210.346748442 - -train accuracy: 0.674474\n",
      "epoch: 957 - cost: 0.661705 mse:  204.012709052 - -train accuracy: 0.705084\n",
      "epoch: 958 - cost: 0.637986 mse:  210.226904236 - -train accuracy: 0.675273\n",
      "epoch: 959 - cost: 0.660412 mse:  203.923945663 - -train accuracy: 0.705084\n",
      "epoch: 960 - cost: 0.636972 mse:  210.110198515 - -train accuracy: 0.675805\n",
      "epoch: 961 - cost: 0.659121 mse:  203.828784218 - -train accuracy: 0.705616\n",
      "epoch: 962 - cost: 0.635898 mse:  209.989069157 - -train accuracy: 0.676337\n",
      "epoch: 963 - cost: 0.657823 mse:  203.738909777 - -train accuracy: 0.705616\n",
      "epoch: 964 - cost: 0.634896 mse:  209.867478231 - -train accuracy: 0.676337\n",
      "epoch: 965 - cost: 0.656615 mse:  203.646869402 - -train accuracy: 0.705882\n",
      "epoch: 966 - cost: 0.633846 mse:  209.741126749 - -train accuracy: 0.676337\n",
      "epoch: 967 - cost: 0.655312 mse:  203.545652971 - -train accuracy: 0.706149\n",
      "epoch: 968 - cost: 0.63275 mse:  209.616992129 - -train accuracy: 0.677136\n",
      "epoch: 969 - cost: 0.653993 mse:  203.447012725 - -train accuracy: 0.707479\n",
      "epoch: 970 - cost: 0.631695 mse:  209.492121121 - -train accuracy: 0.677935\n",
      "epoch: 971 - cost: 0.652698 mse:  203.350909946 - -train accuracy: 0.708012\n",
      "epoch: 972 - cost: 0.630595 mse:  209.368098712 - -train accuracy: 0.678201\n",
      "epoch: 973 - cost: 0.651436 mse:  203.264378875 - -train accuracy: 0.708278\n",
      "epoch: 974 - cost: 0.629574 mse:  209.252756198 - -train accuracy: 0.678201\n",
      "epoch: 975 - cost: 0.650216 mse:  203.180613356 - -train accuracy: 0.70881\n",
      "epoch: 976 - cost: 0.628555 mse:  209.144494235 - -train accuracy: 0.679265\n",
      "epoch: 977 - cost: 0.649069 mse:  203.095873129 - -train accuracy: 0.709343\n",
      "epoch: 978 - cost: 0.627635 mse:  209.037577467 - -train accuracy: 0.680064\n",
      "epoch: 979 - cost: 0.648053 mse:  203.003211406 - -train accuracy: 0.709343\n",
      "epoch: 980 - cost: 0.626778 mse:  208.930227868 - -train accuracy: 0.680596\n",
      "epoch: 981 - cost: 0.647053 mse:  202.910228661 - -train accuracy: 0.709609\n",
      "epoch: 982 - cost: 0.625953 mse:  208.815390517 - -train accuracy: 0.680862\n",
      "epoch: 983 - cost: 0.646102 mse:  202.81613103 - -train accuracy: 0.709076\n",
      "epoch: 984 - cost: 0.625132 mse:  208.703637011 - -train accuracy: 0.680862\n",
      "epoch: 985 - cost: 0.645175 mse:  202.732598458 - -train accuracy: 0.709076\n",
      "epoch: 986 - cost: 0.624352 mse:  208.58960713 - -train accuracy: 0.68033\n",
      "epoch: 987 - cost: 0.644195 mse:  202.641776478 - -train accuracy: 0.709076\n",
      "epoch: 988 - cost: 0.623489 mse:  208.476928449 - -train accuracy: 0.681129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 989 - cost: 0.643199 mse:  202.558026969 - -train accuracy: 0.709875\n",
      "epoch: 990 - cost: 0.622671 mse:  208.370892704 - -train accuracy: 0.680596\n",
      "epoch: 991 - cost: 0.642225 mse:  202.467509265 - -train accuracy: 0.710141\n",
      "epoch: 992 - cost: 0.621851 mse:  208.260602954 - -train accuracy: 0.680596\n",
      "epoch: 993 - cost: 0.641217 mse:  202.390543743 - -train accuracy: 0.710673\n",
      "epoch: 994 - cost: 0.621042 mse:  208.165528031 - -train accuracy: 0.681129\n",
      "epoch: 995 - cost: 0.640305 mse:  202.303257186 - -train accuracy: 0.71094\n",
      "epoch: 996 - cost: 0.620281 mse:  208.060956809 - -train accuracy: 0.681395\n",
      "epoch: 997 - cost: 0.639377 mse:  202.208446404 - -train accuracy: 0.711738\n",
      "epoch: 998 - cost: 0.619488 mse:  207.942526849 - -train accuracy: 0.681395\n",
      "epoch: 999 - cost: 0.638469 mse:  202.116205559 - -train accuracy: 0.71227\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    sess.run(train_step,feed_dict={x:x_train,y_:y_train})\n",
    "    cost=sess.run(cross_entropy,feed_dict={x:x_train,y_:y_train})\n",
    "    cost_history.append(np.append(cost_history,cost))\n",
    "    correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    \n",
    "    pred_y=sess.run(y,feed_dict={x:x_test})\n",
    "    mse=tf.reduce_mean(tf.square(pred_y-y_test))\n",
    "    mse_=sess.run(mse)\n",
    "    mse_history.append(mse_)\n",
    "    accuracy=sess.run(accuracy,feed_dict={x:x_train,y_:y_train})\n",
    "    accuracy_history.append(accuracy)\n",
    "    \n",
    "    print('epoch:',epoch,'-','cost:',cost,'mse: ',mse_,'-','-train accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.706645\n"
     ]
    }
   ],
   "source": [
    "correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "print('test accuracy:',sess.run(accuracy,feed_dict={x:x_test,y_:y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse:202.1162\n"
     ]
    }
   ],
   "source": [
    "pred_y=sess.run(y,feed_dict={x:x_test})\n",
    "mse=tf.reduce_mean(tf.square(pred_y-y_test))\n",
    "print('mse:%.4f'%sess.run(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
